{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding After Cleaning\n",
    "\n",
    "After performing the cleaning, we check again some basic information to show that all the data is correct in the sintax and the semantic, and that the cleaned data are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload allows the notebook to dynamically load code: if we update some helper functions *outside* of the notebook, we do not need to reload the notebook.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclist_url</th>\n",
       "      <th>cyclist_name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>nationality</th>\n",
       "      <th>race_url</th>\n",
       "      <th>race_name</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>...</th>\n",
       "      <th>profile</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>mostly_tarmac</th>\n",
       "      <th>cyclist_team</th>\n",
       "      <th>delta</th>\n",
       "      <th>race_year</th>\n",
       "      <th>race_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>georges-pintens</td>\n",
       "      <td>Georges  Pintens</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>norway-1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willy-van-neste</td>\n",
       "      <td>Willy Van Neste</td>\n",
       "      <td>1944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>norway-1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andre-dierickx</td>\n",
       "      <td>André  Dierickx</td>\n",
       "      <td>1947</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>spain-1991</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eric-leman</td>\n",
       "      <td>Eric  Leman</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>spain-1991</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joseph-schoeters</td>\n",
       "      <td>Joseph  Schoeters</td>\n",
       "      <td>1947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cyclist_url       cyclist_name  birth_year  weight  height  \\\n",
       "0   georges-pintens   Georges  Pintens        1946     NaN     NaN   \n",
       "1   willy-van-neste    Willy Van Neste        1944     NaN     NaN   \n",
       "2    andre-dierickx    André  Dierickx        1947    74.0   180.0   \n",
       "3        eric-leman        Eric  Leman        1946     NaN     NaN   \n",
       "4  joseph-schoeters  Joseph  Schoeters        1947     NaN     NaN   \n",
       "\n",
       "  nationality                      race_url         race_name  points  \\\n",
       "0     Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "1     Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "2     Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "3     Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "4     Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "\n",
       "   uci_points  ...  profile  startlist_quality        date  position  \\\n",
       "0         NaN  ...      NaN                372  1970-04-25         0   \n",
       "1         NaN  ...      NaN                372  1970-04-25         1   \n",
       "2         NaN  ...      NaN                372  1970-04-25         2   \n",
       "3         NaN  ...      NaN                372  1970-04-25         3   \n",
       "4         NaN  ...      NaN                372  1970-04-25         4   \n",
       "\n",
       "  cyclist_age  mostly_tarmac  cyclist_team  delta race_year  race_stage  \n",
       "0          24          False   norway-1987    0.0      1970      result  \n",
       "1          26          False   norway-1987    0.0      1970      result  \n",
       "2          23          False    spain-1991   22.0      1970      result  \n",
       "3          24          False    spain-1991   33.0      1970      result  \n",
       "4          23          False           NaN   33.0      1970      result  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"../data/cleaned_merged_dataset.csv\"\n",
    "dataset = pd.read_csv(csv_file)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589739 entries, 0 to 589738\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   cyclist_url        589739 non-null  object \n",
      " 1   cyclist_name       589739 non-null  object \n",
      " 2   birth_year         589739 non-null  int64  \n",
      " 3   weight             480007 non-null  float64\n",
      " 4   height             480007 non-null  float64\n",
      " 5   nationality        589739 non-null  object \n",
      " 6   race_url           589739 non-null  object \n",
      " 7   race_name          589739 non-null  object \n",
      " 8   points             589739 non-null  float64\n",
      " 9   uci_points         422184 non-null  float64\n",
      " 10  length             589739 non-null  float64\n",
      " 11  climb_total        475338 non-null  float64\n",
      " 12  profile            475338 non-null  float64\n",
      " 13  startlist_quality  589739 non-null  int64  \n",
      " 14  date               589739 non-null  object \n",
      " 15  position           589739 non-null  int64  \n",
      " 16  cyclist_age        589739 non-null  int64  \n",
      " 17  mostly_tarmac      589739 non-null  bool   \n",
      " 18  cyclist_team       451105 non-null  object \n",
      " 19  delta              589739 non-null  float64\n",
      " 20  race_year          589739 non-null  int64  \n",
      " 21  race_stage         589739 non-null  object \n",
      "dtypes: bool(1), float64(8), int64(5), object(8)\n",
      "memory usage: 95.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>length</th>\n",
       "      <th>climb_total</th>\n",
       "      <th>profile</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>delta</th>\n",
       "      <th>race_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>589739.000000</td>\n",
       "      <td>480007.000000</td>\n",
       "      <td>480007.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>422184.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>475338.000000</td>\n",
       "      <td>475338.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1977.683221</td>\n",
       "      <td>68.362072</td>\n",
       "      <td>179.699850</td>\n",
       "      <td>89.225897</td>\n",
       "      <td>70.663263</td>\n",
       "      <td>166776.290800</td>\n",
       "      <td>2318.550823</td>\n",
       "      <td>2.585028</td>\n",
       "      <td>1101.182822</td>\n",
       "      <td>74.217408</td>\n",
       "      <td>28.485834</td>\n",
       "      <td>430.755887</td>\n",
       "      <td>2006.169054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.537102</td>\n",
       "      <td>6.182201</td>\n",
       "      <td>6.269585</td>\n",
       "      <td>54.415806</td>\n",
       "      <td>120.160957</td>\n",
       "      <td>64543.334848</td>\n",
       "      <td>1343.872704</td>\n",
       "      <td>1.502340</td>\n",
       "      <td>380.588233</td>\n",
       "      <td>48.405261</td>\n",
       "      <td>3.855921</td>\n",
       "      <td>1011.486288</td>\n",
       "      <td>11.476909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1933.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1970.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>152500.000000</td>\n",
       "      <td>1306.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>844.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1979.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>178200.000000</td>\n",
       "      <td>2216.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1986.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>203500.000000</td>\n",
       "      <td>3218.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>338000.000000</td>\n",
       "      <td>6974.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46380.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          birth_year         weight         height         points  \\\n",
       "count  589739.000000  480007.000000  480007.000000  589739.000000   \n",
       "mean     1977.683221      68.362072     179.699850      89.225897   \n",
       "std        11.537102       6.182201       6.269585      54.415806   \n",
       "min      1933.000000      48.000000     154.000000      18.000000   \n",
       "25%      1970.000000      64.000000     175.000000      50.000000   \n",
       "50%      1979.000000      68.000000     180.000000      80.000000   \n",
       "75%      1986.000000      73.000000     184.000000     100.000000   \n",
       "max      2004.000000      94.000000     204.000000     350.000000   \n",
       "\n",
       "          uci_points         length    climb_total        profile  \\\n",
       "count  422184.000000  589739.000000  475338.000000  475338.000000   \n",
       "mean       70.663263  166776.290800    2318.550823       2.585028   \n",
       "std       120.160957   64543.334848    1343.872704       1.502340   \n",
       "min         6.000000    1000.000000       2.000000       1.000000   \n",
       "25%        16.000000  152500.000000    1306.000000       1.000000   \n",
       "50%        20.000000  178200.000000    2216.000000       2.000000   \n",
       "75%       100.000000  203500.000000    3218.000000       4.000000   \n",
       "max       800.000000  338000.000000    6974.000000       5.000000   \n",
       "\n",
       "       startlist_quality       position    cyclist_age          delta  \\\n",
       "count      589739.000000  589739.000000  589739.000000  589739.000000   \n",
       "mean         1101.182822      74.217408      28.485834     430.755887   \n",
       "std           380.588233      48.405261       3.855921    1011.486288   \n",
       "min           115.000000       0.000000      13.000000       0.000000   \n",
       "25%           844.000000      32.000000      26.000000      11.000000   \n",
       "50%           988.000000      70.000000      28.000000     158.000000   \n",
       "75%          1309.000000     112.000000      31.000000     626.000000   \n",
       "max          2047.000000     209.000000      56.000000   46380.000000   \n",
       "\n",
       "           race_year  \n",
       "count  589739.000000  \n",
       "mean     2006.169054  \n",
       "std        11.476909  \n",
       "min      1970.000000  \n",
       "25%      1999.000000  \n",
       "50%      2008.000000  \n",
       "75%      2015.000000  \n",
       "max      2023.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks of cyclists data\n",
    "\n",
    "Now we start from the data related to the initial cyclist dataset (we consider only the modified columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'birth_year' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just check that all years are in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid birth_year: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove '.0' from 'birth_year' and check if it's a valid year in the form '19nn' or '20nn'\n",
    "def is_valid_year(birth_year):\n",
    "    # Convert to string and remove '.0'\n",
    "    year = str(birth_year).replace('.0', '')\n",
    "    # Check if the year is a digit and starts with '19' or '20'\n",
    "    return year.isdigit() and (year.startswith('19') or year.startswith('20'))\n",
    "\n",
    "# Filter out rows where 'birth_year' is not null\n",
    "invalid_rows = dataset[dataset['birth_year'].notnull()]\n",
    "\n",
    "# Apply the validation function across the 'birth_year' column\n",
    "invalid_rows = invalid_rows[~invalid_rows['birth_year'].apply(is_valid_year)]\n",
    "\n",
    "print('Number of invalid birth_year: ' + str(len(invalid_rows)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'weight' and 'height' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the remaining null values of weight and height are only of the cyclist where they are both missings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyclists where we don't have both weight and height: 109732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "weight    109732\n",
       "height    109732\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where both 'weight' and 'height' are null\n",
    "missing_weight_missing_height = dataset[dataset['weight'].isnull() & dataset['height'].isnull()]\n",
    "\n",
    "print(\"Cyclists where we don't have both weight and height:\", len(missing_weight_missing_height))\n",
    "dataset[['weight', 'height']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check that all values respect the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid height: 0\n",
      "Number of invalid weight: 0\n"
     ]
    }
   ],
   "source": [
    "# Check that every value in 'height' and 'weight' (without considering the null values) is a number with 1 decimal point\n",
    "\n",
    "def is_valid_number(value):\n",
    "    if pd.notnull(value):\n",
    "        return bool(re.match(r'^\\d+\\.\\d$', str(value)))\n",
    "    return True # If the value is null, we consider it valid\n",
    "\n",
    "invalid_height = dataset[~dataset['height'].apply(is_valid_number)]\n",
    "invalid_weight = dataset[~dataset['weight'].apply(is_valid_number)]\n",
    "\n",
    "print('Number of invalid height: ' + str(len(invalid_height)))\n",
    "print('Number of invalid weight: ' + str(len(invalid_weight)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'nationality' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that every nationality is a string with no number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with numbers in nationality: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are 'nationality' values that contains any number\n",
    "invalid_rows = dataset[dataset['nationality'].str.contains(r'\\d')]\n",
    "\n",
    "print('Number of rows with numbers in nationality: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks of races data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'points' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `points` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique points: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'points' column\n",
    "points_uniques = dataset.groupby('race_url')['points'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique points\n",
    "multiple_points_urls = points_uniques[points_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique points: ' + str(len(multiple_points_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all points respect the correct fromat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid points: 0\n"
     ]
    }
   ],
   "source": [
    "# Check that every value in 'points' is a number that finish with '.0'\n",
    "def is_valid_integer(value):\n",
    "    if pd.notnull(value):\n",
    "        return bool(re.match(r'^\\d+\\.0$', str(value)))\n",
    "    return True # If the value is null, we consider it valid\n",
    "\n",
    "invalid_points = dataset[~dataset['points'].apply(is_valid_integer)]\n",
    "\n",
    "print('Number of invalid points: ' + str(len(invalid_points)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'uci_points' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in uci_points column: 167555 (28.41%)\n",
      "Number of null values in uci_points column before 2001: 167555\n",
      "Number of null values in uci_points column after 2001: 0\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in uci_points column: ' + str(dataset['uci_points'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['uci_points'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "null_values_before_2001 = dataset[dataset['uci_points'].isnull() & (dataset['race_year'] < 2001)]\n",
    "null_values_after_2001 = dataset[dataset['uci_points'].isnull() & (dataset['race_year'] >= 2001)]\n",
    "\n",
    "print('Number of null values in uci_points column before 2001: ' + str(len(null_values_before_2001)))\n",
    "print('Number of null values in uci_points column after 2001: ' + str(len(null_values_after_2001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique uci_points: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'uci_points' column\n",
    "uci_points_uniques = dataset.groupby('race_url')['uci_points'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique uci_points\n",
    "multiple_uci_points_urls = uci_points_uniques[uci_points_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique uci_points: ' + str(len(multiple_uci_points_urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid uci points: 0\n"
     ]
    }
   ],
   "source": [
    "# Check that every value in 'uci_points' is a number that finish with '.0'\n",
    "def is_valid_integer(value):\n",
    "    if pd.notnull(value):\n",
    "        return bool(re.match(r'^\\d+\\.0$', str(value)))\n",
    "    return True # If the value is null, we consider it valid\n",
    "\n",
    "invalid_points = dataset[~dataset['uci_points'].apply(is_valid_integer)]\n",
    "\n",
    "print('Number of invalid uci points: ' + str(len(invalid_points)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'climb_total' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in climb_total column: 114401 (19.4%)\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in climb_total column: ' + str(dataset['climb_total'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['climb_total'].isnull().sum() / len(dataset) * 100, 2)) + '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `climb_total` values are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique climb_total: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'climb_total' column\n",
    "climb_total_uniques = dataset.groupby('race_url')['climb_total'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique climb_total\n",
    "multiple_climb_total_urls = climb_total_uniques[climb_total_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique climb_total: ' + str(len(multiple_climb_total_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'profile' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `profile` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in profile column: 114401 (19.4%)\n",
      "profile\n",
      "1.0    147246\n",
      "2.0    138083\n",
      "3.0     50842\n",
      "4.0     43011\n",
      "5.0     96156\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in profile column: ' + str(dataset['profile'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['profile'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "# Sort by profile value\n",
    "profile_counts = dataset['profile'].value_counts().sort_index()\n",
    "print(profile_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique profile: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'profile' column\n",
    "profile_uniques = dataset.groupby('race_url')['profile'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique profile\n",
    "multiple_profile_urls = profile_uniques[profile_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique profile: ' + str(len(multiple_profile_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'date' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `date` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique date: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'date' column\n",
    "date_uniques = dataset.groupby('race_url')['date'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique date\n",
    "multiple_date_urls = date_uniques[date_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique date: ' + str(len(multiple_date_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid dates: 589739\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any 'date' values not in the format yyyy-mm-dd (in the merged dataset)\n",
    "invalid_rows = dataset[dataset['date'].str.match(r'\\d{4}-\\d{2}-\\d{2}')]\n",
    "print('Number of invalid dates: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'position' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if there are all the `position` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with invalid positions: 98\n"
     ]
    }
   ],
   "source": [
    "# Function to check if the positions are from 0 to the max one after the other\n",
    "def check_positions(positions):\n",
    "    return np.array_equal(np.sort(positions), np.arange(positions.max() + 1))\n",
    "\n",
    "# Apply the function to the dataset\n",
    "invalid_urls = dataset.groupby('race_url')['position'].apply(lambda x: not check_positions(x))\n",
    "\n",
    "# Stampa gli '_url' che non rispettano la condizione\n",
    "print('Number of URLs with invalid positions: ' + str(len(invalid_urls[invalid_urls])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have this because we delete the duplicated cyclist in the same race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'cyclist_age' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `cyclist_age` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in cyclist_age column: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in cyclist_age column: ' + str(dataset['cyclist_age'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['cyclist_age'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'cyclist_team' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `cyclist_team` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in cyclist_team column: 138634 (23.51%)\n"
     ]
    }
   ],
   "source": [
    "# Print total number of null values in 'delta' column, and the percentage of null values (float with two decimal digits after the comma)\n",
    "print('Total number of null values in cyclist_team column: ' + str(dataset['cyclist_team'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['cyclist_team'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if every 'cyclist_team' value matches the required format\n",
    "invalid_teams = dataset[dataset['cyclist_team'].notnull() & ~dataset['cyclist_team'].astype(str).str.match(r'.+-\\d{4}')]\n",
    "\n",
    "print('Number of invalid rows: ' + str(len(invalid_teams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'delta' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `delta` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in delta column: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in delta column: ' + str(dataset['delta'].isnull().sum())\n",
    "        + ' (' + str(round(dataset['delta'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid deltas: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any 'delta' values that do not end with '.0'\n",
    "invalid_rows = dataset[~dataset['delta'].astype(str).str.endswith('.0')]\n",
    "\n",
    "print('Number of invalid deltas: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative deltas: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any 'delta' values that are negative\n",
    "invalid_rows = dataset[dataset['delta'] < 0]\n",
    "\n",
    "print('Number of negative deltas: ' + str(len(invalid_rows)))\n",
    "for index, row in invalid_rows.iterrows():\n",
    "    print(row['_url'], row['delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if following the `positon` order, the delta is ordered too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with invalid deltas: 0\n"
     ]
    }
   ],
   "source": [
    "# Grouped by '_url', check if the 'delta' value is greater or equal than the previous one (the one in the previous row, except for the first one)\n",
    "invalid_urls = dataset.groupby(['race_url', 'delta'])['delta'].apply(lambda x: (x.shift() > x).any())\n",
    "\n",
    "# Print the number of URLs with invalid 'delta' values\n",
    "print('Number of URLs with invalid deltas: ' + str(len(invalid_urls[invalid_urls])))\n",
    "for url in invalid_urls[invalid_urls].index:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'race_year' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `race_year` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in year column: 0\n"
     ]
    }
   ],
   "source": [
    "# Print total number of null values in 'race_year' column, and the percentage of null values (float with two decimal digits after the comma)\n",
    "print('Total number of null values in year column: ' + str(dataset['race_year'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `race_year` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique race_year: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'race_url' and calculate the number of unique values in the 'race_year' column\n",
    "race_year_uniques = dataset.groupby('race_url')['race_year'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique race_year\n",
    "multiple_race_year_urls = race_year_uniques[race_year_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique race_year: ' + str(len(multiple_race_year_urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid year: 0\n"
     ]
    }
   ],
   "source": [
    "# Check that the year match the year in the url (race/year/stage) and in the date (year-month-day)\n",
    "def get_year_from_url(url):\n",
    "    return int(url.split('/')[1])\n",
    "\n",
    "def get_year_from_date(date):\n",
    "    return int(date.split('-')[0])\n",
    "\n",
    "# Check if the year in 'race_year' matches the year extracted from 'race_url' and 'date'\n",
    "invalid_year_rows = dataset[\n",
    "    (dataset['race_year'] != dataset['race_url'].apply(get_year_from_url)) | (dataset['race_year'] != dataset['date'].apply(get_year_from_date))\n",
    "]\n",
    "\n",
    "print('Number of rows with invalid year: ' + str(len(invalid_year_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on 'race_stage' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `race_stage` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in stage column: 0\n"
     ]
    }
   ],
   "source": [
    "# Print total number of null values in 'race_stage' column, and the percentage of null values (float with two decimal digits after the comma)\n",
    "print('Total number of null values in stage column: ' + str(dataset['race_stage'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `race_stage` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique race_stage: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'race_url' and calculate the number of unique values in the 'race_stage' column\n",
    "race_stage_uniques = dataset.groupby('race_url')['race_stage'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique race_stage\n",
    "multiple_race_stage_urls = race_stage_uniques[race_stage_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique race_stage: ' + str(len(multiple_race_stage_urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid stage: 0\n"
     ]
    }
   ],
   "source": [
    "# Check that the stage match the stage in the url (race/year/stage)\n",
    "def get_stage_from_url(url):\n",
    "    return url.split('/')[2]\n",
    "\n",
    "# Check if the stage in the race_stage matches the stage extracted from 'race_url'\n",
    "invalid_stage_rows = dataset[\n",
    "    (dataset['race_stage'] != dataset['race_url'].apply(get_stage_from_url))\n",
    "]\n",
    "\n",
    "print('Number of rows with invalid stage: ' + str(len(invalid_stage_rows)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

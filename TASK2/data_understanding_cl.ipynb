{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding After Cleaning\n",
    "\n",
    "After performing the cleaning, we check again some basic information to show that all the data in correct in the sintax and the semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload allows the notebook to dynamically load code: if we update some helper functions *outside* of the notebook, we do not need to reload the notebook.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url_cyclist</th>\n",
       "      <th>name_cyclist</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>nationality</th>\n",
       "      <th>_url_race</th>\n",
       "      <th>name_race</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>...</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>mostly_tarmac</th>\n",
       "      <th>cyclist_team</th>\n",
       "      <th>delta</th>\n",
       "      <th>year</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerard-vianen</td>\n",
       "      <td>Gerard  Vianen</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>23</td>\n",
       "      <td>gerard-vianen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>uae-team-emirates-2018</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jos-huysmans</td>\n",
       "      <td>Jos  Huysmans</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>18</td>\n",
       "      <td>jos-huysmans</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "      <td>team-monex-2005</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>romain-furniere</td>\n",
       "      <td>Romain  Furniere</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>31</td>\n",
       "      <td>romain-furniere</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>willy-donie</td>\n",
       "      <td>Willy  Donie</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>27</td>\n",
       "      <td>willy-donie</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frans-melckenbeeck</td>\n",
       "      <td>Frans  Melckenbeeck</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>amstel-gold-race/1970/result</td>\n",
       "      <td>Amstel Gold Race</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>372</td>\n",
       "      <td>1970-04-25</td>\n",
       "      <td>8</td>\n",
       "      <td>frans-melckenbeeck</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>team-qhubeka-assos-2021</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _url_cyclist         name_cyclist  birth_year  weight  height  \\\n",
       "0       gerard-vianen       Gerard  Vianen      1944.0     NaN     NaN   \n",
       "1        jos-huysmans        Jos  Huysmans      1941.0     NaN     NaN   \n",
       "2     romain-furniere     Romain  Furniere      1943.0     NaN     NaN   \n",
       "3         willy-donie         Willy  Donie      1945.0     NaN     NaN   \n",
       "4  frans-melckenbeeck  Frans  Melckenbeeck      1940.0     NaN     NaN   \n",
       "\n",
       "   nationality                     _url_race         name_race  points  \\\n",
       "0  Netherlands  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "1      Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "2      Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "3      Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "4      Belgium  amstel-gold-race/1970/result  Amstel Gold Race   225.0   \n",
       "\n",
       "   uci_points  ...  startlist_quality        date  position  \\\n",
       "0         NaN  ...                372  1970-04-25        23   \n",
       "1         NaN  ...                372  1970-04-25        18   \n",
       "2         NaN  ...                372  1970-04-25        31   \n",
       "3         NaN  ...                372  1970-04-25        27   \n",
       "4         NaN  ...                372  1970-04-25         8   \n",
       "\n",
       "              cyclist cyclist_age  mostly_tarmac             cyclist_team  \\\n",
       "0       gerard-vianen        26.0          False   uae-team-emirates-2018   \n",
       "1        jos-huysmans        29.0          False          team-monex-2005   \n",
       "2     romain-furniere        27.0          False                      NaN   \n",
       "3         willy-donie        25.0          False                      NaN   \n",
       "4  frans-melckenbeeck        30.0          False  team-qhubeka-assos-2021   \n",
       "\n",
       "   delta  year   stage  \n",
       "0   52.0  1970  result  \n",
       "1   52.0  1970  result  \n",
       "2   52.0  1970  result  \n",
       "3   52.0  1970  result  \n",
       "4   33.0  1970  result  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"../data/merged_dataset.csv\"\n",
    "dataset = pd.read_csv(csv_file)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589739 entries, 0 to 589738\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   _url_cyclist       589739 non-null  object \n",
      " 1   name_cyclist       589739 non-null  object \n",
      " 2   birth_year         589739 non-null  float64\n",
      " 3   weight             480007 non-null  float64\n",
      " 4   height             480007 non-null  float64\n",
      " 5   nationality        589739 non-null  object \n",
      " 6   _url_race          589739 non-null  object \n",
      " 7   name_race          589739 non-null  object \n",
      " 8   points             589739 non-null  float64\n",
      " 9   uci_points         422184 non-null  float64\n",
      " 10  length             589739 non-null  float64\n",
      " 11  climb_total        573157 non-null  float64\n",
      " 12  profile            573157 non-null  float64\n",
      " 13  startlist_quality  589739 non-null  int64  \n",
      " 14  date               589739 non-null  object \n",
      " 15  position           589739 non-null  int64  \n",
      " 16  cyclist            589739 non-null  object \n",
      " 17  cyclist_age        589739 non-null  float64\n",
      " 18  mostly_tarmac      589739 non-null  bool   \n",
      " 19  cyclist_team       451105 non-null  object \n",
      " 20  delta              589739 non-null  float64\n",
      " 21  year               589739 non-null  int64  \n",
      " 22  stage              589739 non-null  object \n",
      "dtypes: bool(1), float64(10), int64(3), object(9)\n",
      "memory usage: 99.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>length</th>\n",
       "      <th>climb_total</th>\n",
       "      <th>profile</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>delta</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>589739.000000</td>\n",
       "      <td>480007.000000</td>\n",
       "      <td>480007.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>422184.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>573157.000000</td>\n",
       "      <td>573157.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "      <td>589739.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1977.683221</td>\n",
       "      <td>68.362072</td>\n",
       "      <td>179.699850</td>\n",
       "      <td>89.225897</td>\n",
       "      <td>72.048275</td>\n",
       "      <td>166776.290800</td>\n",
       "      <td>2319.964102</td>\n",
       "      <td>2.497300</td>\n",
       "      <td>1101.182822</td>\n",
       "      <td>74.217408</td>\n",
       "      <td>28.485834</td>\n",
       "      <td>430.755887</td>\n",
       "      <td>2006.169054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.537102</td>\n",
       "      <td>6.182201</td>\n",
       "      <td>6.269585</td>\n",
       "      <td>54.415806</td>\n",
       "      <td>121.041689</td>\n",
       "      <td>64543.334848</td>\n",
       "      <td>1353.290485</td>\n",
       "      <td>1.478509</td>\n",
       "      <td>380.588233</td>\n",
       "      <td>48.405261</td>\n",
       "      <td>3.855921</td>\n",
       "      <td>1011.486288</td>\n",
       "      <td>11.476909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1933.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1970.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>152500.000000</td>\n",
       "      <td>1331.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>844.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1979.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>178200.000000</td>\n",
       "      <td>2269.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1986.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>203500.000000</td>\n",
       "      <td>3274.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>338000.000000</td>\n",
       "      <td>6974.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46380.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          birth_year         weight         height         points  \\\n",
       "count  589739.000000  480007.000000  480007.000000  589739.000000   \n",
       "mean     1977.683221      68.362072     179.699850      89.225897   \n",
       "std        11.537102       6.182201       6.269585      54.415806   \n",
       "min      1933.000000      48.000000     154.000000      18.000000   \n",
       "25%      1970.000000      64.000000     175.000000      50.000000   \n",
       "50%      1979.000000      68.000000     180.000000      80.000000   \n",
       "75%      1986.000000      73.000000     184.000000     100.000000   \n",
       "max      2004.000000      94.000000     204.000000     350.000000   \n",
       "\n",
       "          uci_points         length    climb_total        profile  \\\n",
       "count  422184.000000  589739.000000  573157.000000  573157.000000   \n",
       "mean       72.048275  166776.290800    2319.964102       2.497300   \n",
       "std       121.041689   64543.334848    1353.290485       1.478509   \n",
       "min         6.000000    1000.000000       2.000000       1.000000   \n",
       "25%        16.000000  152500.000000    1331.000000       1.000000   \n",
       "50%        20.000000  178200.000000    2269.000000       2.000000   \n",
       "75%       100.000000  203500.000000    3274.000000       4.000000   \n",
       "max       800.000000  338000.000000    6974.000000       5.000000   \n",
       "\n",
       "       startlist_quality       position    cyclist_age          delta  \\\n",
       "count      589739.000000  589739.000000  589739.000000  589739.000000   \n",
       "mean         1101.182822      74.217408      28.485834     430.755887   \n",
       "std           380.588233      48.405261       3.855921    1011.486288   \n",
       "min           115.000000       0.000000      13.000000       0.000000   \n",
       "25%           844.000000      32.000000      26.000000      11.000000   \n",
       "50%           988.000000      70.000000      28.000000     158.000000   \n",
       "75%          1309.000000     112.000000      31.000000     626.000000   \n",
       "max          2047.000000     209.000000      56.000000   46380.000000   \n",
       "\n",
       "                year  \n",
       "count  589739.000000  \n",
       "mean     2006.169054  \n",
       "std        11.476909  \n",
       "min      1970.000000  \n",
       "25%      1999.000000  \n",
       "50%      2008.000000  \n",
       "75%      2015.000000  \n",
       "max      2023.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks of cyclists data\n",
    "\n",
    "Now we start from the data related to the initial cyclist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on '_url' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start considering the `_url` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in _url column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in _url column:\n",
      "_url\n",
      "ward-vanhoof            1\n",
      "bruno-surra             1\n",
      "gerard-rue              1\n",
      "jan-maas                1\n",
      "nathan-van-hooydonck    1\n",
      "                       ..\n",
      "stian-remme             1\n",
      "scott-davies            1\n",
      "joost-van-leijen        1\n",
      "chad-haga               1\n",
      "willy-moonen            1\n",
      "Name: count, Length: 6134, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in _url column: ' + str(dataset['_url'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['_url'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in _url column:')\n",
    "url_counts = dataset['_url'].value_counts()\n",
    "print(url_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lots different values, but no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'name' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `name` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in name column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in name column:\n",
      "name\n",
      "Sergio  Domínguez       2\n",
      "Alberto  Fernández      2\n",
      "Jesús  López            2\n",
      "Antonio  Cabello        2\n",
      "Alessandro  Pozzi       2\n",
      "                       ..\n",
      "Juan José  Martínez     1\n",
      "Iñigo  Elosegui         1\n",
      "Paolo  Alberati         1\n",
      "Jackson  Rodríguez      1\n",
      "Jean-Philippe  Dojwa    1\n",
      "Name: count, Length: 6127, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in name column: ' + str(dataset['name'].isnull().sum())\n",
    "        + ' (' + str(round(dataset['name'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in name column:')\n",
    "name_counts = dataset['name'].value_counts()\n",
    "print(name_counts)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lots of different values, but no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with numbers in the name: 0\n"
     ]
    }
   ],
   "source": [
    "# For each data, check if 'name' object contains any number\n",
    "# Check if the 'name' column contains any number\n",
    "invalid_rows = dataset[dataset['name'].str.contains(r'\\d')]\n",
    "\n",
    "print('Number of rows with numbers in the name: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'birth_year' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `birth_year` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in birth_year column: 13 (0.21%)\n",
      "\n",
      "Count occurrences of each value in birth_year column:\n",
      "birth_year\n",
      "1964.0    145\n",
      "1962.0    141\n",
      "1970.0    140\n",
      "1974.0    138\n",
      "1980.0    133\n",
      "         ... \n",
      "1937.0      4\n",
      "1934.0      2\n",
      "1938.0      2\n",
      "1933.0      1\n",
      "1936.0      1\n",
      "Name: count, Length: 71, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in birth_year column: ' + str(dataset['birth_year'].isnull().sum())\n",
    "        + ' (' + str(round(dataset['birth_year'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in birth_year column:')\n",
    "birth_year_counts = dataset['birth_year'].value_counts()\n",
    "print(birth_year_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, and a few null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid birth_year: 0\n"
     ]
    }
   ],
   "source": [
    "# Get rows where 'birth_year' does not end with '.0'\n",
    "invalid_rows = dataset[~dataset['birth_year'].astype(str).str.endswith('.0')].dropna(subset=['birth_year'])\n",
    "\n",
    "print('Number of invalid birth_year: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block we check if the `birth year` value is not in the form 'nnnn' and if it is not in the form '19nn' or '20nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid birth_year: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove '.0' from 'birth_year' and check if it's a valid year in the form '19nn' or '20nn'\n",
    "def is_valid_year(birth_year):\n",
    "    # Convert to string and remove '.0'\n",
    "    year = str(birth_year).replace('.0', '')\n",
    "    # Check if the year is a digit and starts with '19' or '20'\n",
    "    return year.isdigit() and (year.startswith('19') or year.startswith('20'))\n",
    "\n",
    "# Filter out rows where 'birth_year' is not null\n",
    "invalid_rows = dataset[dataset['birth_year'].notnull()]\n",
    "\n",
    "# Apply the validation function across the 'birth_year' column\n",
    "invalid_rows = invalid_rows[~invalid_rows['birth_year'].apply(is_valid_year)]\n",
    "\n",
    "print('Number of invalid birth_year: ' + str(len(invalid_rows)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the races where the `birth_year` value is small or large, for possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6121.000000\n",
       "mean     1974.071884\n",
       "std        15.535834\n",
       "min      1933.000000\n",
       "25%      1962.000000\n",
       "50%      1974.000000\n",
       "75%      1987.000000\n",
       "max      2004.000000\n",
       "Name: birth_year, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset info, for 'birth_year' column\n",
    "dataset['birth_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The birth years are between 1933 and 2004, so we can say that no extreme values are present (in the cyclism context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'weight' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `weight` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in weight column: 3056 (49.82%)\n",
      "\n",
      "Count occurrences of each value in weight column:\n",
      "weight\n",
      "70.0    272\n",
      "68.0    219\n",
      "65.0    193\n",
      "67.0    177\n",
      "72.0    169\n",
      "69.0    162\n",
      "73.0    146\n",
      "63.0    140\n",
      "66.0    139\n",
      "64.0    137\n",
      "74.0    135\n",
      "62.0    131\n",
      "75.0    128\n",
      "71.0    125\n",
      "60.0     98\n",
      "61.0     90\n",
      "78.0     86\n",
      "77.0     67\n",
      "58.0     64\n",
      "76.0     63\n",
      "80.0     53\n",
      "59.0     49\n",
      "79.0     30\n",
      "82.0     26\n",
      "55.0     25\n",
      "81.0     22\n",
      "83.0     20\n",
      "57.0     20\n",
      "56.0     19\n",
      "85.0     10\n",
      "53.0      7\n",
      "52.0      6\n",
      "84.0      6\n",
      "54.0      4\n",
      "51.0      4\n",
      "90.0      4\n",
      "87.0      3\n",
      "88.0      3\n",
      "63.5      2\n",
      "89.0      2\n",
      "50.0      2\n",
      "58.5      2\n",
      "86.0      2\n",
      "71.5      1\n",
      "48.0      1\n",
      "91.0      1\n",
      "67.5      1\n",
      "66.5      1\n",
      "78.1      1\n",
      "77.5      1\n",
      "74.5      1\n",
      "81.4      1\n",
      "62.5      1\n",
      "93.0      1\n",
      "73.5      1\n",
      "79.5      1\n",
      "65.1      1\n",
      "92.0      1\n",
      "94.0      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in weight column: ' + str(dataset['weight'].isnull().sum())\n",
    "        + ' (' + str(round(dataset['weight'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in weight column:')\n",
    "weight_counts = dataset['weight'].value_counts()\n",
    "print(weight_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, but a lot of null values. Also, we see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the races where the `weight` value is small or large, for possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3078.000000\n",
       "mean       68.658739\n",
       "std         6.348183\n",
       "min        48.000000\n",
       "25%        64.000000\n",
       "50%        69.000000\n",
       "75%        73.000000\n",
       "max        94.000000\n",
       "Name: weight, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset info, for 'weight' column\n",
    "dataset['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are between 48 and 94 kg, so we can say that no extreme values are present (in the cyclism context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'height' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `height` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in height column: 2991 (48.76%)\n",
      "\n",
      "Count occurrences of each value in height column:\n",
      "height\n",
      "180.0    277\n",
      "178.0    226\n",
      "183.0    193\n",
      "181.0    181\n",
      "175.0    169\n",
      "182.0    165\n",
      "185.0    161\n",
      "176.0    154\n",
      "184.0    152\n",
      "179.0    137\n",
      "177.0    133\n",
      "174.0    129\n",
      "173.0    120\n",
      "186.0    107\n",
      "190.0     97\n",
      "170.0     90\n",
      "187.0     85\n",
      "172.0     80\n",
      "188.0     77\n",
      "171.0     67\n",
      "189.0     48\n",
      "169.0     46\n",
      "191.0     37\n",
      "192.0     34\n",
      "168.0     24\n",
      "167.0     23\n",
      "193.0     22\n",
      "164.0     20\n",
      "194.0     17\n",
      "195.0     13\n",
      "165.0     13\n",
      "196.0      7\n",
      "197.0      6\n",
      "166.0      6\n",
      "198.0      4\n",
      "160.0      4\n",
      "162.0      3\n",
      "159.0      3\n",
      "161.0      2\n",
      "199.0      2\n",
      "163.0      2\n",
      "154.0      1\n",
      "204.0      1\n",
      "155.0      1\n",
      "158.0      1\n",
      "202.0      1\n",
      "157.0      1\n",
      "200.0      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in height column: ' + str(dataset['height'].isnull().sum())\n",
    "        + ' (' + str(round(dataset['height'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in height column:')\n",
    "height_counts = dataset['height'].value_counts()\n",
    "print(height_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, but a lot of null values. Also, we see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the races where the `height` value is small or large, for possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3143.000000\n",
       "mean      179.815145\n",
       "std         6.443447\n",
       "min       154.000000\n",
       "25%       175.000000\n",
       "50%       180.000000\n",
       "75%       184.000000\n",
       "max       204.000000\n",
       "Name: height, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset info, for 'height' column\n",
    "dataset['height'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heights are between 154 and 204 cm, so we can say that no extreme values are present (in the cyclism context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'nationality' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `nationality` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in nationality column: 1 (0.02%)\n",
      "\n",
      "Count occurrences of each value in nationality column:\n",
      "nationality\n",
      "Italy                 1029\n",
      "Spain                  872\n",
      "Belgium                869\n",
      "France                 741\n",
      "Netherlands            380\n",
      "                      ... \n",
      "Dominican Republic       1\n",
      "Liechtenstein            1\n",
      "Zimbabwe                 1\n",
      "Puerto Rico              1\n",
      "Hongkong                 1\n",
      "Name: count, Length: 72, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in nationality column: ' + str(dataset['nationality'].isnull().sum())\n",
    "        + ' (' + str(round(dataset['nationality'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in nationality column:')\n",
    "nationality_counts = dataset['nationality'].value_counts()\n",
    "print(nationality_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, and just one null value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block we check if there are `nationality` values that contains any character that is a letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with numbers in nationality: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are 'nationality' values that contains any number, without the null values\n",
    "invalid_rows = dataset[dataset['nationality'].notnull() & dataset['nationality'].str.contains(r'\\d')]\n",
    "\n",
    "print('Number of rows with numbers in nationality: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks of races data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload allows the notebook to dynamically load code: if we update some helper functions *outside* of the notebook, we do not need to reload the notebook.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset from a CSV file and display the first few rows to get an initial understanding of the data. This helps us verify that the data has been loaded correctly and gives us a glimpse of its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url</th>\n",
       "      <th>name</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>length</th>\n",
       "      <th>climb_total</th>\n",
       "      <th>profile</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>is_tarmac</th>\n",
       "      <th>is_cobbled</th>\n",
       "      <th>is_gravel</th>\n",
       "      <th>cyclist_team</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>0</td>\n",
       "      <td>sean-kelly</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>vini-ricordi-pinarello-sidermec-1986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>1</td>\n",
       "      <td>gerrie-knetemann</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>norway-1987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>2</td>\n",
       "      <td>rene-bittinger</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>3</td>\n",
       "      <td>joseph-bruyere</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>navigare-blue-storm-1993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>4</td>\n",
       "      <td>sven-ake-nilsson</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>spain-1991</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _url            name  points  uci_points    length  \\\n",
       "0  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "1  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "2  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "3  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "4  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "\n",
       "   climb_total  profile  startlist_quality  average_temperature  \\\n",
       "0       1101.0      1.0               1241                  NaN   \n",
       "1       1101.0      1.0               1241                  NaN   \n",
       "2       1101.0      1.0               1241                  NaN   \n",
       "3       1101.0      1.0               1241                  NaN   \n",
       "4       1101.0      1.0               1241                  NaN   \n",
       "\n",
       "                  date  position           cyclist  cyclist_age  is_tarmac  \\\n",
       "0  1978-07-05 04:02:24         0        sean-kelly         22.0       True   \n",
       "1  1978-07-05 04:02:24         1  gerrie-knetemann         27.0       True   \n",
       "2  1978-07-05 04:02:24         2    rene-bittinger         24.0       True   \n",
       "3  1978-07-05 04:02:24         3    joseph-bruyere         30.0       True   \n",
       "4  1978-07-05 04:02:24         4  sven-ake-nilsson         27.0       True   \n",
       "\n",
       "   is_cobbled  is_gravel                          cyclist_team  delta  \n",
       "0       False      False  vini-ricordi-pinarello-sidermec-1986    0.0  \n",
       "1       False      False                           norway-1987    0.0  \n",
       "2       False      False                                   NaN    0.0  \n",
       "3       False      False              navigare-blue-storm-1993    0.0  \n",
       "4       False      False                            spain-1991    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_file = \"../data/races.csv\"\n",
    "dataset = pd.read_csv(csv_file)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset without the personal information of the cyclists, taking only one row per race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url</th>\n",
       "      <th>name</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>length</th>\n",
       "      <th>climb_total</th>\n",
       "      <th>profile</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>date</th>\n",
       "      <th>is_tarmac</th>\n",
       "      <th>is_cobbled</th>\n",
       "      <th>is_gravel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>vuelta-a-espana/2016/stage-14</td>\n",
       "      <td>Vuelta a España</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tour-de-france/2019/stage-21</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-28</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>volta-a-catalunya/1999/prologue</td>\n",
       "      <td>Volta Ciclista a Catalunya</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-06-17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>tour-de-france/2022/stage-9</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>192900.0</td>\n",
       "      <td>3743.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1551</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                _url                        name  points  \\\n",
       "0        tour-de-france/1978/stage-6              Tour de France   100.0   \n",
       "106    vuelta-a-espana/2016/stage-14             Vuelta a España    80.0   \n",
       "271     tour-de-france/2019/stage-21              Tour de France   100.0   \n",
       "426  volta-a-catalunya/1999/prologue  Volta Ciclista a Catalunya    50.0   \n",
       "545      tour-de-france/2022/stage-9              Tour de France   100.0   \n",
       "\n",
       "     uci_points    length  climb_total  profile  startlist_quality  \\\n",
       "0           NaN  162000.0       1101.0      1.0               1241   \n",
       "106       100.0  196000.0       5575.0      5.0                821   \n",
       "271       120.0  128000.0        781.0      1.0               1699   \n",
       "426         NaN    8100.0          NaN      NaN                804   \n",
       "545       120.0  192900.0       3743.0      3.0               1551   \n",
       "\n",
       "     average_temperature        date  is_tarmac  is_cobbled  is_gravel  \n",
       "0                    NaN  1978-07-05       True       False      False  \n",
       "106                  NaN  2016-09-03       True       False      False  \n",
       "271                  NaN  2019-07-28       True       False      False  \n",
       "426                  NaN  1999-06-17       True       False      False  \n",
       "545                 24.0  2022-07-10       True       False      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Delete 'position', 'cyclist', 'cyclist_age', 'cyclist_team' and 'delta' columns\n",
    "races_info = dataset.drop(columns=['position', 'cyclist', 'cyclist_age', 'cyclist_team', 'delta'])\n",
    "\n",
    "# For each row in 'races_info', take only the year-month-day part of 'date' (delete the time)\n",
    "races_info['date'] = races_info['date'].str.split(' ').str[0]\n",
    "\n",
    "# Eliminate duplicates\n",
    "races_info = races_info.drop_duplicates()\n",
    "\n",
    "# Display the first rows of the dataset\n",
    "races_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset from the union of the cyclists and the races data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url_cyclist</th>\n",
       "      <th>name_cyclist</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>nationality</th>\n",
       "      <th>_url_race</th>\n",
       "      <th>name_race</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>...</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>is_tarmac</th>\n",
       "      <th>is_cobbled</th>\n",
       "      <th>is_gravel</th>\n",
       "      <th>cyclist_team</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bruno-surra</td>\n",
       "      <td>Bruno  Surra</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>vuelta-a-espana/1989/stage-1</td>\n",
       "      <td>Vuelta a España</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-04-24</td>\n",
       "      <td>110</td>\n",
       "      <td>bruno-surra</td>\n",
       "      <td>25.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>Gérard  Rué</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>France</td>\n",
       "      <td>tour-de-france/1997/stage-2</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-07-07</td>\n",
       "      <td>132</td>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>32.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>denmark-1991</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>Gérard  Rué</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>France</td>\n",
       "      <td>tour-de-france/1990/stage-1</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-07-01</td>\n",
       "      <td>66</td>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>25.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>france-1978</td>\n",
       "      <td>635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>Gérard  Rué</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>France</td>\n",
       "      <td>tour-de-france/1992/stage-7</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992-07-11</td>\n",
       "      <td>35</td>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>france-1978</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>Gérard  Rué</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>France</td>\n",
       "      <td>tour-de-france/1990/stage-9</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-07-09</td>\n",
       "      <td>41</td>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>25.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>france-1978</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  _url_cyclist  name_cyclist  birth_year  weight  height nationality  \\\n",
       "0  bruno-surra  Bruno  Surra      1964.0     NaN     NaN       Italy   \n",
       "1   gerard-rue   Gérard  Rué      1965.0    74.0   182.0      France   \n",
       "2   gerard-rue   Gérard  Rué      1965.0    74.0   182.0      France   \n",
       "3   gerard-rue   Gérard  Rué      1965.0    74.0   182.0      France   \n",
       "4   gerard-rue   Gérard  Rué      1965.0    74.0   182.0      France   \n",
       "\n",
       "                      _url_race        name_race  points  uci_points  ...  \\\n",
       "0  vuelta-a-espana/1989/stage-1  Vuelta a España    80.0         NaN  ...   \n",
       "1   tour-de-france/1997/stage-2   Tour de France   100.0         NaN  ...   \n",
       "2   tour-de-france/1990/stage-1   Tour de France   100.0         NaN  ...   \n",
       "3   tour-de-france/1992/stage-7   Tour de France   100.0         NaN  ...   \n",
       "4   tour-de-france/1990/stage-9   Tour de France   100.0         NaN  ...   \n",
       "\n",
       "   average_temperature        date  position      cyclist  cyclist_age  \\\n",
       "0                  NaN  1989-04-24       110  bruno-surra         25.0   \n",
       "1                  NaN  1997-07-07       132   gerard-rue         32.0   \n",
       "2                  NaN  1990-07-01        66   gerard-rue         25.0   \n",
       "3                  NaN  1992-07-11        35   gerard-rue         27.0   \n",
       "4                  NaN  1990-07-09        41   gerard-rue         25.0   \n",
       "\n",
       "  is_tarmac  is_cobbled is_gravel  cyclist_team  delta  \n",
       "0      True       False     False           NaN   15.0  \n",
       "1      True       False     False  denmark-1991    0.0  \n",
       "2      True       False     False   france-1978  635.0  \n",
       "3      True       False     False   france-1978   65.0  \n",
       "4      True       False     False   france-1978   37.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create union of two datasets, merging them considering the url of the cyclist\n",
    "dataset_cyclists = pd.read_csv(\"../data/cyclists.csv\")\n",
    "dataset_races = pd.read_csv(\"../data/races.csv\")\n",
    "merged_dataset = pd.merge(dataset_cyclists, dataset_races, left_on='_url', right_on='cyclist', how='inner')\n",
    "\n",
    "# Modify name column of the cyclist url in '_url_cyclist', and name column of the race url in '_url_race'\n",
    "merged_dataset = merged_dataset.rename(columns={'_url_x': '_url_cyclist', '_url_y': '_url_race'})\n",
    "# Modify name column of the cyclist name in 'name_cyclist', and name column of the race name in 'name_race'\n",
    "merged_dataset = merged_dataset.rename(columns={'name_x': 'name_cyclist', 'name_y': 'name_race'})\n",
    "# Take only the year-month-day part of 'date' (delete the time)\n",
    "merged_dataset['date'] = merged_dataset['date'].str.split(' ').str[0]\n",
    "\n",
    "merged_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we provide a concise summary of the DataFrame, including the number of non-null entries, data types of each column, and memory usage. It helps us quickly identify missing values and understand the overall structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589865 entries, 0 to 589864\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   _url                 589865 non-null  object \n",
      " 1   name                 589865 non-null  object \n",
      " 2   points               589388 non-null  float64\n",
      " 3   uci_points           251086 non-null  float64\n",
      " 4   length               589865 non-null  float64\n",
      " 5   climb_total          442820 non-null  float64\n",
      " 6   profile              441671 non-null  float64\n",
      " 7   startlist_quality    589865 non-null  int64  \n",
      " 8   average_temperature  29933 non-null   float64\n",
      " 9   date                 589865 non-null  object \n",
      " 10  position             589865 non-null  int64  \n",
      " 11  cyclist              589865 non-null  object \n",
      " 12  cyclist_age          589752 non-null  float64\n",
      " 13  is_tarmac            589865 non-null  bool   \n",
      " 14  is_cobbled           589865 non-null  bool   \n",
      " 15  is_gravel            589865 non-null  bool   \n",
      " 16  cyclist_team         430704 non-null  object \n",
      " 17  delta                589865 non-null  float64\n",
      "dtypes: bool(3), float64(8), int64(2), object(5)\n",
      "memory usage: 69.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we generates a descriptive statistics for numerical columns in the DataFrame. It includes metrics such as count, mean, standard deviation, minimum, and maximum values, as well as the 25th, 50th, and 75th percentiles. This summary helps us understand the distribution and central tendency of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>length</th>\n",
       "      <th>climb_total</th>\n",
       "      <th>profile</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>589388.000000</td>\n",
       "      <td>251086.000000</td>\n",
       "      <td>589865.000000</td>\n",
       "      <td>442820.000000</td>\n",
       "      <td>441671.000000</td>\n",
       "      <td>589865.000000</td>\n",
       "      <td>29933.000000</td>\n",
       "      <td>589865.000000</td>\n",
       "      <td>589752.000000</td>\n",
       "      <td>589865.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89.221635</td>\n",
       "      <td>74.601547</td>\n",
       "      <td>166776.180584</td>\n",
       "      <td>2330.469215</td>\n",
       "      <td>2.611611</td>\n",
       "      <td>1101.161178</td>\n",
       "      <td>21.731768</td>\n",
       "      <td>74.219491</td>\n",
       "      <td>28.486208</td>\n",
       "      <td>418.292794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54.435330</td>\n",
       "      <td>100.947962</td>\n",
       "      <td>64545.605664</td>\n",
       "      <td>1375.710722</td>\n",
       "      <td>1.491741</td>\n",
       "      <td>380.586928</td>\n",
       "      <td>5.884761</td>\n",
       "      <td>48.404023</td>\n",
       "      <td>3.855631</td>\n",
       "      <td>842.961596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-6906.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>152500.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>844.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>178200.000000</td>\n",
       "      <td>2255.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>203500.000000</td>\n",
       "      <td>3273.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>338000.000000</td>\n",
       "      <td>6974.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>61547.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              points     uci_points         length    climb_total  \\\n",
       "count  589388.000000  251086.000000  589865.000000  442820.000000   \n",
       "mean       89.221635      74.601547  166776.180584    2330.469215   \n",
       "std        54.435330     100.947962   64545.605664    1375.710722   \n",
       "min        18.000000       6.000000    1000.000000       2.000000   \n",
       "25%        50.000000      16.000000  152500.000000    1309.000000   \n",
       "50%        80.000000      60.000000  178200.000000    2255.000000   \n",
       "75%       100.000000     100.000000  203500.000000    3273.000000   \n",
       "max       350.000000     800.000000  338000.000000    6974.000000   \n",
       "\n",
       "             profile  startlist_quality  average_temperature       position  \\\n",
       "count  441671.000000      589865.000000         29933.000000  589865.000000   \n",
       "mean        2.611611        1101.161178            21.731768      74.219491   \n",
       "std         1.491741         380.586928             5.884761      48.404023   \n",
       "min         1.000000         115.000000            10.000000       0.000000   \n",
       "25%         1.000000         844.000000            17.000000      32.000000   \n",
       "50%         2.000000         988.000000            22.000000      70.000000   \n",
       "75%         4.000000        1309.000000            26.000000     112.000000   \n",
       "max         5.000000        2047.000000            36.000000     209.000000   \n",
       "\n",
       "         cyclist_age          delta  \n",
       "count  589752.000000  589865.000000  \n",
       "mean       28.486208     418.292794  \n",
       "std         3.855631     842.961596  \n",
       "min        13.000000   -6906.000000  \n",
       "25%        26.000000      10.000000  \n",
       "50%        28.000000     156.000000  \n",
       "75%        31.000000     624.000000  \n",
       "max        56.000000   61547.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on '_url' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start considering the `_url` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in _url column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in _url column:\n",
      "_url\n",
      "tour-de-france/1986/stage-1     210\n",
      "tour-de-france/1986/prologue    210\n",
      "tour-de-france/1987/prologue    207\n",
      "giro-d-italia/2011/stage-2      206\n",
      "tour-de-france/1987/stage-1     206\n",
      "                               ... \n",
      "il-lombardia/1972/result          1\n",
      "giro-d-italia/2001/stage-14       1\n",
      "tour-de-suisse/1972/stage-2       1\n",
      "tour-de-suisse/1972/stage-7       1\n",
      "tour-de-suisse/1972/stage-6b      1\n",
      "Name: count, Length: 5281, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in _url column: ' + str(dataset['_url'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['_url'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in _url column:')\n",
    "url_counts = dataset['_url'].value_counts()\n",
    "print(url_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lots of different values, but no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block we check if there are `_url` values that are not in the form name/year/stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid URLs: 0\n"
     ]
    }
   ],
   "source": [
    "# Split url by / in name, year and stage\n",
    "url_split = dataset['_url'].str.split('/', expand=True)\n",
    "# Check null elements in url_split[0], url_split[1] and url_split[2], and if url_split[1] contains only digits\n",
    "invalid_rows = dataset[url_split[0].isnull() | url_split[1].isnull() | url_split[2].isnull() | ~url_split[1].str.isdigit()]\n",
    "print('Number of invalid URLs: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_url\n",
      "tour-de-romandie/1992/stage-6     5\n",
      "dauphine/1983/prologue            5\n",
      "tour-de-romandie/1989/stage-1     5\n",
      "tirreno-adriatico/1996/stage-7    5\n",
      "volta-a-catalunya/1992/stage-2    5\n",
      "                                 ..\n",
      "il-lombardia/1972/result          1\n",
      "giro-d-italia/2001/stage-14       1\n",
      "tour-de-suisse/1972/stage-2       1\n",
      "tour-de-suisse/1972/stage-7       1\n",
      "tour-de-suisse/1972/stage-6b      1\n",
      "Name: count, Length: 146, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#TODO: Chiedere sulle gare dove ci sono un solo o pochi partecipanti\n",
    "\n",
    "url_counts = dataset['_url'].value_counts()\n",
    "\n",
    "# From url_counts, get the urls where the number of occurrence is less than 2\n",
    "print(url_counts[url_counts < 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'name' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `name` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in name column: 0 (0.0%)\n",
      "\n",
      "\n",
      "Count occurrences of each value in name column:\n",
      "name\n",
      "Tour de France                     145500\n",
      "Giro d'Italia                       95581\n",
      "Vuelta a España                     89222\n",
      "Tour de Suisse                      33682\n",
      "Paris - Nice                        32362\n",
      "                                    ...  \n",
      "E3 Saxo Classic                       101\n",
      "E3 BinckBank Classic                   99\n",
      "E3 Prijs Vlaanderen - Harelbeke        98\n",
      "Clásica Ciclista San Sebastian         84\n",
      "Clásica San Sebastián                  52\n",
      "Name: count, Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in name column: ' + str(dataset['name'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['name'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\n\\nCount occurrences of each value in name column:')\n",
    "name_counts = dataset['name'].value_counts()\n",
    "print(name_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, but no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's small, we print all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Amstel Gold Race', 'Clasica Ciclista San Sebastian',\n",
      "       'Clásica Ciclista San Sebastian', 'Clásica Ciclista San Sebastián',\n",
      "       'Clásica San Sebastián', 'Criterium du Dauphiné',\n",
      "       'Criterium du Dauphiné Libére', 'Critérium du Dauphiné',\n",
      "       'Critérium du Dauphiné Libéré', 'Donostia San Sebastian Klasikoa',\n",
      "       'Dwars door België / À travers la Belgique', 'Dwars door Vlaanderen',\n",
      "       'Dwars door Vlaanderen - A travers la Flandre ME',\n",
      "       'Dwars door Vlaanderen / A travers la Flandre',\n",
      "       'Dwars door Vlaanderen / A travers la Flandre ME',\n",
      "       'E3 BinckBank Classic', 'E3 Harelbeke', 'E3 Prijs Vlaanderen',\n",
      "       'E3 Prijs Vlaanderen - Harelbeke', 'E3 Saxo Bank Classic',\n",
      "       'E3 Saxo Classic', 'E3-Prijs Harelbeke', 'Giro d'Italia',\n",
      "       'Giro di Lombardia', 'Gran Camiño', 'Grand Prix Cycliste de Montréal',\n",
      "       'Grand Prix Cycliste de Quebec', 'Grand Prix Cycliste de Québec',\n",
      "       'Il Lombardia', 'Itzulia Basque Country', 'La Flèche Wallonne',\n",
      "       'La Vuelta ciclista a España', 'Liège - Bastogne - Liège',\n",
      "       'Liège-Bastogne-Liège', 'Milano-Sanremo', 'Monte Paschi Eroica',\n",
      "       'Montepaschi Strade Bianche - Eroica Toscana', 'O Gran Camiño',\n",
      "       'Omloop Het Nieuwsblad ME', 'Omloop Het Volk', 'Omloop Het Volk ME',\n",
      "       'Paris - Nice', 'Paris - Roubaix', 'Paris-Roubaix',\n",
      "       'Record Bank E3 Harelbeke',\n",
      "       'Ronde van Vlaanderen - Tour des Flandres ME',\n",
      "       'Ronde van Vlaanderen / Tour des Flandres',\n",
      "       'Ronde van Vlaanderen / Tour des Flandres ME', 'Strade Bianche',\n",
      "       'Tirreno-Adriatico', 'Tour de France', 'Tour de Romandie',\n",
      "       'Tour de Suisse', 'UAE Tour', 'Volta Ciclista a Catalunya',\n",
      "       'Volta a Catalunya', 'Vuelta Ciclista al País Vasco', 'Vuelta a España',\n",
      "       'Vuelta al País Vasco', 'World Championships - Road Race',\n",
      "       'World Championships ME - Road Race'],\n",
      "      dtype='object', name='name')\n"
     ]
    }
   ],
   "source": [
    "# Print all the names that appear, alphabetically ordered\n",
    "print(name_counts.index.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `name` values are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique name: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'name' column\n",
    "name_uniques = dataset.groupby('_url')['name'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique name\n",
    "multiple_names_urls = name_uniques[name_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique name: ' + str(len(multiple_names_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block we are checking if there are `name` values that contains any incorrect numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid names: 0\n"
     ]
    }
   ],
   "source": [
    "# Get rows wehere 'name' value contains any number, except for names containing 'E3' (there are some races with E3 in the name)\n",
    "invalid_rows = dataset[dataset['name'].str.contains(r'\\d') & ~dataset['name'].str.contains('E3')]\n",
    "print('Number of invalid names: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'points' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `point` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in points column: 477 (0.08%)\n",
      "\n",
      "Count occurrences of each value in points column:\n",
      "points\n",
      "80.0     198878\n",
      "50.0     186102\n",
      "100.0    141706\n",
      "275.0     22299\n",
      "225.0     19536\n",
      "125.0      5992\n",
      "30.0       4313\n",
      "350.0      3917\n",
      "70.0       3299\n",
      "75.0       1963\n",
      "20.0        792\n",
      "18.0        292\n",
      "35.0        183\n",
      "150.0       116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in points column: ' + str(dataset['points'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['points'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in points column:')\n",
    "point_counts = dataset['points'].value_counts()\n",
    "print(point_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not a lot of values, and few null values. Also, we see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `name` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique points: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'points' column\n",
    "points_uniques = dataset.groupby('_url')['points'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique points\n",
    "multiple_points_urls = points_uniques[points_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique points: ' + str(len(multiple_points_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the urls where `points` is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of urls with null points: 4\n",
      "\n",
      "URLs of the rows with null points:\n",
      "156755    vuelta-a-espana/1994/stage-5\n",
      "461300    tour-de-france/1986/stage-19\n",
      "517517    tour-de-france/1988/prologue\n",
      "561313    tour-de-france/2019/stage-19\n",
      "Name: _url, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get unique data based on '_url' and 'points'\n",
    "unique_data = dataset.drop_duplicates(subset=['_url', 'points'])\n",
    "# Get rows where 'points' is null\n",
    "rows = unique_data[unique_data['points'].isnull()]\n",
    "\n",
    "print('Number of urls with null points: ' + str(len(rows)))\n",
    "print('\\nURLs of the rows with null points:')\n",
    "print(rows['_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'uci_points' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `uci_points` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in uci_points column: 338779 (57.43%)\n",
      "\n",
      "Count occurrences of each value in uci_points column:\n",
      "uci_points\n",
      "100.0    47640\n",
      "6.0      43390\n",
      "16.0     41103\n",
      "60.0     39317\n",
      "20.0     21303\n",
      "120.0    20785\n",
      "50.0     13266\n",
      "500.0     6096\n",
      "40.0      4102\n",
      "210.0     3449\n",
      "180.0     3103\n",
      "400.0     2571\n",
      "300.0     2057\n",
      "14.0       792\n",
      "600.0      675\n",
      "800.0      514\n",
      "200.0      338\n",
      "80.0       328\n",
      "10.0       148\n",
      "402.0      109\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in uci_points column: ' + str(dataset['uci_points'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['uci_points'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in uci_points column:')\n",
    "uci_point_counts = dataset['uci_points'].value_counts()\n",
    "print(uci_point_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, but a lot of null values. Also, we see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `uci_points` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique uci_points: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'uci_points' column\n",
    "uci_points_uniques = dataset.groupby('_url')['uci_points'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique uci_points\n",
    "multiple_uci_points_urls = uci_points_uniques[uci_points_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique uci_points: ' + str(len(multiple_uci_points_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the urls where `uci_points` is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with null uci_points: 3682\n",
      "\n",
      "URLs of the rows with null uci_points:\n",
      "0             tour-de-france/1978/stage-6\n",
      "426       volta-a-catalunya/1999/prologue\n",
      "866          tour-de-france/1978/stage-14\n",
      "1075      volta-a-catalunya/1981/stage-2b\n",
      "1084             paris-nice/1994/stage-8b\n",
      "                       ...               \n",
      "588250              gp-quebec/2010/result\n",
      "588712       tour-de-france/1982/stage-21\n",
      "588837     tirreno-adriatico/1993/stage-3\n",
      "589397          paris-roubaix/2000/result\n",
      "589463            paris-nice/1976/stage-2\n",
      "Name: _url, Length: 3682, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get unique data based on '_url' and 'uci_points'\n",
    "unique_data = dataset.drop_duplicates(subset=['_url', 'uci_points'])\n",
    "# Get rows where 'uci_points' is null\n",
    "rows = unique_data[unique_data['uci_points'].isnull()]\n",
    "\n",
    "print('Number of rows with null uci_points: ' + str(len(rows)))\n",
    "print('\\nURLs of the rows with null uci_points:')\n",
    "print(rows['_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check rows where `point` is null but not `uci_point`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with null uci_points: 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique data based on '_url' and 'uci_points'\n",
    "unique_data = dataset.drop_duplicates(subset=['_url', 'uci_points'])\n",
    "# Get rows where 'uci_points' is not null, but 'points' is null\n",
    "rows = unique_data[unique_data['uci_points'].notnull() & unique_data['points'].isnull()]\n",
    "\n",
    "print('Number of rows with null uci_points: ' + str(len(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'length' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `length` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in length column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in length column:\n",
      "length\n",
      "177000.0    5039\n",
      "170000.0    4717\n",
      "195000.0    4413\n",
      "200000.0    4401\n",
      "178000.0    4286\n",
      "            ... \n",
      "4500.0         5\n",
      "107000.0       5\n",
      "123100.0       5\n",
      "142700.0       5\n",
      "2000.0         3\n",
      "Name: count, Length: 1280, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in length column: ' + str(dataset['length'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['length'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in length column:')\n",
    "length_counts = dataset['length'].value_counts()\n",
    "print(length_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of values, but no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `length` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique length: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'length' column\n",
    "length_uniques = dataset.groupby('_url')['length'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique length\n",
    "multiple_length_urls = length_uniques[length_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique length: ' + str(len(multiple_length_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of values, we check if every value is sintatically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that every value is a digit\n",
    "dataset['length'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid lengths: 954\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "tour-de-suisse/1992/stage-4 32200.000000000004\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "amstel-gold-race/2009/result 258600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "paris-roubaix/2023/result 256600.00000000003\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "tour-de-romandie/2021/stage-5 16190.000000000002\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "liege-bastogne-liege/2021/result 259100.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "world-championship/1993/result 257600.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "ronde-van-vlaanderen/2014/result 259100.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "world-championship/1992/result 261600.00000000003\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "volta-a-catalunya/1970/stage-7b 32200.000000000004\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "world-championship/1989/result 259350.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n",
      "liege-bastogne-liege/2023/result 258100.00000000003\n"
     ]
    }
   ],
   "source": [
    "# Get rows where 'length' does not end with '.0'\n",
    "invalid_rows = dataset[~dataset['length'].astype(str).str.endswith('.0')]\n",
    "                                \n",
    "print('Number of invalid lengths: ' + str(len(invalid_rows)))\n",
    "for index, row in invalid_rows.iterrows():\n",
    "    print(row['_url'], row['length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the races where the `length` value is small or large, for possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    589865.000000\n",
       "mean     166776.180584\n",
       "std       64545.605664\n",
       "min        1000.000000\n",
       "25%      152500.000000\n",
       "50%      178200.000000\n",
       "75%      203500.000000\n",
       "max      338000.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset info, for 'length' column\n",
    "dataset['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lenghts are between 1000 and 338000 m, so we can say that no extreme values are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'climb_total' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `climb_total` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in climb_total column: 147045 (24.93%)\n",
      "\n",
      "Count occurrences of each value in climb_total column:\n",
      "climb_total\n",
      "3500.0    3762\n",
      "2500.0    3261\n",
      "4000.0    3029\n",
      "3000.0    2938\n",
      "5000.0    2592\n",
      "          ... \n",
      "3742.0       9\n",
      "2525.0       9\n",
      "1176.0       8\n",
      "1903.0       5\n",
      "3128.0       1\n",
      "Name: count, Length: 2117, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in climb_total column: ' + str(dataset['climb_total'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['climb_total'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in climb_total column:')\n",
    "climb_total_counts = dataset['climb_total'].value_counts()\n",
    "print(climb_total_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of different values, and a lot of null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `climb_total` values are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique climb_total: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'climb_total' column\n",
    "climb_total_uniques = dataset.groupby('_url')['climb_total'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique climb_total\n",
    "multiple_climb_total_urls = climb_total_uniques[climb_total_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique climb_total: ' + str(len(multiple_climb_total_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that every value is a digit\n",
    "dataset['climb_total'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid climb_total: 0\n"
     ]
    }
   ],
   "source": [
    "# Get rows where 'climb_total' does not end with '.0'\n",
    "invalid_rows = dataset[~dataset['climb_total'].astype(str).str.endswith('.0')].dropna(subset=['climb_total'])\n",
    "\n",
    "print('Number of invalid climb_total: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the races where the `climb_total` value is small or large, for possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    442820.000000\n",
       "mean       2330.469215\n",
       "std        1375.710722\n",
       "min           2.000000\n",
       "25%        1309.000000\n",
       "50%        2255.000000\n",
       "75%        3273.000000\n",
       "max        6974.000000\n",
       "Name: climb_total, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset info, for 'climb_total' column\n",
    "dataset['climb_total'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The climb values are between 2 and 6974 m, so we can say that no extreme values are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'profile' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `profile` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in profile column: 148194 (25.12%)\n",
      "\n",
      "Count occurrences of each value in profile column:\n",
      "profile\n",
      "1.0    131344\n",
      "2.0    128269\n",
      "5.0     88203\n",
      "3.0     50844\n",
      "4.0     43011\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in profile column: ' + str(dataset['profile'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['profile'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in profile column:')\n",
    "profile_counts = dataset['profile'].value_counts()\n",
    "print(profile_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have few different values, but a lot of null values. Also, we see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `profile` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique profile: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'profile' column\n",
    "profile_uniques = dataset.groupby('_url')['profile'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique profile\n",
    "multiple_profile_urls = profile_uniques[profile_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique profile: ' + str(len(multiple_profile_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'startlist_quality' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `startlist_quality` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in startlist_quality column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in startlist_quality column:\n",
      "startlist_quality\n",
      "971     8279\n",
      "1812    7807\n",
      "1872    7317\n",
      "1612    7255\n",
      "920     6715\n",
      "        ... \n",
      "455        5\n",
      "438        5\n",
      "394        5\n",
      "228        3\n",
      "544        3\n",
      "Name: count, Length: 697, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in startlist_quality column: ' + str(dataset['startlist_quality'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['startlist_quality'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in startlist_quality column:')\n",
    "startlist_quality_counts = dataset['startlist_quality'].value_counts()\n",
    "print(startlist_quality_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, but no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `startlist_quality` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique startlist_quality: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'startlist_quality' column\n",
    "startlist_quality_uniques = dataset.groupby('_url')['startlist_quality'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique startlist_quality\n",
    "multiple_startlist_quality_urls = startlist_quality_uniques[startlist_quality_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique startlist_quality: ' + str(len(multiple_startlist_quality_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that every value is a digit\n",
    "dataset['startlist_quality'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'average_temperature' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `average_temperature` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in average_temperature column: 559932 (94.93%)\n",
      "\n",
      "Count occurrences of each value in average_temperature column:\n",
      "average_temperature\n",
      "23.0    2343\n",
      "22.0    2099\n",
      "20.0    2055\n",
      "24.0    1829\n",
      "25.0    1789\n",
      "14.0    1499\n",
      "21.0    1463\n",
      "26.0    1440\n",
      "18.0    1435\n",
      "13.0    1386\n",
      "15.0    1295\n",
      "16.0    1213\n",
      "17.0    1170\n",
      "28.0    1149\n",
      "19.0    1080\n",
      "29.0    1038\n",
      "31.0    1026\n",
      "27.0     990\n",
      "30.0     769\n",
      "11.0     731\n",
      "32.0     730\n",
      "12.0     548\n",
      "36.0     265\n",
      "35.0     167\n",
      "33.0     165\n",
      "34.0     133\n",
      "10.0     126\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in average_temperature column: ' + str(dataset['average_temperature'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['average_temperature'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in average_temperature column:')\n",
    "average_temperature_counts = dataset['average_temperature'].value_counts()\n",
    "print(average_temperature_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, and almost all the values are null. Also, we cas see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `average_temperature` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique average_temperature: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'average_temperature' column\n",
    "average_temperature_uniques = dataset.groupby('_url')['average_temperature'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique average_temperature\n",
    "multiple_average_temperature_urls = average_temperature_uniques[average_temperature_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique average_temperature: ' + str(len(multiple_average_temperature_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'date' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `date` column, and check the number of null values and the count the occurrences of each unique value. We do this considerig the merged dataset where we don't have time value of the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in date column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in date column:\n",
      "date\n",
      "1998-06-18    407\n",
      "1987-07-05    404\n",
      "2006-05-15    379\n",
      "2006-05-16    377\n",
      "2023-02-25    376\n",
      "             ... \n",
      "1972-06-23      1\n",
      "1972-06-21      1\n",
      "1972-06-17      1\n",
      "1972-06-22      1\n",
      "2001-06-02      1\n",
      "Name: count, Length: 4708, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in date column: ' + str(merged_dataset['date'].isnull().sum())\n",
    "      + ' (' + str(round(merged_dataset['date'].isnull().sum() / len(merged_dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in date column:')\n",
    "date_counts = merged_dataset['date'].value_counts()\n",
    "print(date_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, but no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `date` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique date (format yyyy-mm-dd hh:mm:ss, in the races dataset): 4777\n",
      "Number of URLs with more than one unique date (format yyyy-mm-dd, in the merged dataset): 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'date' column\n",
    "date_uniques = dataset.groupby('_url')['date'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique date\n",
    "multiple_date_urls = date_uniques[date_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique date (format yyyy-mm-dd hh:mm:ss, in the races dataset): ' + str(len(multiple_date_urls)))\n",
    "\n",
    "# Group by '_url' and calculate the number of unique values in the 'date' column\n",
    "date_uniques = merged_dataset.groupby('_url_race')['date'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique date\n",
    "multiple_date_urls = date_uniques[date_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique date (format yyyy-mm-dd, in the merged dataset): ' + str(len(multiple_date_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid dates (format yyyy-mm-dd hh:mm:ss, in the races dataset): 0\n",
      "Number of invalid dates (format yyyy-mm-dd, in the merged dataset): 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any 'date' values in the format yyyy-mm-dd hh:mm:ss (in the races dataset)\n",
    "invalid_rows = dataset[~dataset['date'].str.match(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}')]\n",
    "print('Number of invalid dates (format yyyy-mm-dd hh:mm:ss, in the races dataset): ' + str(len(invalid_rows)))\n",
    "\n",
    "# Check if there are any 'date' values not in the format yyyy-mm-dd (in the merged dataset)\n",
    "invalid_rows = merged_dataset[~merged_dataset['date'].str.match(r'\\d{4}-\\d{2}-\\d{2}')]\n",
    "print('Number of invalid dates (format yyyy-mm-dd, in the merged dataset): ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the year is the same in both the `_url` and the `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where the year in the url does not match the year in the date: 0\n"
     ]
    }
   ],
   "source": [
    "# Split _url by / into name, year, and stage\n",
    "url_split = dataset['_url'].str.split('/', expand=True) # expand=True to return a DataFrame\n",
    "# Extract the year from the date column (assuming format yyyy-mm-dd hh:mm:ss)\n",
    "date_year = dataset['date'].str[:4]\n",
    "# Compare the year in the _url (from the second part of the split) with the year in the date\n",
    "mismatched_years = dataset[(url_split[1] != date_year)]\n",
    "\n",
    "# Print the number of rows where the year does not match\n",
    "print(f\"Number of rows where the year in the url does not match the year in the date: {len(mismatched_years)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'position' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `position` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in position column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in position column:\n",
      "position\n",
      "0      5281\n",
      "1      5275\n",
      "2      5273\n",
      "3      5267\n",
      "4      5255\n",
      "       ... \n",
      "205       5\n",
      "206       3\n",
      "207       2\n",
      "208       2\n",
      "209       2\n",
      "Name: count, Length: 210, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in position column: ' + str(dataset['position'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['position'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in position column:')\n",
    "position_counts = dataset['position'].value_counts()\n",
    "print(position_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, and no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that every value is a digit\n",
    "dataset['position'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if there are all the `position` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with invalid positions: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to check if the positions are from 0 to the max one after the other\n",
    "def check_positions(positions):\n",
    "    return np.array_equal(np.sort(positions), np.arange(positions.max() + 1))\n",
    "\n",
    "# Apply the function to the dataset\n",
    "invalid_urls = dataset.groupby('_url')['position'].apply(lambda x: not check_positions(x))\n",
    "\n",
    "# Stampa gli '_url' che non rispettano la condizione\n",
    "print('Number of URLs with invalid positions: ' + str(len(invalid_urls[invalid_urls])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'cyclist' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `cyclist` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in cyclist column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in cyclist column:\n",
      "cyclist\n",
      "matteo-tosatto         959\n",
      "alejandro-valverde     942\n",
      "luis-leon-sanchez      899\n",
      "imanol-erviti          883\n",
      "haimar-zubeldia        883\n",
      "                      ... \n",
      "timothy-vangheel         1\n",
      "matthias-friedemann      1\n",
      "stefan-rucker            1\n",
      "john-brouwer             1\n",
      "stijn-ennekens           1\n",
      "Name: count, Length: 6095, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in cyclist column: ' + str(dataset['cyclist'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['cyclist'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in cyclist column:')\n",
    "cyclist_counts = dataset['cyclist'].value_counts()\n",
    "print(cyclist_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lots of different values, but no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if all the cyclists are different in the same race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with a cyclist appearing more than once: 123\n",
      "URL: dauphine/2005/stage-1, Cyclist: ivan-gutierrez, Count: 2\n",
      "URL: dauphine/2005/stage-2, Cyclist: ivan-gutierrez, Count: 2\n",
      "URL: dauphine/2005/stage-3, Cyclist: ivan-gutierrez, Count: 2\n",
      "URL: dauphine/2005/stage-4, Cyclist: ivan-gutierrez, Count: 2\n",
      "URL: dauphine/2005/stage-5, Cyclist: ivan-gutierrez, Count: 2\n",
      "URL: dauphine/2005/stage-6, Cyclist: ivan-gutierrez, Count: 2\n",
      "URL: dauphine/2005/stage-7, Cyclist: ivan-gutierrez, Count: 2\n",
      "URL: dauphine/2012/stage-3, Cyclist: david-moncoutie, Count: 2\n",
      "URL: itzulia-basque-country/2000/stage-1, Cyclist: alberto-david-fernandez, Count: 2\n",
      "URL: itzulia-basque-country/2000/stage-2, Cyclist: alberto-david-fernandez, Count: 2\n",
      "URL: itzulia-basque-country/2000/stage-2, Cyclist: david-vazquez, Count: 2\n",
      "URL: itzulia-basque-country/2000/stage-2, Cyclist: miguel-angel-pena, Count: 2\n",
      "URL: itzulia-basque-country/2000/stage-3, Cyclist: miguel-angel-pena, Count: 2\n",
      "URL: itzulia-basque-country/2000/stage-4, Cyclist: miguel-angel-pena, Count: 3\n",
      "URL: itzulia-basque-country/2001/stage-5b, Cyclist: riccardo-forconi, Count: 2\n",
      "URL: la-fleche-wallone/2007/result, Cyclist: chris-anker-sorensen, Count: 2\n",
      "URL: liege-bastogne-liege/1989/result, Cyclist: luc-roosen, Count: 2\n",
      "URL: liege-bastogne-liege/1993/result, Cyclist: jose-roberto-sierra-aguerro, Count: 2\n",
      "URL: liege-bastogne-liege/1994/result, Cyclist: massimiliano-lelli, Count: 2\n",
      "URL: san-sebastian/1993/result, Cyclist: carlos-galarreta, Count: 2\n",
      "URL: san-sebastian/1993/result, Cyclist: javier-murguialday, Count: 2\n",
      "URL: san-sebastian/1998/result, Cyclist: leonardo-guidi, Count: 2\n",
      "URL: san-sebastian/2005/result, Cyclist: luis-perez-rodriguez, Count: 2\n",
      "URL: tirreno-adriatico/1998/stage-6, Cyclist: dario-pieri, Count: 2\n",
      "URL: tirreno-adriatico/2001/stage-3, Cyclist: andrea-noe, Count: 2\n",
      "URL: tour-de-france/1995/stage-11, Cyclist: fabian-jeker, Count: 2\n",
      "URL: tour-de-france/1995/stage-12, Cyclist: fabian-jeker, Count: 2\n",
      "URL: tour-de-france/1995/stage-14, Cyclist: fabian-jeker, Count: 2\n",
      "URL: tour-de-france/1995/stage-14, Cyclist: laudelino-cubino, Count: 2\n",
      "URL: tour-de-france/1995/stage-15, Cyclist: arsenio-gonzalez, Count: 2\n",
      "URL: tour-de-france/1995/stage-5, Cyclist: fabian-jeker, Count: 2\n",
      "URL: tour-de-france/1995/stage-7, Cyclist: fabian-jeker, Count: 3\n",
      "URL: tour-de-france/1995/stage-7, Cyclist: giovanni-fidanza, Count: 3\n",
      "URL: tour-de-france/1995/stage-7, Cyclist: alexander-gontsjenkov, Count: 2\n",
      "URL: tour-de-france/1995/stage-7, Cyclist: laudelino-cubino, Count: 2\n",
      "URL: tour-de-france/1995/stage-8, Cyclist: fabian-jeker, Count: 2\n",
      "URL: tour-de-france/1995/stage-9, Cyclist: fabian-jeker, Count: 2\n",
      "URL: tour-de-france/1999/stage-5, Cyclist: armin-meier, Count: 2\n",
      "URL: tour-de-france/1999/stage-6, Cyclist: armin-meier, Count: 2\n",
      "URL: tour-de-france/1999/stage-7, Cyclist: armin-meier, Count: 2\n",
      "URL: tour-de-romandie/1994/stage-4, Cyclist: marco-saligari, Count: 2\n",
      "URL: tour-de-romandie/1998/prologue, Cyclist: lukas-zumsteg, Count: 2\n",
      "URL: tour-de-romandie/1998/prologue, Cyclist: rik-verbrugghe, Count: 2\n",
      "URL: tour-de-romandie/1998/stage-2, Cyclist: claudio-chiappucci, Count: 2\n",
      "URL: tour-de-romandie/1998/stage-2, Cyclist: daniele-de-paoli, Count: 2\n",
      "URL: tour-de-romandie/1998/stage-2, Cyclist: francois-simon, Count: 2\n",
      "URL: tour-de-romandie/1998/stage-2, Cyclist: mario-scirea, Count: 2\n",
      "URL: tour-de-romandie/1998/stage-2, Cyclist: roland-muller, Count: 2\n",
      "URL: tour-de-suisse/1996/stage-3, Cyclist: olaf-ludwig, Count: 2\n",
      "URL: tour-de-suisse/1996/stage-4, Cyclist: olaf-ludwig, Count: 2\n",
      "URL: tour-de-suisse/1997/stage-3, Cyclist: daniel-paradis, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-1a, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-1b, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-2, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-3, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-4, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-5, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-6, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-7, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: volta-a-catalunya/1998/stage-8, Cyclist: jose-vicente-garcia-acosta, Count: 2\n",
      "URL: vuelta-a-espana/1980/stage-4, Cyclist: angel-lopez-del-alamo, Count: 2\n",
      "URL: vuelta-a-espana/1981/prologue, Cyclist: antonio-cabello, Count: 2\n",
      "URL: vuelta-a-espana/1981/prologue, Cyclist: jacques-van-meer, Count: 2\n",
      "URL: vuelta-a-espana/1981/prologue, Cyclist: jose-maria-yurrebaso, Count: 2\n",
      "URL: vuelta-a-espana/1981/stage-4, Cyclist: felix-perez, Count: 2\n",
      "URL: vuelta-a-espana/1982/stage-15b, Cyclist: maurice-van-heer, Count: 2\n",
      "URL: vuelta-a-espana/1982/stage-17, Cyclist: jaime-vilamajo, Count: 2\n",
      "URL: vuelta-a-espana/1982/stage-17, Cyclist: pierre-raymond-villemiane, Count: 2\n",
      "URL: vuelta-a-espana/1982/stage-17, Cyclist: sven-ake-nilsson, Count: 2\n",
      "URL: vuelta-a-espana/1983/prologue, Cyclist: alain-vigneron, Count: 2\n",
      "URL: vuelta-a-espana/1983/stage-12, Cyclist: alain-vigneron, Count: 2\n",
      "URL: vuelta-a-espana/1983/stage-13, Cyclist: eric-vanderaerden, Count: 2\n",
      "URL: vuelta-a-espana/1983/stage-14, Cyclist: eric-vanderaerden, Count: 2\n",
      "URL: vuelta-a-espana/1983/stage-15b, Cyclist: frits-van-bindsbergen, Count: 2\n",
      "URL: vuelta-a-espana/1983/stage-19, Cyclist: bernard-hinault, Count: 2\n",
      "URL: vuelta-a-espana/1983/stage-3, Cyclist: miguel-angel-iglesias, Count: 2\n",
      "URL: vuelta-a-espana/1983/stage-5, Cyclist: faustino-cueli, Count: 2\n",
      "URL: vuelta-a-espana/1984/stage-1, Cyclist: guy-gallopin, Count: 2\n",
      "URL: vuelta-a-espana/1984/stage-1, Cyclist: rafael-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1984/stage-11, Cyclist: rafael-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1984/stage-6, Cyclist: guy-gallopin, Count: 2\n",
      "URL: vuelta-a-espana/1984/stage-8, Cyclist: guy-gallopin, Count: 2\n",
      "URL: vuelta-a-espana/1984/stage-9, Cyclist: alberto-saronni, Count: 2\n",
      "URL: vuelta-a-espana/1984/stage-9, Cyclist: giuseppe-saronni, Count: 2\n",
      "URL: vuelta-a-espana/1985/stage-12, Cyclist: jose-luis-laguia, Count: 2\n",
      "URL: vuelta-a-espana/1985/stage-12, Cyclist: miguel-angel-iglesias, Count: 2\n",
      "URL: vuelta-a-espana/1985/stage-16, Cyclist: jean-claude-garde, Count: 2\n",
      "URL: vuelta-a-espana/1985/stage-3, Cyclist: jesus-suarez-cueva, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-10, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-11, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-13, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-15, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-16, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-17, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-18, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-18, Cyclist: johan-bruyneel, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-19, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-2, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-2, Cyclist: jose-luis-de-santos-arribas, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-20, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-21, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-3, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-4, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-5, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-6, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-7, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-8, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1993/stage-9, Cyclist: ignacio-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1995/prologue, Cyclist: jesus-montoya, Count: 2\n",
      "URL: vuelta-a-espana/1995/stage-1, Cyclist: jose-luis-santamaria, Count: 2\n",
      "URL: vuelta-a-espana/1996/stage-10, Cyclist: inaki-ayarzaguena-urkidi, Count: 2\n",
      "URL: vuelta-a-espana/1996/stage-10, Cyclist: manuel-rodriguez-305, Count: 2\n",
      "URL: vuelta-a-espana/1996/stage-12, Cyclist: inaki-ayarzaguena-urkidi, Count: 2\n",
      "URL: vuelta-a-espana/1996/stage-3, Cyclist: igor-gonzalez-de-galdeano, Count: 2\n",
      "URL: vuelta-a-espana/1996/stage-8, Cyclist: inaki-ayarzaguena-urkidi, Count: 2\n",
      "URL: vuelta-a-espana/1996/stage-9, Cyclist: jose-luis-rodriguez-garcia, Count: 2\n",
      "URL: vuelta-a-espana/1997/stage-10, Cyclist: eleuterio-anguita, Count: 2\n",
      "URL: vuelta-a-espana/1997/stage-2, Cyclist: eleuterio-anguita, Count: 2\n",
      "URL: vuelta-a-espana/1997/stage-3, Cyclist: eleuterio-anguita, Count: 2\n",
      "URL: vuelta-a-espana/1997/stage-5, Cyclist: eleuterio-anguita, Count: 2\n",
      "URL: vuelta-a-espana/1997/stage-6, Cyclist: eleuterio-anguita, Count: 2\n",
      "URL: vuelta-a-espana/1997/stage-7, Cyclist: eleuterio-anguita, Count: 2\n",
      "URL: vuelta-a-espana/1997/stage-9, Cyclist: eleuterio-anguita, Count: 2\n"
     ]
    }
   ],
   "source": [
    "# For each url, check if the a cyclist appears more than once\n",
    "url_cyclist_count = dataset.groupby('_url')['cyclist'].value_counts()\n",
    "invalid_entries = url_cyclist_count[url_cyclist_count > 1]\n",
    "\n",
    "print('Number of URLs with a cyclist appearing more than once: ' + str(len(invalid_entries.index.get_level_values(0))))\n",
    "\n",
    "# Estrai gli _url e i ciclisti che compaiono più volte\n",
    "for (url, cyclist), count in invalid_entries.items():\n",
    "    print(f\"URL: {url}, Cyclist: {cyclist}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the two datasets, we check if all the cyclists in cyclists.csv are in races.csv, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cyclists with no info: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any 'cyclist' values in the races dataset that are not in the cyclists dataset\n",
    "invalid_rows = dataset[~dataset['cyclist'].isin(dataset_cyclists['_url'])]\n",
    "\n",
    "print('Number of cyclists with no info: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cyclists that are not in any race: 39\n",
      "jean-michel-thilloy Jean-Michel  Thilloy\n",
      "gert-van-brabant Gert Van Brabant\n",
      "roman-bronis Roman  Broniš\n",
      "oleg-grishkine Oleg  Grishkine\n",
      "eddy-torrekens Eddy  Torrekens\n",
      "philipp-ludescher Philipp  Ludescher\n",
      "nicolas-liboreau Nicolas  Liboreau\n",
      "gino-primo Gino  Primo\n",
      "luca-braidot Luca  Braidot\n",
      "tanner-putt Tanner  Putt\n",
      "matteo-di-serafino Matteo Di Serafino\n",
      "jeanot-deriemaecker Jeanot  Deriemaecker\n",
      "dorian-de-maeght Dorian De Maeght\n",
      "martin-gilbert Martin  Gilbert\n",
      "eric-schoefs Eric  Schoefs\n",
      "silvere-ackermann Silvère  Ackermann\n",
      "franck-morelle Franck  Morelle\n",
      "christian-mager Christian  Mager\n",
      "rikkie-matthijssens Rikkie  Matthijssens\n",
      "marat-ganeev Marat  Ganeev\n",
      "bas-tietema Bas  Tietema\n",
      "mattia-viel Mattia  Viel\n",
      "hiroki-nishimura Hiroki  Nishimura\n",
      "christophe-premont Christophe  Premont\n",
      "kurt-van-landeghem Kurt van Landeghem\n",
      "lenaic-olivier Lénaïc  Olivier\n",
      "arturo-gravalos-lopez Arturo  Grávalos\n",
      "morten-hegreberg Morten  Hegreberg\n",
      "rik-claeys Rik  Claeys\n",
      "pascal-duez Pascal  Duez\n",
      "koen-hullebusch Koen Van Hullebusch\n",
      "olivier-matthys Olivier  Matthys\n",
      "gianluca-maggiore Gianluca  Maggiore\n",
      "raphael-pires Raphael  Pires\n",
      "flavio-cardoso Flavio Cardoso  Santos\n",
      "peter-spaenhoven Peter  Spaenhoven\n",
      "benjamin-levecot Benjamin  Levecot\n",
      "mattia-bevilacqua Mattia  Bevilacqua\n",
      "sergio-garcia-gonzalez Sergio  García González\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any '_url' values in the cyclists dataset that are not in the races dataset\n",
    "invalid_rows = dataset_cyclists[~dataset_cyclists['_url'].isin(dataset['cyclist'])]\n",
    "\n",
    "print('Number of cyclists that are not in any race: ' + str(len(invalid_rows)))\n",
    "for index, row in invalid_rows.iterrows():\n",
    "    print(row['_url'], row['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'cyclist_age' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `cyclist_age` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in cyclist_age column: 113 (0.02%)\n",
      "\n",
      "Count occurrences of each value in cyclist_age column:\n",
      "cyclist_age\n",
      "27.0    58897\n",
      "26.0    57921\n",
      "28.0    56213\n",
      "25.0    54346\n",
      "29.0    52616\n",
      "30.0    46860\n",
      "24.0    43252\n",
      "31.0    40827\n",
      "32.0    35063\n",
      "23.0    30009\n",
      "33.0    27972\n",
      "34.0    21965\n",
      "35.0    16413\n",
      "22.0    13531\n",
      "36.0    12111\n",
      "37.0     8141\n",
      "38.0     4703\n",
      "21.0     3733\n",
      "39.0     2470\n",
      "40.0     1127\n",
      "20.0      842\n",
      "41.0      307\n",
      "42.0      218\n",
      "43.0       96\n",
      "19.0       90\n",
      "45.0       16\n",
      "44.0       11\n",
      "56.0        1\n",
      "13.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in cyclist_age column: ' + str(dataset['cyclist_age'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['cyclist_age'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in cyclist_age column:')\n",
    "cyclist_age_counts = dataset['cyclist_age'].value_counts()\n",
    "print(cyclist_age_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, and just a few of null values. Also, we see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the races where the `cyclist_age` value is small or large, for possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    589752.000000\n",
       "mean         28.486208\n",
       "std           3.855631\n",
       "min          13.000000\n",
       "25%          26.000000\n",
       "50%          28.000000\n",
       "75%          31.000000\n",
       "max          56.000000\n",
       "Name: cyclist_age, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset info, for 'cyclist_age' column\n",
    "dataset['cyclist_age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ages are between 13 and 56 cm, so we can say that no extreme values are present (in the cyclism context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'is_tarmac' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `is_tarmac` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in is_tarmac column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in is_tarmac column:\n",
      "is_tarmac\n",
      "True     536042\n",
      "False     53823\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in is_tarmac column: ' + str(dataset['is_tarmac'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['is_tarmac'].isnull().sum() / len(dataset) * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in is_tarmac column:')\n",
    "is_tarmac_counts = dataset['is_tarmac'].value_counts()\n",
    "print(is_tarmac_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two different values, and no null values. Also, we see that every value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each url, check if all the `is_tarmac` values are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with more than one unique is_tarmac: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by '_url' and calculate the number of unique values in the 'is_tarmac' column\n",
    "is_tarmac_uniques = dataset.groupby('_url')['is_tarmac'].nunique(dropna=False)\n",
    "# Filter the URLs with more than one unique is_tarmac\n",
    "multiple_is_tarmac_urls = is_tarmac_uniques[is_tarmac_uniques > 1].index\n",
    "\n",
    "print('Number of URLs with more than one unique is_tarmac: ' + str(len(multiple_is_tarmac_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'is_cobbled' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `is_cobbled` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in is_cobbled column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in is_cobbled column:\n",
      "is_cobbled\n",
      "False    589865\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in is_cobbled column: ' + str(dataset['is_cobbled'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['is_cobbled'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in is_cobbled column:')\n",
    "is_cobbled_counts = dataset['is_cobbled'].value_counts()\n",
    "print(is_cobbled_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one value, and no null values. Also, we see that the value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'is_gravel' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `is_gravel` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in is_gravel column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in is_gravel column:\n",
      "is_gravel\n",
      "False    589865\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in is_gravel column: ' + str(dataset['is_gravel'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['is_gravel'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in is_gravel column:')\n",
    "is_gravel_counts = dataset['is_gravel'].value_counts()\n",
    "print(is_gravel_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one value, and no null values. Also, we see that the value is sintatically correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'cyclist_team' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `cyclist_team` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in cyclist_team column: 159161 (26.98%)\n",
      "\n",
      "Count occurrences of each value in cyclist_team column:\n",
      "cyclist_team\n",
      "liberty-seguros-wurth-team-2005     8869\n",
      "roompot-nederlandse-loterij-2018    8773\n",
      "chazal-vetta-mbk-1993               8094\n",
      "kondor-1979                         7895\n",
      "kazakhstan-2019                     7701\n",
      "                                    ... \n",
      "atala-ofmega-1988                   1259\n",
      "finland-2016                        1236\n",
      "south-africa-1993                   1174\n",
      "denmark-2003                         216\n",
      "quickstep-innergetic-2009              3\n",
      "Name: count, Length: 91, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print total number of null values in 'delta' column, and the percentage of null values (float with two decimal digits after the comma)\n",
    "print('Total number of null values in cyclist_team column: ' + str(dataset['cyclist_team'].isnull().sum())\n",
    "      + ' (' + str(round(dataset['cyclist_team'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in cyclist_team column:')\n",
    "cyclist_team_counts = dataset['cyclist_team'].value_counts()\n",
    "print(cyclist_team_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different values, and a lot of null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of different values, we check if every value is sintatically correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if every 'cyclist_team' value matches the required format\n",
    "invalid_teams = dataset[dataset['cyclist_team'].notnull() & ~dataset['cyclist_team'].astype(str).str.match(r'.+-\\d{4}')]\n",
    "\n",
    "print('Number of invalid rows: ' + str(len(invalid_teams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on 'delta' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the `delta` column, and check the number of null values and the count the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in delta column: 0 (0.0%)\n",
      "\n",
      "Count occurrences of each value in delta column:\n",
      "delta\n",
      "0.0       120546\n",
      "2.0         3700\n",
      "5.0         3353\n",
      "3.0         3178\n",
      "4.0         3036\n",
      "           ...  \n",
      "2453.0         1\n",
      "2357.0         1\n",
      "2889.0         1\n",
      "2718.0         1\n",
      "2527.0         1\n",
      "Name: count, Length: 2836, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total number of null values in delta column: ' + str(dataset['delta'].isnull().sum())\n",
    "        + ' (' + str(round(dataset['delta'].isnull().sum() / dataset.shape[0] * 100, 2)) + '%)')\n",
    "\n",
    "print('\\nCount occurrences of each value in delta column:')\n",
    "delta_counts = dataset['delta'].value_counts()\n",
    "print(delta_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lots of different values, but no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of different values, we check if every value is sintatically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that every value is a digit\n",
    "dataset['delta'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid deltas: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any 'delta' values that do not end with '.0'\n",
    "invalid_rows = dataset[~dataset['delta'].astype(str).str.endswith('.0')]\n",
    "\n",
    "print('Number of invalid deltas: ' + str(len(invalid_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative deltas: 86\n",
      "vuelta-a-espana/1992/stage-19 -2635.0\n",
      "vuelta-a-espana/1992/stage-19 -2638.0\n",
      "vuelta-a-espana/1992/stage-19 -2541.0\n",
      "vuelta-a-espana/1992/stage-19 -2542.0\n",
      "vuelta-a-espana/1992/stage-19 -2545.0\n",
      "vuelta-a-espana/1992/stage-19 -2546.0\n",
      "vuelta-a-espana/1992/stage-19 -2550.0\n",
      "vuelta-a-espana/1992/stage-19 -2560.0\n",
      "vuelta-a-espana/1992/stage-19 -2564.0\n",
      "vuelta-a-espana/1992/stage-19 -2567.0\n",
      "vuelta-a-espana/1992/stage-19 -2567.0\n",
      "vuelta-a-espana/1992/stage-19 -2574.0\n",
      "vuelta-a-espana/1992/stage-19 -2469.0\n",
      "vuelta-a-espana/1992/stage-19 -2473.0\n",
      "vuelta-a-espana/1992/stage-19 -2475.0\n",
      "vuelta-a-espana/1992/stage-19 -2477.0\n",
      "vuelta-a-espana/1992/stage-19 -2479.0\n",
      "vuelta-a-espana/1992/stage-19 -2481.0\n",
      "vuelta-a-espana/1992/stage-19 -2482.0\n",
      "vuelta-a-espana/1992/stage-19 -2485.0\n",
      "vuelta-a-espana/1992/stage-19 -2486.0\n",
      "vuelta-a-espana/1992/stage-19 -2486.0\n",
      "vuelta-a-espana/1992/stage-19 -2487.0\n",
      "vuelta-a-espana/1992/stage-19 -2500.0\n",
      "vuelta-a-espana/1992/stage-19 -2504.0\n",
      "vuelta-a-espana/1992/stage-19 -2505.0\n",
      "vuelta-a-espana/1992/stage-19 -2509.0\n",
      "vuelta-a-espana/1992/stage-19 -2510.0\n",
      "vuelta-a-espana/1992/stage-19 -2513.0\n",
      "vuelta-a-espana/1992/stage-19 -2514.0\n",
      "vuelta-a-espana/1992/stage-19 -2408.0\n",
      "vuelta-a-espana/1992/stage-19 -2410.0\n",
      "vuelta-a-espana/1992/stage-19 -2413.0\n",
      "vuelta-a-espana/1992/stage-19 -2413.0\n",
      "vuelta-a-espana/1992/stage-19 -2416.0\n",
      "vuelta-a-espana/1992/stage-19 -2419.0\n",
      "vuelta-a-espana/1992/stage-19 -2424.0\n",
      "vuelta-a-espana/1992/stage-19 -2424.0\n",
      "vuelta-a-espana/1992/stage-19 -2425.0\n",
      "vuelta-a-espana/1992/stage-19 -2425.0\n",
      "vuelta-a-espana/1992/stage-19 -2428.0\n",
      "vuelta-a-espana/1992/stage-19 -2430.0\n",
      "vuelta-a-espana/1992/stage-19 -2432.0\n",
      "vuelta-a-espana/1992/stage-19 -2434.0\n",
      "vuelta-a-espana/1992/stage-19 -2437.0\n",
      "vuelta-a-espana/1992/stage-19 -2438.0\n",
      "vuelta-a-espana/1992/stage-19 -2440.0\n",
      "vuelta-a-espana/1992/stage-19 -2444.0\n",
      "vuelta-a-espana/1992/stage-19 -2446.0\n",
      "vuelta-a-espana/1992/stage-19 -2448.0\n",
      "vuelta-a-espana/1992/stage-19 -2391.0\n",
      "vuelta-a-espana/1992/stage-19 -2457.0\n",
      "vuelta-a-espana/1992/stage-19 -2345.0\n",
      "vuelta-a-espana/1992/stage-19 -2346.0\n",
      "vuelta-a-espana/1992/stage-19 -2348.0\n",
      "vuelta-a-espana/1992/stage-19 -2348.0\n",
      "vuelta-a-espana/1992/stage-19 -2349.0\n",
      "vuelta-a-espana/1992/stage-19 -2352.0\n",
      "vuelta-a-espana/1992/stage-19 -2353.0\n",
      "vuelta-a-espana/1992/stage-19 -2353.0\n",
      "vuelta-a-espana/1992/stage-19 -2355.0\n",
      "vuelta-a-espana/1992/stage-19 -2356.0\n",
      "vuelta-a-espana/1992/stage-19 -2356.0\n",
      "vuelta-a-espana/1992/stage-19 -2358.0\n",
      "vuelta-a-espana/1992/stage-19 -2359.0\n",
      "vuelta-a-espana/1992/stage-19 -2365.0\n",
      "vuelta-a-espana/1992/stage-19 -2365.0\n",
      "vuelta-a-espana/1992/stage-19 -2367.0\n",
      "vuelta-a-espana/1992/stage-19 -2378.0\n",
      "vuelta-a-espana/1992/stage-19 -2384.0\n",
      "vuelta-a-espana/1992/stage-19 -2385.0\n",
      "vuelta-a-espana/1992/stage-19 -2391.0\n",
      "vuelta-a-espana/1992/stage-19 -2393.0\n",
      "vuelta-a-espana/1992/stage-19 -2394.0\n",
      "vuelta-a-espana/1992/stage-19 -2397.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -5562.0\n",
      "paris-nice/1990/stage-7a -6906.0\n",
      "tour-de-france/2003/stage-12 -2937.0\n",
      "tour-de-suisse/1993/stage-4 -106.0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any 'delta' values that are negative\n",
    "invalid_rows = dataset[dataset['delta'] < 0]\n",
    "\n",
    "print('Number of negative deltas: ' + str(len(invalid_rows)))\n",
    "for index, row in invalid_rows.iterrows():\n",
    "    print(row['_url'], row['delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if following the `positon` order, the delta is ordered too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with invalid deltas: 346\n",
      "dauphine/2006/stage-2\n",
      "dauphine/2007/stage-7\n",
      "dauphine/2008/stage-2\n",
      "dauphine/2008/stage-3\n",
      "dauphine/2008/stage-6\n",
      "dauphine/2008/stage-7\n",
      "dauphine/2009/stage-4\n",
      "dauphine/2009/stage-6\n",
      "dauphine/2011/stage-2\n",
      "dauphine/2015/stage-2\n",
      "dauphine/2016/stage-4\n",
      "dauphine/2017/stage-1\n",
      "dauphine/2022/stage-1\n",
      "dauphine/2022/stage-2\n",
      "dauphine/2023/stage-1\n",
      "dauphine/2023/stage-3\n",
      "dauphine/2023/stage-5\n",
      "dwars-door-vlaanderen/2003/result\n",
      "e3-harelbeke/1976/result\n",
      "e3-harelbeke/2023/result\n",
      "giro-d-italia/1991/stage-10\n",
      "giro-d-italia/1992/stage-3\n",
      "giro-d-italia/1994/stage-8\n",
      "giro-d-italia/1995/stage-14\n",
      "giro-d-italia/1995/stage-17\n",
      "giro-d-italia/1995/stage-5\n",
      "giro-d-italia/1995/stage-8\n",
      "giro-d-italia/1997/stage-13\n",
      "giro-d-italia/1997/stage-3\n",
      "giro-d-italia/1999/stage-7\n",
      "giro-d-italia/2002/stage-2\n",
      "giro-d-italia/2002/stage-3\n",
      "giro-d-italia/2002/stage-4\n",
      "giro-d-italia/2003/stage-1\n",
      "giro-d-italia/2005/prologue\n",
      "giro-d-italia/2005/stage-1\n",
      "giro-d-italia/2005/stage-15\n",
      "giro-d-italia/2005/stage-2\n",
      "giro-d-italia/2005/stage-3\n",
      "giro-d-italia/2005/stage-4\n",
      "giro-d-italia/2005/stage-5\n",
      "giro-d-italia/2005/stage-7\n",
      "giro-d-italia/2007/stage-4\n",
      "giro-d-italia/2008/stage-13\n",
      "giro-d-italia/2008/stage-18\n",
      "giro-d-italia/2008/stage-19\n",
      "giro-d-italia/2008/stage-2\n",
      "giro-d-italia/2008/stage-4\n",
      "giro-d-italia/2008/stage-5\n",
      "giro-d-italia/2008/stage-9\n",
      "giro-d-italia/2009/stage-12\n",
      "giro-d-italia/2009/stage-21\n",
      "giro-d-italia/2009/stage-7\n",
      "giro-d-italia/2010/stage-10\n",
      "giro-d-italia/2011/stage-8\n",
      "giro-d-italia/2011/stage-9\n",
      "giro-d-italia/2012/stage-3\n",
      "giro-d-italia/2013/stage-1\n",
      "giro-d-italia/2013/stage-12\n",
      "giro-d-italia/2013/stage-16\n",
      "giro-d-italia/2013/stage-17\n",
      "giro-d-italia/2013/stage-3\n",
      "giro-d-italia/2013/stage-5\n",
      "giro-d-italia/2014/stage-10\n",
      "giro-d-italia/2014/stage-14\n",
      "giro-d-italia/2014/stage-4\n",
      "giro-d-italia/2014/stage-5\n",
      "giro-d-italia/2014/stage-7\n",
      "giro-d-italia/2014/stage-9\n",
      "giro-d-italia/2015/stage-13\n",
      "giro-d-italia/2015/stage-2\n",
      "giro-d-italia/2015/stage-21\n",
      "giro-d-italia/2015/stage-6\n",
      "giro-d-italia/2016/stage-12\n",
      "giro-d-italia/2016/stage-17\n",
      "giro-d-italia/2016/stage-5\n",
      "giro-d-italia/2017/stage-7\n",
      "giro-d-italia/2017/stage-8\n",
      "giro-d-italia/2019/stage-10\n",
      "giro-d-italia/2019/stage-11\n",
      "giro-d-italia/2019/stage-2\n",
      "giro-d-italia/2019/stage-5\n",
      "giro-d-italia/2020/stage-4\n",
      "giro-d-italia/2020/stage-6\n",
      "giro-d-italia/2021/stage-7\n",
      "giro-d-italia/2022/stage-18\n",
      "giro-d-italia/2022/stage-5\n",
      "giro-d-italia/2023/stage-21\n",
      "giro-d-italia/2023/stage-5\n",
      "gp-quebec/2011/result\n",
      "itzulia-basque-country/1998/stage-1\n",
      "itzulia-basque-country/1998/stage-2\n",
      "itzulia-basque-country/2003/stage-4\n",
      "itzulia-basque-country/2006/stage-4\n",
      "itzulia-basque-country/2012/stage-2\n",
      "itzulia-basque-country/2013/stage-2\n",
      "itzulia-basque-country/2015/stage-1\n",
      "itzulia-basque-country/2017/stage-1\n",
      "itzulia-basque-country/2017/stage-4\n",
      "itzulia-basque-country/2019/stage-4\n",
      "itzulia-basque-country/2022/stage-2\n",
      "itzulia-basque-country/2022/stage-3\n",
      "la-fleche-wallone/1979/result\n",
      "la-fleche-wallone/1986/result\n",
      "la-fleche-wallone/1995/result\n",
      "la-fleche-wallone/1996/result\n",
      "la-fleche-wallone/1997/result\n",
      "paris-nice/1990/stage-7a\n",
      "paris-nice/2000/stage-3\n",
      "paris-nice/2000/stage-5\n",
      "paris-nice/2002/stage-3\n",
      "paris-nice/2002/stage-6\n",
      "paris-nice/2005/stage-7\n",
      "paris-nice/2006/stage-4\n",
      "paris-nice/2008/stage-7\n",
      "paris-nice/2009/stage-4\n",
      "paris-nice/2014/stage-1\n",
      "paris-nice/2014/stage-2\n",
      "paris-nice/2014/stage-4\n",
      "paris-nice/2014/stage-8\n",
      "paris-nice/2015/stage-5\n",
      "paris-nice/2016/stage-1\n",
      "paris-nice/2016/stage-5\n",
      "paris-nice/2018/stage-5\n",
      "paris-nice/2019/stage-1\n",
      "paris-nice/2020/stage-3\n",
      "paris-nice/2020/stage-5\n",
      "paris-nice/2021/stage-1\n",
      "paris-nice/2021/stage-2\n",
      "paris-nice/2022/stage-2\n",
      "paris-nice/2022/stage-3\n",
      "paris-nice/2022/stage-6\n",
      "paris-nice/2023/stage-1\n",
      "paris-roubaix/1976/result\n",
      "ronde-van-vlaanderen/1974/result\n",
      "ronde-van-vlaanderen/2023/result\n",
      "tirreno-adriatico/1999/stage-7\n",
      "tirreno-adriatico/2002/stage-1\n",
      "tirreno-adriatico/2002/stage-2\n",
      "tirreno-adriatico/2005/stage-2\n",
      "tirreno-adriatico/2006/stage-2\n",
      "tirreno-adriatico/2007/stage-2\n",
      "tirreno-adriatico/2008/stage-7\n",
      "tirreno-adriatico/2012/stage-2\n",
      "tirreno-adriatico/2014/stage-2\n",
      "tirreno-adriatico/2014/stage-3\n",
      "tirreno-adriatico/2014/stage-6\n",
      "tirreno-adriatico/2015/stage-2\n",
      "tirreno-adriatico/2016/stage-2\n",
      "tirreno-adriatico/2017/stage-3\n",
      "tirreno-adriatico/2018/stage-2\n",
      "tirreno-adriatico/2019/stage-4\n",
      "tirreno-adriatico/2020/stage-1\n",
      "tirreno-adriatico/2020/stage-6\n",
      "tirreno-adriatico/2022/stage-3\n",
      "tirreno-adriatico/2023/stage-3\n",
      "tour-de-france/1980/stage-10\n",
      "tour-de-france/1982/stage-7\n",
      "tour-de-france/1983/stage-3\n",
      "tour-de-france/1984/stage-7\n",
      "tour-de-france/1985/stage-14\n",
      "tour-de-france/1985/stage-4\n",
      "tour-de-france/1985/stage-7\n",
      "tour-de-france/1987/stage-12\n",
      "tour-de-france/1987/stage-7\n",
      "tour-de-france/1987/stage-8\n",
      "tour-de-france/1988/stage-13\n",
      "tour-de-france/1988/stage-19\n",
      "tour-de-france/1988/stage-21\n",
      "tour-de-france/1989/stage-11\n",
      "tour-de-france/1990/stage-7\n",
      "tour-de-france/1991/stage-5\n",
      "tour-de-france/1993/stage-11\n",
      "tour-de-france/1993/stage-7\n",
      "tour-de-france/1994/prologue\n",
      "tour-de-france/1994/stage-1\n",
      "tour-de-france/1995/stage-1\n",
      "tour-de-france/1995/stage-15\n",
      "tour-de-france/1996/stage-1\n",
      "tour-de-france/1996/stage-15\n",
      "tour-de-france/1996/stage-16\n",
      "tour-de-france/1996/stage-7\n",
      "tour-de-france/1997/prologue\n",
      "tour-de-france/1997/stage-1\n",
      "tour-de-france/1997/stage-10\n",
      "tour-de-france/1997/stage-11\n",
      "tour-de-france/1997/stage-12\n",
      "tour-de-france/1997/stage-19\n",
      "tour-de-france/1997/stage-3\n",
      "tour-de-france/1997/stage-4\n",
      "tour-de-france/1997/stage-5\n",
      "tour-de-france/1997/stage-6\n",
      "tour-de-france/1997/stage-7\n",
      "tour-de-france/1997/stage-8\n",
      "tour-de-france/1997/stage-9\n",
      "tour-de-france/1999/prologue\n",
      "tour-de-france/2000/stage-7\n",
      "tour-de-france/2001/prologue\n",
      "tour-de-france/2001/stage-2\n",
      "tour-de-france/2001/stage-3\n",
      "tour-de-france/2001/stage-4\n",
      "tour-de-france/2002/stage-1\n",
      "tour-de-france/2002/stage-11\n",
      "tour-de-france/2002/stage-5\n",
      "tour-de-france/2002/stage-7\n",
      "tour-de-france/2002/stage-8\n",
      "tour-de-france/2002/stage-9\n",
      "tour-de-france/2003/stage-12\n",
      "tour-de-france/2003/stage-7\n",
      "tour-de-france/2004/stage-6\n",
      "tour-de-france/2005/stage-21\n",
      "tour-de-france/2005/stage-6\n",
      "tour-de-france/2008/stage-20\n",
      "tour-de-france/2008/stage-21\n",
      "tour-de-france/2010/stage-12\n",
      "tour-de-france/2012/stage-18\n",
      "tour-de-france/2012/stage-3\n",
      "tour-de-france/2012/stage-6\n",
      "tour-de-france/2013/stage-10\n",
      "tour-de-france/2013/stage-12\n",
      "tour-de-france/2014/stage-1\n",
      "tour-de-france/2014/stage-19\n",
      "tour-de-france/2014/stage-21\n",
      "tour-de-france/2014/stage-3\n",
      "tour-de-france/2014/stage-7\n",
      "tour-de-france/2015/stage-13\n",
      "tour-de-france/2015/stage-21\n",
      "tour-de-france/2015/stage-6\n",
      "tour-de-france/2016/stage-1\n",
      "tour-de-france/2016/stage-12\n",
      "tour-de-france/2016/stage-16\n",
      "tour-de-france/2016/stage-2\n",
      "tour-de-france/2016/stage-20\n",
      "tour-de-france/2016/stage-21\n",
      "tour-de-france/2016/stage-7\n",
      "tour-de-france/2017/stage-2\n",
      "tour-de-france/2017/stage-21\n",
      "tour-de-france/2017/stage-4\n",
      "tour-de-france/2018/stage-2\n",
      "tour-de-france/2018/stage-6\n",
      "tour-de-france/2019/stage-1\n",
      "tour-de-france/2019/stage-21\n",
      "tour-de-france/2021/stage-21\n",
      "tour-de-france/2021/stage-3\n",
      "tour-de-france/2021/stage-4\n",
      "tour-de-france/2023/stage-21\n",
      "tour-de-france/2023/stage-4\n",
      "tour-de-france/2023/stage-8\n",
      "tour-de-romandie/1990/stage-5\n",
      "tour-de-romandie/1993/prologue\n",
      "tour-de-romandie/1993/stage-3\n",
      "tour-de-romandie/1998/stage-3\n",
      "tour-de-romandie/2002/stage-2\n",
      "tour-de-romandie/2005/prologue\n",
      "tour-de-romandie/2007/stage-4\n",
      "tour-de-romandie/2010/stage-4\n",
      "tour-de-romandie/2014/stage-1\n",
      "tour-de-romandie/2014/stage-4\n",
      "tour-de-romandie/2016/stage-5\n",
      "tour-de-suisse/1984/stage-8b\n",
      "tour-de-suisse/1988/stage-3\n",
      "tour-de-suisse/1993/stage-4\n",
      "tour-de-suisse/1998/prologue\n",
      "tour-de-suisse/2005/stage-5\n",
      "tour-de-suisse/2006/stage-3\n",
      "tour-de-suisse/2008/stage-6\n",
      "tour-de-suisse/2013/stage-6\n",
      "tour-de-suisse/2014/stage-5\n",
      "tour-de-suisse/2015/stage-4\n",
      "tour-de-suisse/2015/stage-6\n",
      "tour-de-suisse/2016/stage-2\n",
      "tour-de-suisse/2021/stage-3\n",
      "uae-tour/2019/stage-2\n",
      "uae-tour/2019/stage-4\n",
      "uae-tour/2021/stage-1\n",
      "uae-tour/2022/stage-6\n",
      "uae-tour/2023/stage-6\n",
      "volta-a-catalunya/1999/stage-3\n",
      "volta-a-catalunya/2000/stage-7\n",
      "volta-a-catalunya/2006/stage-5\n",
      "volta-a-catalunya/2013/stage-4\n",
      "volta-a-catalunya/2015/stage-2\n",
      "volta-a-catalunya/2015/stage-5\n",
      "volta-a-catalunya/2015/stage-6\n",
      "volta-a-catalunya/2018/stage-3\n",
      "volta-a-catalunya/2019/stage-5\n",
      "volta-a-catalunya/2022/stage-1\n",
      "volta-a-catalunya/2022/stage-5\n",
      "vuelta-a-espana/1983/stage-1\n",
      "vuelta-a-espana/1983/stage-14\n",
      "vuelta-a-espana/1983/stage-16\n",
      "vuelta-a-espana/1992/stage-1\n",
      "vuelta-a-espana/1992/stage-19\n",
      "vuelta-a-espana/1992/stage-7\n",
      "vuelta-a-espana/1993/stage-11\n",
      "vuelta-a-espana/1996/stage-21\n",
      "vuelta-a-espana/1998/stage-1\n",
      "vuelta-a-espana/1998/stage-6\n",
      "vuelta-a-espana/1998/stage-8\n",
      "vuelta-a-espana/2001/stage-1\n",
      "vuelta-a-espana/2001/stage-13\n",
      "vuelta-a-espana/2001/stage-2\n",
      "vuelta-a-espana/2001/stage-20\n",
      "vuelta-a-espana/2001/stage-3\n",
      "vuelta-a-espana/2001/stage-4\n",
      "vuelta-a-espana/2001/stage-5\n",
      "vuelta-a-espana/2001/stage-6\n",
      "vuelta-a-espana/2001/stage-7\n",
      "vuelta-a-espana/2001/stage-8\n",
      "vuelta-a-espana/2002/stage-7\n",
      "vuelta-a-espana/2003/stage-18\n",
      "vuelta-a-espana/2003/stage-5\n",
      "vuelta-a-espana/2005/stage-12\n",
      "vuelta-a-espana/2006/stage-12\n",
      "vuelta-a-espana/2007/stage-17\n",
      "vuelta-a-espana/2007/stage-18\n",
      "vuelta-a-espana/2007/stage-3\n",
      "vuelta-a-espana/2009/stage-5\n",
      "vuelta-a-espana/2010/stage-19\n",
      "vuelta-a-espana/2010/stage-4\n",
      "vuelta-a-espana/2011/stage-2\n",
      "vuelta-a-espana/2012/stage-13\n",
      "vuelta-a-espana/2012/stage-8\n",
      "vuelta-a-espana/2013/stage-7\n",
      "vuelta-a-espana/2014/stage-12\n",
      "vuelta-a-espana/2014/stage-2\n",
      "vuelta-a-espana/2014/stage-20\n",
      "vuelta-a-espana/2014/stage-7\n",
      "vuelta-a-espana/2015/stage-3\n",
      "vuelta-a-espana/2015/stage-5\n",
      "vuelta-a-espana/2016/stage-16\n",
      "vuelta-a-espana/2016/stage-2\n",
      "vuelta-a-espana/2016/stage-5\n",
      "vuelta-a-espana/2016/stage-7\n",
      "vuelta-a-espana/2018/stage-10\n",
      "vuelta-a-espana/2018/stage-21\n",
      "vuelta-a-espana/2019/stage-14\n",
      "vuelta-a-espana/2020/stage-15\n",
      "vuelta-a-espana/2020/stage-5\n",
      "vuelta-a-espana/2020/stage-9\n",
      "vuelta-a-espana/2021/stage-2\n",
      "vuelta-a-espana/2021/stage-4\n",
      "vuelta-a-espana/2021/stage-8\n",
      "vuelta-a-espana/2022/stage-11\n",
      "vuelta-a-espana/2022/stage-16\n",
      "vuelta-a-espana/2022/stage-2\n"
     ]
    }
   ],
   "source": [
    "# Grouped by '_url', check if the 'delta' value is greater or equal than the previous one (the one in the previous row, except for the first one)\n",
    "invalid_urls = dataset.groupby('_url')['delta'].apply(lambda x: (x.shift() > x).any())\n",
    "\n",
    "# Print the number of URLs with invalid 'delta' values\n",
    "print('Number of URLs with invalid deltas: ' + str(len(invalid_urls[invalid_urls])))\n",
    "for url in invalid_urls[invalid_urls].index:\n",
    "    print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

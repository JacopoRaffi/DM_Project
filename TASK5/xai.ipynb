{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI (XAI)\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the best set of parameter setting, we can run a grid search\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import wittgenstein as lw\n",
    "import keras_tuner\n",
    "import keras\n",
    "from keras_tuner import HyperParameters\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from statistics import mean, stdev\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import loguniform as sp_loguniform\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "dev_set = pd.read_csv('../data/ml_datasets/undersampling/dev_set.csv').sample(frac = 1, random_state=RANDOM_STATE) # shuffling the data so not to introduce bias\n",
    "test_set = pd.read_csv('../data/ml_datasets/undersampling/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set['race_season%autumn'] = dev_set['race_season%autumn'].astype(int)\n",
    "dev_set['race_season%spring'] = dev_set['race_season%spring'].astype(int)\n",
    "dev_set['race_season%summer'] = dev_set['race_season%summer'].astype(int)\n",
    "dev_set['race_season%winter'] = dev_set['race_season%winter'].astype(int)\n",
    "\n",
    "test_set['race_season%autumn'] = test_set['race_season%autumn'].astype(int)\n",
    "test_set['race_season%spring'] = test_set['race_season%spring'].astype(int)\n",
    "test_set['race_season%summer'] = test_set['race_season%summer'].astype(int)\n",
    "test_set['race_season%winter'] = test_set['race_season%winter'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_label = dev_set.pop('label')\n",
    "test_label = test_set.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__class_weight': {0: 0.8, 1: 0.2}, 'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 13, 'classifier__min_samples_leaf': 20, 'classifier__min_samples_split': 30}\n"
     ]
    }
   ],
   "source": [
    "RUS = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "\n",
    "param_dist = {\"classifier__max_depth\": [3, 5, 10, 15, 20, None],\n",
    "              \"classifier__max_features\": sp_randint(3, len(dev_set.iloc[0]) + 1),\n",
    "              \"classifier__min_samples_split\": [20, 30, 50, 100],\n",
    "              \"classifier__min_samples_leaf\": [10, 20, 30, 50, 100],\n",
    "              \"classifier__criterion\": [\"entropy\", \"gini\"],\n",
    "              \"classifier__class_weight\":['balanced', None, {0: 0.8, 1: 0.2}, {0: 0.6, 1: 0.4}]} # class weights are related to over/undersampling chosen\n",
    "#define the number of iters\n",
    "n_iter_search = 10 # Total-Iteration: 400\n",
    "#define the model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('undersampler', RUS),  # Passo di undersampling\n",
    "    ('classifier', clf)  # Il classificatore\n",
    "], verbose=False)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=2, \n",
    "                            scoring='f1_weighted',\n",
    "                            refit=False,\n",
    "                            cv=skf)\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);\n",
    "print(rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9307655830128037,\n",
       "  'recall': 0.6469511078557041,\n",
       "  'f1-score': 0.7633307406447153,\n",
       "  'support': 27305.0},\n",
       " '1': {'precision': 0.2198753742817836,\n",
       "  'recall': 0.6740262962044158,\n",
       "  'f1-score': 0.3315840859165243,\n",
       "  'support': 4031.0},\n",
       " 'accuracy': 0.6504340056165433,\n",
       " 'macro avg': {'precision': 0.5753204786472936,\n",
       "  'recall': 0.6604887020300599,\n",
       "  'f1-score': 0.5474574132806198,\n",
       "  'support': 31336.0},\n",
       " 'weighted avg': {'precision': 0.8393180966905307,\n",
       "  'recall': 0.6504340056165433,\n",
       "  'f1-score': 0.7077917195440853,\n",
       "  'support': 31336.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(class_weight='balanced', criterion='entropy', max_depth=20, max_features=5, min_samples_leaf=30, min_samples_split=50)\n",
    "\n",
    "dev_set_u, dev_label_u = RUS.fit_resample(dev_set, dev_label)\n",
    "model.fit(dev_set_u, dev_label_u)\n",
    "\n",
    "train_labels_model = model.predict(dev_set_u)\n",
    "\n",
    "test_labels_model = model.predict(test_set)\n",
    "validation = classification_report(test_label, test_labels_model, output_dict=True)\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_data = dev_set_u\n",
    "perturbation_labels = dev_label_u\n",
    "perturbation_predictions = train_labels_model\n",
    "\n",
    "explanation_data = test_set\n",
    "explanation_labels = test_label\n",
    "explanation_predictions = test_labels_model\n",
    "\n",
    "explanations = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventional_explanation_algorithm = shap.TreeExplainer(\n",
    "    model=model,\n",
    "    data=dev_set_u,                       # perturb on a causal model induced on perturbation data\n",
    "    feature_perturbation=\"interventional\"  # use a causal model\n",
    ")\n",
    "\n",
    "distributional_explanation_algorithm = shap.TreeExplainer(\n",
    "    model=model,\n",
    "    feature_perturbation=\"tree_path_dependent\"  # condition on the distribution learned on the train data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 61057/62672 [00:31<00:00]       "
     ]
    }
   ],
   "source": [
    "interventional_explanations = interventional_explanation_algorithm(explanation_data)\n",
    "distributional_explanations = distributional_explanation_algorithm(explanation_data)\n",
    "\n",
    "explanations[\"shap_interventional\"] = interventional_explanations.values\n",
    "explanations[\"shap_distributional\"] = distributional_explanations.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The beeswarm plot does not support plotting explanations with instances that have more than one dimension!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeeswarm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterventional_explanations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dm/lib/python3.10/site-packages/shap/plots/_beeswarm.py:86\u001b[0m, in \u001b[0;36mbeeswarm\u001b[0;34m(shap_values, max_display, order, clustering, cluster_threshold, color, axis_color, alpha, show, log_scale, color_bar, s, plot_size, color_bar_label)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sv_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     82\u001b[0m     emsg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe beeswarm plot does not support plotting explanations with instances that have more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan one dimension!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     )\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(emsg)\n\u001b[1;32m     88\u001b[0m shap_exp \u001b[38;5;241m=\u001b[39m shap_values\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# we make a copy here, because later there are places that might modify this array\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The beeswarm plot does not support plotting explanations with instances that have more than one dimension!"
     ]
    }
   ],
   "source": [
    "shap.plots.beeswarm(interventional_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The beeswarm plot does not support plotting explanations with instances that have more than one dimension!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeeswarm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistributional_explanations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dm/lib/python3.10/site-packages/shap/plots/_beeswarm.py:86\u001b[0m, in \u001b[0;36mbeeswarm\u001b[0;34m(shap_values, max_display, order, clustering, cluster_threshold, color, axis_color, alpha, show, log_scale, color_bar, s, plot_size, color_bar_label)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sv_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     82\u001b[0m     emsg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe beeswarm plot does not support plotting explanations with instances that have more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan one dimension!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     )\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(emsg)\n\u001b[1;32m     88\u001b[0m shap_exp \u001b[38;5;241m=\u001b[39m shap_values\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# we make a copy here, because later there are places that might modify this array\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The beeswarm plot does not support plotting explanations with instances that have more than one dimension!"
     ]
    }
   ],
   "source": [
    "shap.plots.beeswarm(distributional_explanations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- Usare silhouette per \"validare\" la tecnica di clustering;\n",
    "- metodo MIN (Single);\n",
    "- metodo MAX (Complete);\n",
    "- metodo Average;\n",
    "- metodo Ward.\n",
    "\n",
    "In tutti i casi provare con e senza outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/complete_dataset_fe.csv', dtype={'cyclist_team': str})\n",
    "dataset['date'] = pd.to_datetime(dataset['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234082\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns for clustering\n",
    "columns_to_use = ['points', 'uci_points', 'length', 'climb_total', 'cyclist_age',\n",
    "                  'cyclist_bmi', 'climb_percentage', 'race_prestige', 'race_physical_effort'] #TODO: choose which feature to use\n",
    "\n",
    "data_for_clustering = dataset[columns_to_use].dropna() #TODO: remove when we have imputed the missing values\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.26 TiB for an array with shape (173688812578,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_dist \u001b[38;5;241m=\u001b[39m \u001b[43mpdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data_link \u001b[38;5;241m=\u001b[39m linkage(data_dist, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m'\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m res \u001b[38;5;241m=\u001b[39m dendrogram(data_link, color_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, truncate_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlastp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dm/lib/python3.10/site-packages/scipy/spatial/distance.py:2180\u001b[0m, in \u001b[0;36mpdist\u001b[0;34m(X, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2179\u001b[0m     pdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mpdist_func\n\u001b[0;32m-> 2180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2182\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 1.26 TiB for an array with shape (173688812578,) and data type float64"
     ]
    }
   ],
   "source": [
    "data_dist = pdist(data_scaled, metric='euclidean')\n",
    "data_link = linkage(data_dist, method='complete', metric='euclidean')\n",
    "res = dendrogram(data_link, color_threshold=10, truncate_mode='lastp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

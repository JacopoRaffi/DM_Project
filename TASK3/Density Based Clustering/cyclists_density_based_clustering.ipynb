{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclist - Density Based Clustering (DBSCAN)\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! IMPORTANT !!!\n",
    "\n",
    "This notebook, along with the notebooks ‚Äòcyclist_density_based_clustering_3f.ipynb‚Äô and ‚Äòcyclist_density_based_clustering_4f.ipynb‚Äô study the application of the DBSCAN density-based clustering algorithm. In particular, they represent three variants of our approach, aimed at studying the inclusion of more or fewer features in the clustering process.\n",
    "\n",
    "The variant approach below includes in the clustering process the 5 features 'mean_bmi','mean_height', 'mean_cp' (climb power), 'mean_position' and 'mean_delta'.\n",
    "\n",
    "The selection of these features was derived from a data understanding process, applied following the data cleaning and feature engeneering phases, through which it was possible to skim the attributes by identifying those that appeared to be the most significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2769 entries, 0 to 2768\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   mean_cyclist_cp  2769 non-null   float64\n",
      " 1   mean_delta       2769 non-null   float64\n",
      " 2   mean_position    2769 non-null   float64\n",
      " 3   birth_year       2769 non-null   int64  \n",
      " 4   weight           2769 non-null   float64\n",
      " 5   height           2769 non-null   float64\n",
      " 6   cyclist_bmi      2769 non-null   float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 151.6 KB\n"
     ]
    }
   ],
   "source": [
    "cyclists_dataset = pd.read_csv('../../data/cyclists_dataset_no_outliers.csv')\n",
    "cyclists_dataset = cyclists_dataset.select_dtypes(include=['number'])\n",
    "cyclists_dataset = cyclists_dataset.dropna().reset_index(drop=True)\n",
    "\n",
    "cyclists_dataset.info()\n",
    "columns_to_use = cyclists_dataset.columns\n",
    "\n",
    "# Standardizzazione dei dati\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cyclists_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the following model selection process, the two parameters of the ‚ÄòDBSCAN‚Äô algorithm (‚Äòeps‚Äô and ‚Äòmin_samples‚Äô) were selected in the context of this case study. Of the options studied in the process, the evaluation was made according to the trade-off between the number of clusters identified and silhouette score.\n",
    "\n",
    "Each iteration of the model selection process starts with setting the ‚Äòmin_points‚Äô parameter, studied in the range 2-20. For each of these alternatives, the optimal value of the ‚Äòeps‚Äô parameter is identified through the identification of the knee-point in the curve defined by the points (k-th distance, index).\n",
    "\n",
    "Our Knee Method implementation:\n",
    "\n",
    "- We compute the ùëò-distance for each point:\n",
    "    - Choose a value for ùëò, a tipical choice should be to set to ùëò = min_points ‚àí 1, where min_points is the minimum number of points required to form a dense region (DBSCAN parameter fixed in the model selection iteration). \n",
    "    - For each point in the dataset, we calculate the distance to its ùëò-th nearest neighbor (ùëò-distance).\n",
    "- We sort the ùëò-distances:\n",
    "    - Arrange all the points by their ùëò-distance in a ùëò-distance plot, where the x-axis is the points (sorted) and the y-axis is their ùëò-distance.\n",
    "- Plot the ùëò-distance graph\n",
    "- Identify the \"knee\" in the plot: The y-axis typically increases gradually at first and then sharply increases, forming a curve. The knee corresponds to the point of maximum curvature in the graph. It is the location where the slope changes most significantly. Intuitively, it separates the \"dense\" regions (gradual slope) from the \"sparse\" regions (steep slope) in the dataset.\n",
    "\n",
    "\n",
    "To automate the process of knee detection, we relied on the kneed library (KneeLocator).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = squareform(pdist(data_scaled, 'euclidean'))\n",
    "min_points = range(2, 20)\n",
    "optimal_eps = []\n",
    "optimal_index = []\n",
    "cluster_count = []\n",
    "silhouette_scores = []\n",
    "\n",
    "\n",
    "\n",
    "for i, value in enumerate(min_points):\n",
    "    k = value - 1 #standard value? TODO: check this\n",
    "    \n",
    "    kth_distances = list()\n",
    "    for d in dist:\n",
    "        index_kth_distance = np.argsort(d)[k]\n",
    "        kth_distances.append(d[index_kth_distance])\n",
    "\n",
    "    sorted_distances = sorted(kth_distances)\n",
    "    indices = range(0, len(kth_distances))\n",
    "\n",
    "    # Use the KneeLocator to find the knee point\n",
    "    kneedle = KneeLocator(indices, sorted_distances, curve=\"convex\", direction=\"increasing\")\n",
    "    \n",
    "    if(kneedle.knee is None):\n",
    "        optimal_eps.append(None) \n",
    "        optimal_index.append(None)  \n",
    "        silhouette_scores.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Get the knee (selecting automatically the optimal epsilon)\n",
    "    optimal_eps.append(sorted_distances[kneedle.knee])  # The y-value at the knee\n",
    "    optimal_index.append(kneedle.knee)  # The x-value (index)\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=optimal_eps[i], min_samples=value)\n",
    "    clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "    # Add cluster labels to the data\n",
    "    cyclists_dataset['cluster'] = clusters\n",
    "    number_of_clusters = cyclists_dataset['cluster'].nunique()\n",
    "    cluster_count.append(number_of_clusters)\n",
    "    \n",
    "    if(number_of_clusters < 3): # Considering that a cluster (label -1) is that of outliers, to compute silhouette we need at least 3 clusters here\n",
    "        silhouette_scores.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Removing outliers so to not include them in silhouette calculation\n",
    "    no_out_data_scaled = scaler.fit_transform(cyclists_dataset[cyclists_dataset['cluster'] != -1])\n",
    "    no_out_labels = dbscan.labels_[dbscan.labels_ != -1]\n",
    "\n",
    "    # Calculate Silhouette\n",
    "    silhouette_scores.append(silhouette_score(no_out_data_scaled, no_out_labels))\n",
    "    \n",
    "\n",
    "# Creating the DataFrame\n",
    "model_selection_data = {\"min_points\": min_points, \"optimal_eps\": optimal_eps, \"optimal_index\": optimal_index, \"cluster_count\": cluster_count, \"silhouette_score\": silhouette_scores}\n",
    "model_selection_df = pd.DataFrame(model_selection_data)\n",
    "\n",
    "model_selection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_selection_df[model_selection_df['cluster_count'] > 2]['min_points']\n",
    "y = model_selection_df[model_selection_df['cluster_count'] > 2]['silhouette_score']\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylabel('silhouette_scores')\n",
    "plt.xlabel('min_points', fontsize=18)\n",
    "plt.xticks(min_points)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosen Parameter Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_points = 4 # found throught model selection\n",
    "\n",
    "dist = pdist(data_scaled, 'euclidean') #pair wise distance\n",
    "print (dist.shape)\n",
    "dist = squareform(dist) #distance matrix given the vector dist\n",
    "print(dist.shape)\n",
    "\n",
    "k = min_points - 1 #standard value?\n",
    "kth_distances = list()\n",
    "for d in dist:\n",
    "    index_kth_distance = np.argsort(d)[k]\n",
    "    kth_distances.append(d[index_kth_distance])\n",
    "\n",
    "sorted_distances = sorted(kth_distances)\n",
    "indices = range(0, len(kth_distances))\n",
    "\n",
    "# Use the KneeLocator to find the knee point\n",
    "kneedle = KneeLocator(indices, sorted_distances, curve=\"convex\", direction=\"increasing\")\n",
    "\n",
    "# Get the knee (optimal epsilon)\n",
    "optimal_eps = sorted_distances[kneedle.knee]  # The y-value at the knee\n",
    "optimal_index = kneedle.knee  # The x-value (index)\n",
    "\n",
    "print(f\"Optimal epsilon (eps): {optimal_eps}\")\n",
    "print(f\"Knee point index: {optimal_index}\")\n",
    "\n",
    "# Plot the k-distance graph with the knee point marked\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(indices, sorted_distances, label=\"k-distance curve\")\n",
    "plt.axvline(optimal_index, linestyle=\"--\", color=\"r\", label=f\"Knee (eps={optimal_eps:.2f})\")\n",
    "plt.scatter(optimal_index, optimal_eps, color=\"red\", label=\"Knee point\", zorder=5)\n",
    "plt.xlabel(\"Sorted Points\")\n",
    "plt.ylabel(\"k-distance\")\n",
    "plt.title(\"Knee Point Detection for Epsilon\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection of best eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=optimal_eps, min_samples=min_points)\n",
    "clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "# Add cluster labels to the data\n",
    "cyclists_dataset['cluster'] = clusters\n",
    "\n",
    "# Display cluster distribution\n",
    "print(cyclists_dataset['cluster'].value_counts())\n",
    "print(cyclists_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dbscan.labels_, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers (cluster label -1)\n",
    "outliers = cyclists_dataset[cyclists_dataset['cluster'] == -1]\n",
    "print(\"\\nNumber of outliers:\", len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the mean and standard deviation of numerical features for each cluster\n",
    "cluster_stats = cyclists_dataset.groupby('cluster').agg(['mean', 'std'])\n",
    "print(\"Cluster Statistics:\\n\", cluster_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pair plot for a subset of columns\n",
    "data_subset = cyclists_dataset[columns_to_use + [\"cluster\"]]\n",
    "sns.pairplot(data_subset, hue='cluster', palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "x = cyclists_dataset['mean_bmi']  # Prima feature\n",
    "y = cyclists_dataset['mean_position']  # Seconda feature\n",
    "z = cyclists_dataset['mean_cp']  # Terza feature\n",
    "\n",
    "# Crea il grafico 3D\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatterplot\n",
    "scatter = ax.scatter(x, y, z, c=cyclists_dataset['cluster'], cmap='viridis', s=50)\n",
    "ax.set_xlabel('mean_bmi')\n",
    "ax.set_ylabel('mean_position')\n",
    "ax.set_zlabel('mean_cp')\n",
    "\n",
    "# Aggiungi una legenda (opzionale)\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.title('3D Scatterplot of Clusters')\n",
    "\n",
    "# Abilita la modalit√† interattiva\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the clustering that involved all five features, we can observe how two clusters have been highlighted in the data. The larger cluster (in green in the plots) seems to represent the vast majority of cyclists, while those associated with the smaller cluster (yellow in the plots) seem to stand out for their average climbing power higher than the previous ones. No relevant associations seem to emerge between the clusters identified by the algorithm and the other features, so we proceed with the analyses of the notebooks \"cyclist_density_based_clustering_4f\" and \"cyclist_density_based_clustering_3f\", where we reduce the features to those that from these results seem to be more influential in a possible clustering (observing the distribution of the data in space). We then eliminate the feature \"height\" (analysis in the notebook \"cyclist_density_based_clustering_4f\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = scaler.fit_transform(cyclists_dataset[cyclists_dataset['cluster'] != -1])\n",
    "no_out_labels = dbscan.labels_[dbscan.labels_ != -1]\n",
    "\n",
    "print('Silhouette %s' % silhouette_score(data_scaled, no_out_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

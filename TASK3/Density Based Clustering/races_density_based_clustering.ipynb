{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Races - Density Based Clustering (DBSCAN)\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents the application of DBSCAN as a hierarchical clustering algorithm rspect to races data. the approach below includes in the clustering process the three features 'race_prestige','race_physical_effort' and 'lenght'.\n",
    "\n",
    "The selection of these features was derived from a data understanding process, applied following the data cleaning and feature engeneering phases, through which it was possible to skim the attributes by identifying those that appeared to be the most representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2817 entries, 0 to 2816\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   points                2817 non-null   float64\n",
      " 1   length                2817 non-null   float64\n",
      " 2   climb_total           2817 non-null   float64\n",
      " 3   race_physical_effort  2817 non-null   float64\n",
      " 4   race_prestige         2817 non-null   float64\n",
      " 5   num_participants      2817 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 132.2 KB\n"
     ]
    }
   ],
   "source": [
    "races_dataset = pd.read_csv('../../data/races_dataset_no_outliers.csv').drop(['uci_points', 'profile'], axis=1)\n",
    "races_dataset = races_dataset.select_dtypes(include=['number'])\n",
    "races_dataset = races_dataset.dropna().reset_index(drop=True)\n",
    "\n",
    "# drop colums from PCA and UMAP analisis\n",
    "races_dataset = races_dataset.drop(['startlist_quality', 'race_year', 'climb_percentage'], axis=1)\n",
    "\n",
    "races_dataset.info()\n",
    "columns_to_use = races_dataset.columns\n",
    "\n",
    "# Standardizzazione dei dati\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(races_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the following model selection process, the two parameters of the ‚ÄòDBSCAN‚Äô algorithm (‚Äòeps‚Äô and ‚Äòmin_samples‚Äô) were selected in the context of this case study. Of the options studied in the process, the evaluation was made according to the trade-off between the number of clusters identified and silhouette score.\n",
    "\n",
    "Each iteration of the model selection process starts with setting the ‚Äòmin_points‚Äô parameter, studied in the range 2-20. For each of these alternatives, the optimal value of the ‚Äòeps‚Äô parameter is identified through the identification of the knee-point in the curve defined by the points (k-th distance, index).\n",
    "\n",
    "Our Knee Method implementation:\n",
    "\n",
    "- We compute the ùëò-distance for each point:\n",
    "    - Choose a value for ùëò, a tipical choice should be to set to ùëò = min_points ‚àí 1, where min_points is the minimum number of points required to form a dense region (DBSCAN parameter fixed in the model selection iteration). \n",
    "    - For each point in the dataset, we calculate the distance to its ùëò-th nearest neighbor (ùëò-distance).\n",
    "- We sort the ùëò-distances:\n",
    "    - Arrange all the points by their ùëò-distance in a ùëò-distance plot, where the x-axis is the points (sorted) and the y-axis is their ùëò-distance.\n",
    "- Plot the ùëò-distance graph\n",
    "- Identify the \"knee\" in the plot: The y-axis typically increases gradually at first and then sharply increases, forming a curve. The knee corresponds to the point of maximum curvature in the graph. It is the location where the slope changes most significantly. Intuitively, it separates the \"dense\" regions (gradual slope) from the \"sparse\" regions (steep slope) in the dataset.\n",
    "\n",
    "\n",
    "To automate the process of knee detection, we relied on the kneed library (KneeLocator).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = squareform(pdist(data_scaled, 'euclidean'))\n",
    "min_points = range(2, 20)\n",
    "optimal_eps = []\n",
    "optimal_index = []\n",
    "cluster_count = []\n",
    "silhouette_scores = []\n",
    "\n",
    "\n",
    "\n",
    "for i, value in enumerate(min_points):\n",
    "    k = value - 1 #standard value? TODO: check this\n",
    "    \n",
    "    kth_distances = list()\n",
    "    for d in dist:\n",
    "        index_kth_distance = np.argsort(d)[k]\n",
    "        kth_distances.append(d[index_kth_distance])\n",
    "\n",
    "    sorted_distances = sorted(kth_distances)\n",
    "    indices = range(0, len(kth_distances))\n",
    "\n",
    "    # Use the KneeLocator to find the knee point\n",
    "    kneedle = KneeLocator(indices, sorted_distances, curve=\"convex\", direction=\"increasing\")\n",
    "    \n",
    "    if(kneedle.knee is None):\n",
    "        optimal_eps.append(None) \n",
    "        optimal_index.append(None)  \n",
    "        silhouette_scores.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Get the knee (selecting automatically the optimal epsilon)\n",
    "    optimal_eps.append(sorted_distances[kneedle.knee])  # The y-value at the knee\n",
    "    optimal_index.append(kneedle.knee)  # The x-value (index)\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=optimal_eps[i], min_samples=value)\n",
    "    clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "    # Add cluster labels to the data\n",
    "    races_dataset['cluster'] = clusters\n",
    "    number_of_clusters = races_dataset['cluster'].nunique()\n",
    "    cluster_count.append(number_of_clusters)\n",
    "    \n",
    "    if(number_of_clusters < 3): # Considering that a cluster (label -1) is that of outliers, to compute silhouette we need at least 3 clusters here\n",
    "        silhouette_scores.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Removing outliers so to not include them in silhouette calculation\n",
    "    no_out_data_scaled = scaler.fit_transform(races_dataset[races_dataset['cluster'] != -1])\n",
    "    no_out_labels = dbscan.labels_[dbscan.labels_ != -1]\n",
    "\n",
    "    # Calculate Silhouette\n",
    "    silhouette_scores.append(silhouette_score(no_out_data_scaled, no_out_labels))\n",
    "    \n",
    "\n",
    "# Creating the DataFrame\n",
    "model_selection_data = {\"min_points\": min_points, \"optimal_eps\": optimal_eps, \"optimal_index\": optimal_index, \"cluster_count\": cluster_count, \"silhouette_score\": silhouette_scores}\n",
    "model_selection_df = pd.DataFrame(model_selection_data)\n",
    "\n",
    "model_selection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_selection_df[model_selection_df['cluster_count'] > 2]['min_points']\n",
    "y = model_selection_df[model_selection_df['cluster_count'] > 2]['silhouette_score']\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylabel('silhouette_scores')\n",
    "plt.xlabel('min_points', fontsize=18)\n",
    "plt.xticks(min_points)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosen Parameters Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_points = 6 # found throught model selection\n",
    "\n",
    "dist = pdist(data_scaled, 'euclidean') #pair wise distance\n",
    "print (dist.shape)\n",
    "dist = squareform(dist) #distance matrix given the vector dist\n",
    "print(dist.shape)\n",
    "\n",
    "k = min_points - 1 #standard value?\n",
    "kth_distances = list()\n",
    "for d in dist:\n",
    "    index_kth_distance = np.argsort(d)[k]\n",
    "    kth_distances.append(d[index_kth_distance])\n",
    "\n",
    "sorted_distances = sorted(kth_distances)\n",
    "indices = range(0, len(kth_distances))\n",
    "\n",
    "# Use the KneeLocator to find the knee point\n",
    "kneedle = KneeLocator(indices, sorted_distances, curve=\"convex\", direction=\"increasing\")\n",
    "\n",
    "# Get the knee (optimal epsilon)\n",
    "optimal_eps = sorted_distances[kneedle.knee]  # The y-value at the knee\n",
    "optimal_index = kneedle.knee  # The x-value (index)\n",
    "\n",
    "print(f\"Optimal epsilon (eps): {optimal_eps}\")\n",
    "print(f\"Knee point index: {optimal_index}\")\n",
    "\n",
    "# Plot the k-distance graph with the knee point marked\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(indices, sorted_distances, label=\"k-distance curve\")\n",
    "plt.axvline(optimal_index, linestyle=\"--\", color=\"r\", label=f\"Knee (eps={optimal_eps:.2f})\")\n",
    "plt.scatter(optimal_index, optimal_eps, color=\"red\", label=\"Knee point\", zorder=5)\n",
    "plt.xlabel(\"Sorted Points\")\n",
    "plt.ylabel(\"k-distance\")\n",
    "plt.title(\"Knee Point Detection for Epsilon\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection of best eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=optimal_eps, min_samples=min_points)\n",
    "clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "# Add cluster labels to the data\n",
    "races_dataset['cluster'] = clusters\n",
    "\n",
    "# Display cluster distribution\n",
    "print(races_dataset['cluster'].value_counts())\n",
    "print(races_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dbscan.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers (cluster label -1)\n",
    "outliers = races_dataset[races_dataset['cluster'] == -1]\n",
    "print(\"\\nNumber of outliers:\", len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the mean and standard deviation of numerical features for each cluster\n",
    "cluster_stats = races_dataset.groupby('cluster').agg(['mean', 'std'])\n",
    "print(\"Cluster Statistics:\\n\", cluster_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for a subset of columns\n",
    "data_subset = races_dataset[['length','race_prestige', 'race_physical_effort', 'cluster']]\n",
    "sns.pairplot(data_subset, hue='cluster', palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "x = races_dataset['length']  # Prima feature\n",
    "y = races_dataset['race_physical_effort']  # Seconda feature\n",
    "z = races_dataset['race_prestige']  # Terza feature\n",
    "\n",
    "# Crea il grafico 3D\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatterplot\n",
    "scatter = ax.scatter(x, y, z, c=races_dataset['cluster'], cmap='viridis', s=50)\n",
    "ax.set_xlabel('length')\n",
    "ax.set_ylabel('race_physical_effort')\n",
    "ax.set_zlabel('race_prestige')\n",
    "\n",
    "# Aggiungi una legenda (opzionale)\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.title('3D Scatterplot of Clusters')\n",
    "\n",
    "# Abilita la modalit√† interattiva\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the plots, we can see that density-based clustering through DBSCAN revealed the presence of four relevant clusters.\n",
    "In particular, looking at the data with respect to the size of the ‚Äòrace_physical_effort‚Äô and ‚Äòrace_prestige‚Äô features, we can clearly observe the result of DBSCAN's behaviour, with clusters of varying shapes and densely packed within them.\n",
    "\n",
    "The clusters can be analysed as follows (colour references and labels in the plots):\n",
    "- yellow (3) : race_prestige (0.4-0.5), race_physical_effort (0.5-0.6)\n",
    "- green (2): race_prestige (0.7-0.8), race_physical_effort (0.5-0.7)\n",
    "- teal (1): race_prestige (0.7-0.8), race_physical_effort (0.1-0.2)\n",
    "- dark blue (-1): outliers\n",
    "- blue (0): remaining records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = scaler.fit_transform(races_dataset[races_dataset['cluster'] != -1])\n",
    "no_out_labels = dbscan.labels_[dbscan.labels_ != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Silhouette %s' % silhouette_score(data_scaled, no_out_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The silhouette value obtained confirms that the clusters are ‚Äòwell defined‚Äô and logically ‚Äòcompact‚Äô"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Bayesian Search - Oversampled Dataset\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn import tree\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge results from previous random search\n",
    "USER_1 = 'Jacopo'\n",
    "USER_2 = 'Simone'\n",
    "\n",
    "models = ['ada_boost', 'nn', 'xgb', 'naive_bayes', 'random_forest', 'decision_tree', 'svm', 'rule_based', 'knn']\n",
    "\n",
    "for model in models:\n",
    "    path_1 = f'../../data/ml_datasets/oversampling/model_selection/{USER_1}_{model}_results.csv'\n",
    "    path_2 = f'../../data/ml_datasets/oversampling/model_selection/{USER_2}_{model}_results.csv'\n",
    "\n",
    "    concatenate_path = f'../../data/ml_datasets/oversampling/model_selection/{model}_results.csv'\n",
    "\n",
    "    df1 = pd.read_csv(path_1)\n",
    "    df2 = pd.read_csv(path_2)\n",
    "\n",
    "    df_concat = pd.concat([df1, df2], ignore_index=True) # Concat the two files\n",
    "    df_concat.to_csv(concatenate_path, index=False)  # Save the result in a new CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_see = ['mean_test_f1_micro', 'mean_test_f1_1', 'mean_test_f1_0', 'mean_test_f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/ada_boost_results.csv')\n",
    "# df.sort_values(by='mean_test_f1_micro', ascending=False, inplace=True)\n",
    "# params= [col for col in df.columns if col.startswith(\"param_\")]\n",
    "# df.head(n=10)[columns_to_see+params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['batch_size', 'epochs', 'units_layer1', 'units_layer2', 'drop_rate',\n",
      "       'learning_rate', 'mean_test_f1_micro', 'std_test_f1_micro',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'mean_test_f1_1', 'std_test_f1_1',\n",
      "       'mean_test_f1_macro'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "models = ['ada_boost', 'nn', 'xgb', 'naive_bayes', 'random_forest', 'decision_tree', 'svm', 'rule_based', 'knn']\n",
    "\n",
    "df_results = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/nn_results.csv')\n",
    "df_results = df_results.rename(columns={'mean_f1_micro': 'mean_test_f1_micro', \n",
    "                                        'std_f1_micro': 'std_test_f1_micro',\n",
    "                                        'mean_f1_1': 'mean_test_f1_1',\n",
    "                                        'std_f1_1': 'std_test_f1_1',\n",
    "                                        'mean_f1_0': 'mean_test_f1_0',\n",
    "                                        'std_f1_0': 'std_test_f1_0',\n",
    "                                        'mean_f1_macro': 'mean_test_f1_macro', \n",
    "                                        'std_f1_macro': 'std_test_f1_macro',})\n",
    "print(df_results.columns)\n",
    "df_results = df_results[columns_to_see]\n",
    "df_results['model'] = 'nn'\n",
    "models.remove('nn')\n",
    "\n",
    "columns_to_see = ['model'] + columns_to_see\n",
    "for model in models:\n",
    "    path = f'../../data/ml_datasets/oversampling/model_selection/{model}_results.csv'\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df['model'] = model\n",
    "    df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "    df = df.head(10)\n",
    "    df = df[columns_to_see]\n",
    "\n",
    "    df_results = pd.concat([df_results, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_f1_micro</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.854396</td>\n",
       "      <td>0.485541</td>\n",
       "      <td>0.915198</td>\n",
       "      <td>0.700369</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.858062</td>\n",
       "      <td>0.479820</td>\n",
       "      <td>0.917819</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.858481</td>\n",
       "      <td>0.471561</td>\n",
       "      <td>0.918301</td>\n",
       "      <td>0.694931</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.844311</td>\n",
       "      <td>0.479672</td>\n",
       "      <td>0.908461</td>\n",
       "      <td>0.694066</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.838012</td>\n",
       "      <td>0.475128</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>0.689678</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.839732</td>\n",
       "      <td>0.471662</td>\n",
       "      <td>0.905539</td>\n",
       "      <td>0.688601</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.806650</td>\n",
       "      <td>0.471103</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>0.676402</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.804689</td>\n",
       "      <td>0.470015</td>\n",
       "      <td>0.880286</td>\n",
       "      <td>0.675151</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.804944</td>\n",
       "      <td>0.469089</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.674806</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880446</td>\n",
       "      <td>0.413018</td>\n",
       "      <td>0.933446</td>\n",
       "      <td>0.673232</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.848650</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.914112</td>\n",
       "      <td>0.638874</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.860845</td>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.922011</td>\n",
       "      <td>0.638447</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.856775</td>\n",
       "      <td>0.356807</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>0.638111</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.855788</td>\n",
       "      <td>0.355835</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.637320</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.782350</td>\n",
       "      <td>0.407543</td>\n",
       "      <td>0.866687</td>\n",
       "      <td>0.637115</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.848261</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.913980</td>\n",
       "      <td>0.635523</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.843728</td>\n",
       "      <td>0.358949</td>\n",
       "      <td>0.911018</td>\n",
       "      <td>0.634984</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.789981</td>\n",
       "      <td>0.396664</td>\n",
       "      <td>0.872862</td>\n",
       "      <td>0.634763</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.849832</td>\n",
       "      <td>0.354349</td>\n",
       "      <td>0.915036</td>\n",
       "      <td>0.634692</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.778579</td>\n",
       "      <td>0.405177</td>\n",
       "      <td>0.863971</td>\n",
       "      <td>0.634574</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734139</td>\n",
       "      <td>0.411422</td>\n",
       "      <td>0.828289</td>\n",
       "      <td>0.619855</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.721241</td>\n",
       "      <td>0.405020</td>\n",
       "      <td>0.817981</td>\n",
       "      <td>0.611501</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.717067</td>\n",
       "      <td>0.401633</td>\n",
       "      <td>0.814732</td>\n",
       "      <td>0.608182</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.710932</td>\n",
       "      <td>0.398780</td>\n",
       "      <td>0.809723</td>\n",
       "      <td>0.604252</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.710229</td>\n",
       "      <td>0.397674</td>\n",
       "      <td>0.809225</td>\n",
       "      <td>0.603449</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.709286</td>\n",
       "      <td>0.398204</td>\n",
       "      <td>0.808353</td>\n",
       "      <td>0.603278</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.706174</td>\n",
       "      <td>0.398947</td>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.602254</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817109</td>\n",
       "      <td>0.309474</td>\n",
       "      <td>0.894596</td>\n",
       "      <td>0.602035</td>\n",
       "      <td>rule_based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.765397</td>\n",
       "      <td>0.336282</td>\n",
       "      <td>0.857517</td>\n",
       "      <td>0.596900</td>\n",
       "      <td>rule_based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.700727</td>\n",
       "      <td>0.391234</td>\n",
       "      <td>0.801595</td>\n",
       "      <td>0.596415</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.697256</td>\n",
       "      <td>0.392348</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.595379</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.699964</td>\n",
       "      <td>0.389403</td>\n",
       "      <td>0.801119</td>\n",
       "      <td>0.595261</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.724578</td>\n",
       "      <td>0.344317</td>\n",
       "      <td>0.825676</td>\n",
       "      <td>0.584997</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.724728</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.584787</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_f1_micro  mean_test_f1_1  mean_test_f1_0  mean_test_f1_macro  \\\n",
       "15            0.854396        0.485541        0.915198            0.700369   \n",
       "14            0.858062        0.479820        0.917819            0.698820   \n",
       "13            0.858481        0.471561        0.918301            0.694931   \n",
       "16            0.844311        0.479672        0.908461            0.694066   \n",
       "18            0.838012        0.475128        0.904227            0.689678   \n",
       "17            0.839732        0.471662        0.905539            0.688601   \n",
       "21            0.806650        0.471103        0.881701            0.676402   \n",
       "23            0.804689        0.470015        0.880286            0.675151   \n",
       "22            0.804944        0.469089        0.880524            0.674806   \n",
       "0             0.880446        0.413018        0.933446            0.673232   \n",
       "29            0.848650        0.363636        0.914112            0.638874   \n",
       "11            0.860845        0.354883        0.922011            0.638447   \n",
       "16            0.856775        0.356807        0.919415            0.638111   \n",
       "23            0.855788        0.355835        0.918805            0.637320   \n",
       "71            0.782350        0.407543        0.866687            0.637115   \n",
       "31            0.848261        0.357066        0.913980            0.635523   \n",
       "37            0.843728        0.358949        0.911018            0.634984   \n",
       "59            0.789981        0.396664        0.872862            0.634763   \n",
       "28            0.849832        0.354349        0.915036            0.634692   \n",
       "77            0.778579        0.405177        0.863971            0.634574   \n",
       "0             0.734139        0.411422        0.828289            0.619855   \n",
       "26            0.721241        0.405020        0.817981            0.611501   \n",
       "27            0.717067        0.401633        0.814732            0.608182   \n",
       "28            0.710932        0.398780        0.809723            0.604252   \n",
       "29            0.710229        0.397674        0.809225            0.603449   \n",
       "31            0.709286        0.398204        0.808353            0.603278   \n",
       "32            0.706174        0.398947        0.805561            0.602254   \n",
       "0             0.817109        0.309474        0.894596            0.602035   \n",
       "1             0.765397        0.336282        0.857517            0.596900   \n",
       "34            0.700727        0.391234        0.801595            0.596415   \n",
       "37            0.697256        0.392348        0.798410            0.595379   \n",
       "35            0.699964        0.389403        0.801119            0.595261   \n",
       "10            0.724578        0.344317        0.825676            0.584997   \n",
       "9             0.724728        0.343738        0.825837            0.584787   \n",
       "1             0.725566        0.339230        0.826820            0.583025   \n",
       "2             0.725566        0.339230        0.826820            0.583025   \n",
       "3             0.725566        0.339230        0.826820            0.583025   \n",
       "6             0.725566        0.339230        0.826820            0.583025   \n",
       "5             0.725566        0.339230        0.826820            0.583025   \n",
       "4             0.725566        0.339230        0.826820            0.583025   \n",
       "\n",
       "            model  \n",
       "15  random_forest  \n",
       "14  random_forest  \n",
       "13  random_forest  \n",
       "16  random_forest  \n",
       "18  random_forest  \n",
       "17  random_forest  \n",
       "21  random_forest  \n",
       "23  random_forest  \n",
       "22  random_forest  \n",
       "0   random_forest  \n",
       "29  decision_tree  \n",
       "11  decision_tree  \n",
       "16  decision_tree  \n",
       "23  decision_tree  \n",
       "71  decision_tree  \n",
       "31  decision_tree  \n",
       "37  decision_tree  \n",
       "59  decision_tree  \n",
       "28  decision_tree  \n",
       "77  decision_tree  \n",
       "0             xgb  \n",
       "26            xgb  \n",
       "27            xgb  \n",
       "28            xgb  \n",
       "29            xgb  \n",
       "31            xgb  \n",
       "32            xgb  \n",
       "0      rule_based  \n",
       "1      rule_based  \n",
       "34            xgb  \n",
       "37            xgb  \n",
       "35            xgb  \n",
       "10      ada_boost  \n",
       "9       ada_boost  \n",
       "1       ada_boost  \n",
       "2       ada_boost  \n",
       "3       ada_boost  \n",
       "6       ada_boost  \n",
       "5       ada_boost  \n",
       "4       ada_boost  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df_results.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winner models for oversampling:\n",
    "- Random Forests\n",
    "- XGB\n",
    "- Decision Tree\n",
    "- Ada-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_f1_micro</th>\n",
       "      <th>rank_test_f1_micro</th>\n",
       "      <th>split0_test_f1_0</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.638874</td>\n",
       "      <td>0.638874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.914112</td>\n",
       "      <td>0.914112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.638447</td>\n",
       "      <td>0.638447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.922011</td>\n",
       "      <td>0.922011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.638111</td>\n",
       "      <td>0.638111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.356807</td>\n",
       "      <td>0.356807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.637320</td>\n",
       "      <td>0.637320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.355835</td>\n",
       "      <td>0.355835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.637115</td>\n",
       "      <td>0.637115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.866687</td>\n",
       "      <td>0.866687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.407543</td>\n",
       "      <td>0.407543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.635523</td>\n",
       "      <td>0.635523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.913980</td>\n",
       "      <td>0.913980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.634984</td>\n",
       "      <td>0.634984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.911018</td>\n",
       "      <td>0.911018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.358949</td>\n",
       "      <td>0.358949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.634763</td>\n",
       "      <td>0.634763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.872862</td>\n",
       "      <td>0.872862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.396664</td>\n",
       "      <td>0.396664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.634692</td>\n",
       "      <td>0.634692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.915036</td>\n",
       "      <td>0.915036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.354349</td>\n",
       "      <td>0.354349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.634574</td>\n",
       "      <td>0.634574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.863971</td>\n",
       "      <td>0.863971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.405177</td>\n",
       "      <td>0.405177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_class_weight param_criterion  param_max_depth  param_max_features  \\\n",
       "29   {0: 0.8, 1: 0.2}         entropy             20.0                  15   \n",
       "11   {0: 0.8, 1: 0.2}         entropy             15.0                  15   \n",
       "16   {0: 0.8, 1: 0.2}            gini             20.0                  14   \n",
       "23   {0: 0.8, 1: 0.2}            gini             20.0                  14   \n",
       "71   {0: 0.6, 1: 0.4}         entropy             15.0                   8   \n",
       "31   {0: 0.8, 1: 0.2}            gini             20.0                  15   \n",
       "37   {0: 0.8, 1: 0.2}            gini             20.0                  11   \n",
       "59   {0: 0.6, 1: 0.4}         entropy             10.0                   6   \n",
       "28   {0: 0.8, 1: 0.2}         entropy             20.0                   6   \n",
       "77   {0: 0.6, 1: 0.4}            gini             10.0                  14   \n",
       "\n",
       "    param_min_samples_leaf  param_min_samples_split  \\\n",
       "29                      50                       50   \n",
       "11                     100                       20   \n",
       "16                     100                       50   \n",
       "23                     100                       30   \n",
       "71                     100                       30   \n",
       "31                      30                      100   \n",
       "37                      30                       30   \n",
       "59                      20                      100   \n",
       "28                      10                      100   \n",
       "77                      30                      100   \n",
       "\n",
       "                                               params  split0_test_f1_macro  \\\n",
       "29  {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.638874   \n",
       "11  {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.638447   \n",
       "16  {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.638111   \n",
       "23  {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.637320   \n",
       "71  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.637115   \n",
       "31  {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.635523   \n",
       "37  {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.634984   \n",
       "59  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.634763   \n",
       "28  {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.634692   \n",
       "77  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.634574   \n",
       "\n",
       "    mean_test_f1_macro  std_test_f1_macro  ...  std_test_f1_micro  \\\n",
       "29            0.638874                0.0  ...                0.0   \n",
       "11            0.638447                0.0  ...                0.0   \n",
       "16            0.638111                0.0  ...                0.0   \n",
       "23            0.637320                0.0  ...                0.0   \n",
       "71            0.637115                0.0  ...                0.0   \n",
       "31            0.635523                0.0  ...                0.0   \n",
       "37            0.634984                0.0  ...                0.0   \n",
       "59            0.634763                0.0  ...                0.0   \n",
       "28            0.634692                0.0  ...                0.0   \n",
       "77            0.634574                0.0  ...                0.0   \n",
       "\n",
       "    rank_test_f1_micro  split0_test_f1_0  mean_test_f1_0  std_test_f1_0  \\\n",
       "29                  30          0.914112        0.914112            0.0   \n",
       "11                  12          0.922011        0.922011            0.0   \n",
       "16                  17          0.919415        0.919415            0.0   \n",
       "23                  24          0.918805        0.918805            0.0   \n",
       "71                  72          0.866687        0.866687            0.0   \n",
       "31                  32          0.913980        0.913980            0.0   \n",
       "37                  38          0.911018        0.911018            0.0   \n",
       "59                  60          0.872862        0.872862            0.0   \n",
       "28                  29          0.915036        0.915036            0.0   \n",
       "77                  78          0.863971        0.863971            0.0   \n",
       "\n",
       "    rank_test_f1_0  split0_test_f1_1  mean_test_f1_1  std_test_f1_1  \\\n",
       "29              31          0.363636        0.363636            0.0   \n",
       "11              15          0.354883        0.354883            0.0   \n",
       "16              22          0.356807        0.356807            0.0   \n",
       "23              27          0.355835        0.355835            0.0   \n",
       "71              73          0.407543        0.407543            0.0   \n",
       "31              32          0.357066        0.357066            0.0   \n",
       "37              38          0.358949        0.358949            0.0   \n",
       "59              60          0.396664        0.396664            0.0   \n",
       "28              29          0.354349        0.354349            0.0   \n",
       "77              81          0.405177        0.405177            0.0   \n",
       "\n",
       "    rank_test_f1_1  \n",
       "29             101  \n",
       "11             123  \n",
       "16             118  \n",
       "23             119  \n",
       "71               1  \n",
       "31             116  \n",
       "37             111  \n",
       "59              11  \n",
       "28             125  \n",
       "77               2  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/decision_tree_results.csv').drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree:\n",
    "- criterion: entropy, gini\n",
    "- max_depth: 15-30\n",
    "- max_features: 6 in su\n",
    "- min_leaf: 30, 200 ogni 15\n",
    "- min_samples_split: 20-150 ogni 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_f1_micro</th>\n",
       "      <th>rank_test_f1_micro</th>\n",
       "      <th>split0_test_f1_0</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.700369</td>\n",
       "      <td>0.700369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.915198</td>\n",
       "      <td>0.915198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.485541</td>\n",
       "      <td>0.485541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.917819</td>\n",
       "      <td>0.917819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.479820</td>\n",
       "      <td>0.479820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.694931</td>\n",
       "      <td>0.694931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.918301</td>\n",
       "      <td>0.918301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471561</td>\n",
       "      <td>0.471561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.694066</td>\n",
       "      <td>0.694066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.908461</td>\n",
       "      <td>0.908461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.479672</td>\n",
       "      <td>0.479672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.689678</td>\n",
       "      <td>0.689678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.475128</td>\n",
       "      <td>0.475128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>{'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...</td>\n",
       "      <td>0.688601</td>\n",
       "      <td>0.688601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.905539</td>\n",
       "      <td>0.905539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.471662</td>\n",
       "      <td>0.471662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.676402</td>\n",
       "      <td>0.676402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.471103</td>\n",
       "      <td>0.471103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.675151</td>\n",
       "      <td>0.675151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.880286</td>\n",
       "      <td>0.880286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.470015</td>\n",
       "      <td>0.470015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.674806</td>\n",
       "      <td>0.674806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.469089</td>\n",
       "      <td>0.469089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{0: 0.8, 1: 0.2}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>{'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...</td>\n",
       "      <td>0.673232</td>\n",
       "      <td>0.673232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933446</td>\n",
       "      <td>0.933446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.413018</td>\n",
       "      <td>0.413018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_class_weight param_criterion  param_max_depth  param_max_features  \\\n",
       "15                NaN         entropy              NaN                  13   \n",
       "14   {0: 0.6, 1: 0.4}            gini             20.0                  11   \n",
       "13   {0: 0.6, 1: 0.4}            gini              NaN                  15   \n",
       "16   {0: 0.6, 1: 0.4}         entropy              NaN                   8   \n",
       "18   {0: 0.6, 1: 0.4}            gini              NaN                   8   \n",
       "17   {0: 0.6, 1: 0.4}            gini              NaN                  15   \n",
       "21                NaN         entropy              NaN                   5   \n",
       "23           balanced         entropy             20.0                  11   \n",
       "22           balanced         entropy             20.0                  14   \n",
       "0    {0: 0.8, 1: 0.2}         entropy              NaN                  11   \n",
       "\n",
       "    param_min_samples_leaf  param_min_samples_split  param_n_estimators  \\\n",
       "15                      10                       20                 150   \n",
       "14                      10                       20                 100   \n",
       "13                      10                       20                  50   \n",
       "16                      30                       50                  50   \n",
       "18                      30                      100                 100   \n",
       "17                      30                       20                 150   \n",
       "21                      30                       20                 150   \n",
       "23                      10                      100                 150   \n",
       "22                      30                       50                 150   \n",
       "0                       10                       50                 150   \n",
       "\n",
       "                                               params  split0_test_f1_macro  \\\n",
       "15  {'class_weight': None, 'criterion': 'entropy',...              0.700369   \n",
       "14  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.698820   \n",
       "13  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.694931   \n",
       "16  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.694066   \n",
       "18  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.689678   \n",
       "17  {'class_weight': {0: 0.6, 1: 0.4}, 'criterion'...              0.688601   \n",
       "21  {'class_weight': None, 'criterion': 'entropy',...              0.676402   \n",
       "23  {'class_weight': 'balanced', 'criterion': 'ent...              0.675151   \n",
       "22  {'class_weight': 'balanced', 'criterion': 'ent...              0.674806   \n",
       "0   {'class_weight': {0: 0.8, 1: 0.2}, 'criterion'...              0.673232   \n",
       "\n",
       "    mean_test_f1_macro  ...  std_test_f1_micro  rank_test_f1_micro  \\\n",
       "15            0.700369  ...                0.0                  16   \n",
       "14            0.698820  ...                0.0                  15   \n",
       "13            0.694931  ...                0.0                  14   \n",
       "16            0.694066  ...                0.0                  17   \n",
       "18            0.689678  ...                0.0                  19   \n",
       "17            0.688601  ...                0.0                  18   \n",
       "21            0.676402  ...                0.0                  22   \n",
       "23            0.675151  ...                0.0                  24   \n",
       "22            0.674806  ...                0.0                  23   \n",
       "0             0.673232  ...                0.0                   1   \n",
       "\n",
       "    split0_test_f1_0  mean_test_f1_0  std_test_f1_0  rank_test_f1_0  \\\n",
       "15          0.915198        0.915198            0.0              16   \n",
       "14          0.917819        0.917819            0.0              15   \n",
       "13          0.918301        0.918301            0.0              14   \n",
       "16          0.908461        0.908461            0.0              17   \n",
       "18          0.904227        0.904227            0.0              19   \n",
       "17          0.905539        0.905539            0.0              18   \n",
       "21          0.881701        0.881701            0.0              22   \n",
       "23          0.880286        0.880286            0.0              24   \n",
       "22          0.880524        0.880524            0.0              23   \n",
       "0           0.933446        0.933446            0.0               2   \n",
       "\n",
       "    split0_test_f1_1  mean_test_f1_1  std_test_f1_1  rank_test_f1_1  \n",
       "15          0.485541        0.485541            0.0               1  \n",
       "14          0.479820        0.479820            0.0               2  \n",
       "13          0.471561        0.471561            0.0               6  \n",
       "16          0.479672        0.479672            0.0               3  \n",
       "18          0.475128        0.475128            0.0               4  \n",
       "17          0.471662        0.471662            0.0               5  \n",
       "21          0.471103        0.471103            0.0               7  \n",
       "23          0.470015        0.470015            0.0               8  \n",
       "22          0.469089        0.469089            0.0               9  \n",
       "0           0.413018        0.413018            0.0              25  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/random_forest_results.csv').drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "- criterion: entropy, gini\n",
    "- max_depth: NaN\n",
    "- class_weight: 0.6-0.4, NaN\n",
    "- max_features: 8 in su\n",
    "- min_samples_leaf: 5-30\n",
    "- min_samples_split: 10-150 ogni 10\n",
    "- estimators: 50, 100, 150, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>split0_test_f1_micro</th>\n",
       "      <th>mean_test_f1_micro</th>\n",
       "      <th>std_test_f1_micro</th>\n",
       "      <th>rank_test_f1_micro</th>\n",
       "      <th>split0_test_f1_0</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estima...</td>\n",
       "      <td>0.619855</td>\n",
       "      <td>0.619855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734139</td>\n",
       "      <td>0.734139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828289</td>\n",
       "      <td>0.828289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.411422</td>\n",
       "      <td>0.411422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 4, 'n_estima...</td>\n",
       "      <td>0.611501</td>\n",
       "      <td>0.611501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.721241</td>\n",
       "      <td>0.721241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.817981</td>\n",
       "      <td>0.817981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.405020</td>\n",
       "      <td>0.405020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estima...</td>\n",
       "      <td>0.608182</td>\n",
       "      <td>0.608182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.717067</td>\n",
       "      <td>0.717067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.814732</td>\n",
       "      <td>0.814732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.401633</td>\n",
       "      <td>0.401633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estima...</td>\n",
       "      <td>0.604252</td>\n",
       "      <td>0.604252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.809723</td>\n",
       "      <td>0.809723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.398780</td>\n",
       "      <td>0.398780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 4, 'n_estima...</td>\n",
       "      <td>0.603449</td>\n",
       "      <td>0.603449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.710229</td>\n",
       "      <td>0.710229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.809225</td>\n",
       "      <td>0.809225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.397674</td>\n",
       "      <td>0.397674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 3, 'n_estima...</td>\n",
       "      <td>0.603278</td>\n",
       "      <td>0.603278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.709286</td>\n",
       "      <td>0.709286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.808353</td>\n",
       "      <td>0.808353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.398204</td>\n",
       "      <td>0.398204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.602254</td>\n",
       "      <td>0.602254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.706174</td>\n",
       "      <td>0.706174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.398947</td>\n",
       "      <td>0.398947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 4, 'n_estima...</td>\n",
       "      <td>0.596415</td>\n",
       "      <td>0.596415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.700727</td>\n",
       "      <td>0.700727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.801595</td>\n",
       "      <td>0.801595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.391234</td>\n",
       "      <td>0.391234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.595379</td>\n",
       "      <td>0.595379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.697256</td>\n",
       "      <td>0.697256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.392348</td>\n",
       "      <td>0.392348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 3, 'n_estima...</td>\n",
       "      <td>0.595261</td>\n",
       "      <td>0.595261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.699964</td>\n",
       "      <td>0.699964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.801119</td>\n",
       "      <td>0.801119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.389403</td>\n",
       "      <td>0.389403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "0                   1.0                5                 100   \n",
       "26                  1.0                4                 100   \n",
       "27                  1.0                5                  50   \n",
       "28                  1.0                5                  25   \n",
       "29                  1.0                4                  50   \n",
       "31                  1.0                3                 100   \n",
       "32                  0.1                5                 100   \n",
       "34                  1.0                4                  25   \n",
       "37                  0.1                4                 100   \n",
       "35                  1.0                3                  50   \n",
       "\n",
       "                                               params  split0_test_f1_macro  \\\n",
       "0   {'learning_rate': 1, 'max_depth': 5, 'n_estima...              0.619855   \n",
       "26  {'learning_rate': 1, 'max_depth': 4, 'n_estima...              0.611501   \n",
       "27  {'learning_rate': 1, 'max_depth': 5, 'n_estima...              0.608182   \n",
       "28  {'learning_rate': 1, 'max_depth': 5, 'n_estima...              0.604252   \n",
       "29  {'learning_rate': 1, 'max_depth': 4, 'n_estima...              0.603449   \n",
       "31  {'learning_rate': 1, 'max_depth': 3, 'n_estima...              0.603278   \n",
       "32  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...              0.602254   \n",
       "34  {'learning_rate': 1, 'max_depth': 4, 'n_estima...              0.596415   \n",
       "37  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...              0.595379   \n",
       "35  {'learning_rate': 1, 'max_depth': 3, 'n_estima...              0.595261   \n",
       "\n",
       "    mean_test_f1_macro  std_test_f1_macro  rank_test_f1_macro  \\\n",
       "0             0.619855                0.0                 1.0   \n",
       "26            0.611501                0.0                 2.0   \n",
       "27            0.608182                0.0                 3.0   \n",
       "28            0.604252                0.0                 4.0   \n",
       "29            0.603449                0.0                 5.0   \n",
       "31            0.603278                0.0                 6.0   \n",
       "32            0.602254                0.0                 7.0   \n",
       "34            0.596415                0.0                 8.0   \n",
       "37            0.595379                0.0                 9.0   \n",
       "35            0.595261                0.0                10.0   \n",
       "\n",
       "    split0_test_f1_micro  mean_test_f1_micro  std_test_f1_micro  \\\n",
       "0               0.734139            0.734139                0.0   \n",
       "26              0.721241            0.721241                0.0   \n",
       "27              0.717067            0.717067                0.0   \n",
       "28              0.710932            0.710932                0.0   \n",
       "29              0.710229            0.710229                0.0   \n",
       "31              0.709286            0.709286                0.0   \n",
       "32              0.706174            0.706174                0.0   \n",
       "34              0.700727            0.700727                0.0   \n",
       "37              0.697256            0.697256                0.0   \n",
       "35              0.699964            0.699964                0.0   \n",
       "\n",
       "    rank_test_f1_micro  split0_test_f1_0  mean_test_f1_0  std_test_f1_0  \\\n",
       "0                    1          0.828289        0.828289            0.0   \n",
       "26                  27          0.817981        0.817981            0.0   \n",
       "27                  28          0.814732        0.814732            0.0   \n",
       "28                  29          0.809723        0.809723            0.0   \n",
       "29                  30          0.809225        0.809225            0.0   \n",
       "31                  32          0.808353        0.808353            0.0   \n",
       "32                  33          0.805561        0.805561            0.0   \n",
       "34                  35          0.801595        0.801595            0.0   \n",
       "37                  38          0.798410        0.798410            0.0   \n",
       "35                  36          0.801119        0.801119            0.0   \n",
       "\n",
       "    rank_test_f1_0  split0_test_f1_1  mean_test_f1_1  std_test_f1_1  \\\n",
       "0               12          0.411422        0.411422            0.0   \n",
       "26              27          0.405020        0.405020            0.0   \n",
       "27              28          0.401633        0.401633            0.0   \n",
       "28              30          0.398780        0.398780            0.0   \n",
       "29              31          0.397674        0.397674            0.0   \n",
       "31              33          0.398204        0.398204            0.0   \n",
       "32              34          0.398947        0.398947            0.0   \n",
       "34              36          0.391234        0.391234            0.0   \n",
       "37              41          0.392348        0.392348            0.0   \n",
       "35              38          0.389403        0.389403            0.0   \n",
       "\n",
       "    rank_test_f1_1  \n",
       "0                1  \n",
       "26               2  \n",
       "27               3  \n",
       "28               5  \n",
       "29               7  \n",
       "31               6  \n",
       "32               4  \n",
       "34               9  \n",
       "37               8  \n",
       "35              11  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/xgb_results.csv').drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB:\n",
    "- lr: 0.1-1\n",
    "- max_depth: 3-15\n",
    "- n_estimators: 50-175, ogni 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>split0_test_f1_micro</th>\n",
       "      <th>mean_test_f1_micro</th>\n",
       "      <th>std_test_f1_micro</th>\n",
       "      <th>rank_test_f1_micro</th>\n",
       "      <th>split0_test_f1_0</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.1, '...</td>\n",
       "      <td>0.584997</td>\n",
       "      <td>0.584997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724578</td>\n",
       "      <td>0.724578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.825676</td>\n",
       "      <td>0.825676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.344317</td>\n",
       "      <td>0.344317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.1, '...</td>\n",
       "      <td>0.584787</td>\n",
       "      <td>0.584787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.724728</td>\n",
       "      <td>0.724728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.0001...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.01, ...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.001,...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.001,...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>25</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.001,...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>25</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.0001...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.01, ...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 0.0001...</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_algorithm  param_learning_rate  param_n_estimators  \\\n",
       "10           SAMME               0.1000                 100   \n",
       "9            SAMME               0.1000                  50   \n",
       "2            SAMME               0.0001                  50   \n",
       "1            SAMME               0.0100                  50   \n",
       "4            SAMME               0.0010                 100   \n",
       "5            SAMME               0.0010                  50   \n",
       "6            SAMME               0.0010                  25   \n",
       "3            SAMME               0.0001                  25   \n",
       "0            SAMME               0.0100                  25   \n",
       "8            SAMME               0.0001                 100   \n",
       "\n",
       "                                               params  split0_test_f1_macro  \\\n",
       "10  {'algorithm': 'SAMME', 'learning_rate': 0.1, '...              0.584997   \n",
       "9   {'algorithm': 'SAMME', 'learning_rate': 0.1, '...              0.584787   \n",
       "2   {'algorithm': 'SAMME', 'learning_rate': 0.0001...              0.583025   \n",
       "1   {'algorithm': 'SAMME', 'learning_rate': 0.01, ...              0.583025   \n",
       "4   {'algorithm': 'SAMME', 'learning_rate': 0.001,...              0.583025   \n",
       "5   {'algorithm': 'SAMME', 'learning_rate': 0.001,...              0.583025   \n",
       "6   {'algorithm': 'SAMME', 'learning_rate': 0.001,...              0.583025   \n",
       "3   {'algorithm': 'SAMME', 'learning_rate': 0.0001...              0.583025   \n",
       "0   {'algorithm': 'SAMME', 'learning_rate': 0.01, ...              0.583025   \n",
       "8   {'algorithm': 'SAMME', 'learning_rate': 0.0001...              0.583025   \n",
       "\n",
       "    mean_test_f1_macro  std_test_f1_macro  rank_test_f1_macro  \\\n",
       "10            0.584997                0.0                 1.0   \n",
       "9             0.584787                0.0                 2.0   \n",
       "2             0.583025                0.0                 3.0   \n",
       "1             0.583025                0.0                 3.0   \n",
       "4             0.583025                0.0                 3.0   \n",
       "5             0.583025                0.0                 3.0   \n",
       "6             0.583025                0.0                 3.0   \n",
       "3             0.583025                0.0                 3.0   \n",
       "0             0.583025                0.0                 3.0   \n",
       "8             0.583025                0.0                 3.0   \n",
       "\n",
       "    split0_test_f1_micro  mean_test_f1_micro  std_test_f1_micro  \\\n",
       "10              0.724578            0.724578                0.0   \n",
       "9               0.724728            0.724728                0.0   \n",
       "2               0.725566            0.725566                0.0   \n",
       "1               0.725566            0.725566                0.0   \n",
       "4               0.725566            0.725566                0.0   \n",
       "5               0.725566            0.725566                0.0   \n",
       "6               0.725566            0.725566                0.0   \n",
       "3               0.725566            0.725566                0.0   \n",
       "0               0.725566            0.725566                0.0   \n",
       "8               0.725566            0.725566                0.0   \n",
       "\n",
       "    rank_test_f1_micro  split0_test_f1_0  mean_test_f1_0  std_test_f1_0  \\\n",
       "10                  11          0.825676        0.825676            0.0   \n",
       "9                   10          0.825837        0.825837            0.0   \n",
       "2                    1          0.826820        0.826820            0.0   \n",
       "1                    1          0.826820        0.826820            0.0   \n",
       "4                    1          0.826820        0.826820            0.0   \n",
       "5                    1          0.826820        0.826820            0.0   \n",
       "6                    1          0.826820        0.826820            0.0   \n",
       "3                    1          0.826820        0.826820            0.0   \n",
       "0                    1          0.826820        0.826820            0.0   \n",
       "8                    1          0.826820        0.826820            0.0   \n",
       "\n",
       "    rank_test_f1_0  split0_test_f1_1  mean_test_f1_1  std_test_f1_1  \\\n",
       "10              11          0.344317        0.344317            0.0   \n",
       "9               10          0.343738        0.343738            0.0   \n",
       "2                1          0.339230        0.339230            0.0   \n",
       "1                1          0.339230        0.339230            0.0   \n",
       "4                1          0.339230        0.339230            0.0   \n",
       "5                1          0.339230        0.339230            0.0   \n",
       "6                1          0.339230        0.339230            0.0   \n",
       "3                1          0.339230        0.339230            0.0   \n",
       "0                1          0.339230        0.339230            0.0   \n",
       "8                1          0.339230        0.339230            0.0   \n",
       "\n",
       "    rank_test_f1_1  \n",
       "10               4  \n",
       "9                5  \n",
       "2                6  \n",
       "1                6  \n",
       "4                6  \n",
       "5                6  \n",
       "6                6  \n",
       "3                6  \n",
       "0                6  \n",
       "8                6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/ada_boost_results.csv').drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada-Boost:\n",
    "- lr: 0.1-0.00001 ogni 0.0005\n",
    "- n_estimators: 25-175, ogni 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "train_data = pd.read_csv('../../data/ml_datasets/oversampling/train_set.csv').sample(frac = 1, random_state=RANDOM_STATE) # Shuffling the data to not introduce bias\n",
    "val_data = pd.read_csv('../../data/ml_datasets/oversampling/val_set.csv')\n",
    "testing_data = pd.read_csv('../../data/ml_datasets/oversampling/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.pop('label')\n",
    "val_label = val_data.pop('label')\n",
    "test_label = testing_data.pop('label')\n",
    "\n",
    "train_set = train_data\n",
    "train_set['race_season%autumn'] = train_set['race_season%autumn'].astype(int)\n",
    "train_set['race_season%spring'] = train_set['race_season%spring'].astype(int)\n",
    "train_set['race_season%summer'] = train_set['race_season%summer'].astype(int)\n",
    "train_set['race_season%winter'] = train_set['race_season%winter'].astype(int)\n",
    "\n",
    "val_set = val_data\n",
    "val_set['race_season%autumn'] = val_set['race_season%autumn'].astype(int)\n",
    "val_set['race_season%spring'] = val_set['race_season%spring'].astype(int)\n",
    "val_set['race_season%summer'] = val_set['race_season%summer'].astype(int)\n",
    "val_set['race_season%winter'] = val_set['race_season%winter'].astype(int)\n",
    "\n",
    "test_set = testing_data\n",
    "test_set['race_season%autumn'] = test_set['race_season%autumn'].astype(int)\n",
    "test_set['race_season%spring'] = test_set['race_season%spring'].astype(int)\n",
    "test_set['race_season%summer'] = test_set['race_season%summer'].astype(int)\n",
    "test_set['race_season%winter'] = test_set['race_season%winter'].astype(int)\n",
    "\n",
    "N_JOBS = 4\n",
    "USER = 'Jacopo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for the best hyperparameters\n",
    "def f1_class_scorer(class_index):\n",
    "    # Function to calculate F1 score for a specific class\n",
    "    def score_function(y_true, y_pred):\n",
    "        return f1_score(y_true, y_pred, average=None)[class_index] # Compute the F1 score for each class and return the one specified\n",
    "    return make_scorer(score_function)\n",
    "\n",
    "# Scorer for class 0 and 1\n",
    "f1_class_0 = f1_class_scorer(0)\n",
    "f1_class_1 = f1_class_scorer(1)\n",
    "\n",
    "scoring={\n",
    "        'f1_macro': 'f1_macro', # F1 macro for each class\n",
    "        'f1_0': f1_class_0,     # F1 only for class 0\n",
    "        'f1_1': f1_class_1      # F1 only for class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "def func(*args):\n",
    "    global i\n",
    "    print(f'Configurazione: {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = len(train_set.iloc[0])\n",
    "\n",
    "train_set = train_set.to_numpy()\n",
    "train_label = train_label.to_numpy()\n",
    "\n",
    "val_set = val_set.to_numpy()\n",
    "val_label = val_label.to_numpy()\n",
    "\n",
    "split_index = np.concatenate([\n",
    "    np.full(len(train_set), -1), # -1 for training\n",
    "    np.zeros(len(val_set))       # 0 for validation\n",
    "])\n",
    "\n",
    "X_combined = np.vstack((train_set, val_set))\n",
    "y_combined = np.concatenate((train_label, val_label))\n",
    "\n",
    "ps = PredefinedSplit(test_fold=split_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree:\n",
    "- criterion: entropy, gini\n",
    "- max_depth: 15-30\n",
    "- max_features: 6 in su\n",
    "- min_leaf: 30-210 ogni 15\n",
    "- min_samples_split: 20-150 ogni 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": Integer(15, 30),\n",
    "              \"max_features\": Integer(6, N_FEATURES),\n",
    "              \"min_samples_split\": Categorical(list(range(20, 151, 10))),\n",
    "              \"min_samples_leaf\": Categorical(list(range(30, 211, 15))),\n",
    "              \"criterion\": Categorical(['gini', 'entropy'])}\n",
    "n_iter_search = 100 # Number of iterations\n",
    "clf = tree.DecisionTreeClassifier() # Model\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = BayesSearchCV(clf, search_spaces=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit='f1_macro',\n",
    "                            cv=ps)\n",
    "i = 1\n",
    "rand_search.fit(X_combined, y_combined, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_decision_tree_results_bayes.csv', index=False)\n",
    "df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "- criterion: entropy, gini\n",
    "- max_depth: NaN\n",
    "- class_weight: 0.6-0.4, NaN\n",
    "- max_features: 8 in su\n",
    "- min_samples_leaf: 5-30\n",
    "- min_samples_split: 10-150 ogni 10\n",
    "- estimators: 50, 100, 150, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_features\": Integer(8, N_FEATURES),\n",
    "              \"min_samples_split\": Categorical(list(range(10, 151, 10))),\n",
    "              \"min_samples_leaf\": Integer(5, 30),\n",
    "              \"criterion\": Categorical(['gini', 'entropy']),\n",
    "              \"n_estimators\": Categorical([50, 100, 150, 200]),\n",
    "              \"class_weight\": Categorical([{0:0.6, 1:0.4}, None])}\n",
    "n_iter_search = 100 # Number of iterations\n",
    "clf = RandomForestClassifier() # Model\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = BayesSearchCV(clf, search_spaces=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit='f1_macro',\n",
    "                            cv=ps)\n",
    "i = 1\n",
    "rand_search.fit(X_combined, y_combined, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_random_forest_results_bayes.csv', index=False)\n",
    "df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB:\n",
    "- lr: 0.1-1\n",
    "- max_depth: 3-15\n",
    "- n_estimators: 50-175, ogni 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": Categorical(list(range(50, 176, 25))),\n",
    "    \"max_depth\": Integer(3, 15), \n",
    "    \"learning_rate\": Real(0.1, 1)\n",
    "}\n",
    "n_iter_search = 100 # Number of iterations\n",
    "clf = XGBClassifier() # Model\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = BayesSearchCV(clf, search_spaces=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit='f1_macro',\n",
    "                            cv=ps)\n",
    "i = 1\n",
    "rand_search.fit(X_combined, y_combined, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_xgb_results_bayes.csv', index=False)\n",
    "df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada-Boost:\n",
    "- lr: 0.1-0.00001 ogni 0.0005\n",
    "- n_estimators: 25-175, ogni 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": Categorical(list(range(25, 176, 25))),  \n",
    "    \"learning_rate\": Categorical(np.arange(0.1, 0.00001, -0.0005).tolist()),  \n",
    "    \"algorithm\": Categorical(['SAMME']) \n",
    "}\n",
    "n_iter_search = 100 # Number of iterations\n",
    "clf = AdaBoostClassifier() # Model\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = BayesSearchCV(clf, search_spaces=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit='f1_macro',\n",
    "                            cv=ps)\n",
    "i = 1\n",
    "rand_search.fit(X_combined, y_combined, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_ada_boost_results_bayes.csv', index=False)\n",
    "df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_see = ['mean_test_f1_1', 'mean_test_f1_0', 'mean_test_f1_macro', 'model']\n",
    "USER_1 = 'Jacopo'\n",
    "USER_2 = 'Simone'\n",
    "\n",
    "models = ['ada_boost', 'xgb', 'random_forest']\n",
    "path_dt = f'../../data/ml_datasets/oversampling/model_selection/{USER_1}_decision_tree_results_bayes.csv'\n",
    "path_ada = f'../../data/ml_datasets/oversampling/model_selection/{USER_1}_ada_boost_results_bayes.csv'\n",
    "path_xgb = f'../../data/ml_datasets/oversampling/model_selection/{USER_2}_xgb_results_bayes.csv'\n",
    "path_rf = f'../../data/ml_datasets/oversampling/model_selection/{USER_2}_random_forest_results_bayes.csv'\n",
    "\n",
    "path_list = [path_ada, path_xgb, path_rf]\n",
    "\n",
    "df_results = pd.read_csv(path_dt)\n",
    "df_results['model'] = 'decision_tree'\n",
    "df_results = df_results[columns_to_see]\n",
    "\n",
    "for i, path in enumerate(path_list):\n",
    "    df = pd.read_csv(path)\n",
    "    df['model'] = models[i]\n",
    "    df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "    df = df[columns_to_see]\n",
    "\n",
    "    df_results = pd.concat([df_results, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486121</td>\n",
       "      <td>0.921442</td>\n",
       "      <td>0.703781</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481108</td>\n",
       "      <td>0.926045</td>\n",
       "      <td>0.703577</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485595</td>\n",
       "      <td>0.921474</td>\n",
       "      <td>0.703535</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.488323</td>\n",
       "      <td>0.918479</td>\n",
       "      <td>0.703401</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487602</td>\n",
       "      <td>0.918668</td>\n",
       "      <td>0.703135</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.478780</td>\n",
       "      <td>0.927105</td>\n",
       "      <td>0.702943</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.484297</td>\n",
       "      <td>0.921266</td>\n",
       "      <td>0.702782</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.481473</td>\n",
       "      <td>0.923881</td>\n",
       "      <td>0.702677</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.483113</td>\n",
       "      <td>0.921988</td>\n",
       "      <td>0.702550</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.485114</td>\n",
       "      <td>0.919681</td>\n",
       "      <td>0.702398</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_f1_1  mean_test_f1_0  mean_test_f1_macro          model\n",
       "0        0.486121        0.921442            0.703781  random_forest\n",
       "1        0.481108        0.926045            0.703577  random_forest\n",
       "0        0.485595        0.921474            0.703535            xgb\n",
       "1        0.488323        0.918479            0.703401            xgb\n",
       "2        0.487602        0.918668            0.703135  random_forest\n",
       "3        0.478780        0.927105            0.702943  random_forest\n",
       "4        0.484297        0.921266            0.702782  random_forest\n",
       "5        0.481473        0.923881            0.702677  random_forest\n",
       "2        0.483113        0.921988            0.702550            xgb\n",
       "3        0.485114        0.919681            0.702398            xgb"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner model is the \"Random Forest\", next step is to take the \"best\" hyperparameters and retrain the model on the whole developmente set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>split0_test_f1_0</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>OrderedDict([('class_weight', None), ('criteri...</td>\n",
       "      <td>0.703781</td>\n",
       "      <td>0.703781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921442</td>\n",
       "      <td>0.921442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.486121</td>\n",
       "      <td>0.486121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>OrderedDict([('class_weight', {0: 0.6, 1: 0.4}...</td>\n",
       "      <td>0.703577</td>\n",
       "      <td>0.703577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926045</td>\n",
       "      <td>0.926045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.481108</td>\n",
       "      <td>0.481108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>OrderedDict([('class_weight', None), ('criteri...</td>\n",
       "      <td>0.703135</td>\n",
       "      <td>0.703135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.918668</td>\n",
       "      <td>0.918668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.487602</td>\n",
       "      <td>0.487602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{0: 0.6, 1: 0.4}</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>OrderedDict([('class_weight', {0: 0.6, 1: 0.4}...</td>\n",
       "      <td>0.702943</td>\n",
       "      <td>0.702943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927105</td>\n",
       "      <td>0.927105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.478780</td>\n",
       "      <td>0.478780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>OrderedDict([('class_weight', None), ('criteri...</td>\n",
       "      <td>0.702782</td>\n",
       "      <td>0.702782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.921266</td>\n",
       "      <td>0.921266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.484297</td>\n",
       "      <td>0.484297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_class_weight param_criterion  param_max_features  \\\n",
       "0                NaN         entropy                   8   \n",
       "1   {0: 0.6, 1: 0.4}            gini                   8   \n",
       "2                NaN            gini                   8   \n",
       "3   {0: 0.6, 1: 0.4}         entropy                   8   \n",
       "4                NaN         entropy                   8   \n",
       "\n",
       "   param_min_samples_leaf  param_min_samples_split  param_n_estimators  \\\n",
       "0                       5                       20                 150   \n",
       "1                       5                       20                 200   \n",
       "2                       5                       20                 150   \n",
       "3                       5                       20                 200   \n",
       "4                       5                       20                 200   \n",
       "\n",
       "                                              params  split0_test_f1_macro  \\\n",
       "0  OrderedDict([('class_weight', None), ('criteri...              0.703781   \n",
       "1  OrderedDict([('class_weight', {0: 0.6, 1: 0.4}...              0.703577   \n",
       "2  OrderedDict([('class_weight', None), ('criteri...              0.703135   \n",
       "3  OrderedDict([('class_weight', {0: 0.6, 1: 0.4}...              0.702943   \n",
       "4  OrderedDict([('class_weight', None), ('criteri...              0.702782   \n",
       "\n",
       "   mean_test_f1_macro  std_test_f1_macro  rank_test_f1_macro  \\\n",
       "0            0.703781                0.0                   1   \n",
       "1            0.703577                0.0                   2   \n",
       "2            0.703135                0.0                   3   \n",
       "3            0.702943                0.0                   4   \n",
       "4            0.702782                0.0                   5   \n",
       "\n",
       "   split0_test_f1_0  mean_test_f1_0  std_test_f1_0  rank_test_f1_0  \\\n",
       "0          0.921442        0.921442            0.0              21   \n",
       "1          0.926045        0.926045            0.0               8   \n",
       "2          0.918668        0.918668            0.0              31   \n",
       "3          0.927105        0.927105            0.0               6   \n",
       "4          0.921266        0.921266            0.0              25   \n",
       "\n",
       "   split0_test_f1_1  mean_test_f1_1  std_test_f1_1  rank_test_f1_1  \n",
       "0          0.486121        0.486121            0.0               6  \n",
       "1          0.481108        0.481108            0.0              27  \n",
       "2          0.487602        0.487602            0.0               3  \n",
       "3          0.478780        0.478780            0.0              45  \n",
       "4          0.484297        0.484297            0.0              11  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_2 = 'Simone'\n",
    "path_rf = f'../../data/ml_datasets/oversampling/model_selection/{USER_2}_random_forest_results_bayes.csv'\n",
    "df_rf = pd.read_csv(path_rf).drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])\n",
    "df_rf.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df_rf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.546106\n",
       "1    0.453894\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = pd.concat([train_data, val_data])\n",
    "dev_label = pd.concat([train_label, val_label])\n",
    "dev_label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     27446\n",
      "           1       0.42      0.36      0.38      4203\n",
      "\n",
      "    accuracy                           0.85     31649\n",
      "   macro avg       0.66      0.64      0.65     31649\n",
      "weighted avg       0.84      0.85      0.84     31649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(class_weight=None, criterion='entropy', max_features=8, min_samples_leaf=5, min_samples_split=20, n_estimators=150)\n",
    "\n",
    "rf_clf.fit(dev_set, dev_label)\n",
    "\n",
    "predicitions = rf_clf.predict(test_set)\n",
    "print(classification_report(test_label, predicitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7d3a9faf50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0).clf()\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, predicitions)\n",
    "auc = metrics.roc_auc_score(test_label, predicitions)\n",
    "plt.plot(fpr,tpr,label=\"RandomForest, auc=\"+str(auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.legend(loc=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

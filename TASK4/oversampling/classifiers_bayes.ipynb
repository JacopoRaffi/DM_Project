{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Bayesian Search\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 22:07:32.636702: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-19 22:07:32.657759: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734642452.680677    7902 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734642452.689506    7902 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-19 22:07:32.714822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#to find the best set of parameter setting, we can run a grid search\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import wittgenstein as lw\n",
    "import keras_tuner\n",
    "import keras\n",
    "from keras_tuner import HyperParameters\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from statistics import mean, stdev\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import loguniform as sp_loguniform\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_boost\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_algorithm', 'param_learning_rate', 'param_n_estimators',\n",
      "       'params', 'split0_test_f1_micro', 'mean_test_f1_micro',\n",
      "       'std_test_f1_micro', 'rank_test_f1_micro', 'split0_test_f1_0',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'rank_test_f1_0', 'split0_test_f1_1',\n",
      "       'mean_test_f1_1', 'std_test_f1_1', 'rank_test_f1_1'],\n",
      "      dtype='object')\n",
      "nn\n",
      "Index(['batch_size', 'epochs', 'units_layer1', 'units_layer2', 'drop_rate',\n",
      "       'learning_rate', 'mean_test_f1_micro', 'std_test_f1_micro',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'mean_test_f1_1', 'std_test_f1_1'],\n",
      "      dtype='object')\n",
      "xgb\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_learning_rate', 'param_max_depth', 'param_n_estimators',\n",
      "       'params', 'split0_test_f1_micro', 'mean_test_f1_micro',\n",
      "       'std_test_f1_micro', 'rank_test_f1_micro', 'split0_test_f1_0',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'rank_test_f1_0', 'split0_test_f1_1',\n",
      "       'mean_test_f1_1', 'std_test_f1_1', 'rank_test_f1_1'],\n",
      "      dtype='object')\n",
      "naive_bayes\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'params', 'split0_test_f1_micro', 'mean_test_f1_micro',\n",
      "       'std_test_f1_micro', 'rank_test_f1_micro', 'split0_test_f1_0',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'rank_test_f1_0', 'split0_test_f1_1',\n",
      "       'mean_test_f1_1', 'std_test_f1_1', 'rank_test_f1_1'],\n",
      "      dtype='object')\n",
      "random_forest\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_class_weight', 'param_criterion', 'param_max_depth',\n",
      "       'param_max_features', 'param_min_samples_leaf',\n",
      "       'param_min_samples_split', 'param_n_estimators', 'params',\n",
      "       'split0_test_f1_micro', 'mean_test_f1_micro', 'std_test_f1_micro',\n",
      "       'rank_test_f1_micro', 'split0_test_f1_0', 'mean_test_f1_0',\n",
      "       'std_test_f1_0', 'rank_test_f1_0', 'split0_test_f1_1', 'mean_test_f1_1',\n",
      "       'std_test_f1_1', 'rank_test_f1_1'],\n",
      "      dtype='object')\n",
      "decision_tree\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_class_weight', 'param_criterion', 'param_max_depth',\n",
      "       'param_max_features', 'param_min_samples_leaf',\n",
      "       'param_min_samples_split', 'params', 'split0_test_f1_micro',\n",
      "       'mean_test_f1_micro', 'std_test_f1_micro', 'rank_test_f1_micro',\n",
      "       'split0_test_f1_0', 'mean_test_f1_0', 'std_test_f1_0', 'rank_test_f1_0',\n",
      "       'split0_test_f1_1', 'mean_test_f1_1', 'std_test_f1_1',\n",
      "       'rank_test_f1_1'],\n",
      "      dtype='object')\n",
      "svm\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_C', 'params', 'split0_test_f1_micro', 'mean_test_f1_micro',\n",
      "       'std_test_f1_micro', 'rank_test_f1_micro', 'split0_test_f1_0',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'rank_test_f1_0', 'split0_test_f1_1',\n",
      "       'mean_test_f1_1', 'std_test_f1_1', 'rank_test_f1_1'],\n",
      "      dtype='object')\n",
      "rule_based\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_k', 'param_prune_size', 'params', 'split0_test_f1_macro',\n",
      "       'mean_test_f1_macro', 'std_test_f1_macro', 'rank_test_f1_macro',\n",
      "       'split0_test_f1_0', 'mean_test_f1_0', 'std_test_f1_0', 'rank_test_f1_0',\n",
      "       'split0_test_f1_1', 'mean_test_f1_1', 'std_test_f1_1',\n",
      "       'rank_test_f1_1'],\n",
      "      dtype='object')\n",
      "knn\n",
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_algorithm', 'param_n_neighbors', 'params',\n",
      "       'split0_test_f1_micro', 'mean_test_f1_micro', 'std_test_f1_micro',\n",
      "       'rank_test_f1_micro', 'split0_test_f1_0', 'mean_test_f1_0',\n",
      "       'std_test_f1_0', 'rank_test_f1_0', 'split0_test_f1_1', 'mean_test_f1_1',\n",
      "       'std_test_f1_1', 'rank_test_f1_1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge results from previous random search\n",
    "USER_1 = 'Jacopo'\n",
    "USER_2 = 'Simone'\n",
    "\n",
    "models = ['ada_boost', 'nn', 'xgb', 'naive_bayes', 'random_forest', 'decision_tree', 'svm', 'rule_based', 'knn']\n",
    "\n",
    "for model in models:\n",
    "    path_1 = f'../../data/ml_datasets/oversampling/model_selection/{USER_1}_{model}_results.csv'\n",
    "    path_2 = f'../../data/ml_datasets/oversampling/model_selection/{USER_2}_{model}_results.csv'\n",
    "\n",
    "    concatenate_path = f'../../data/ml_datasets/oversampling/model_selection/{model}_results.csv'\n",
    "\n",
    "    df1 = pd.read_csv(path_1)\n",
    "    df2 = pd.read_csv(path_2)\n",
    "    print(model)\n",
    "    print(df2.columns)\n",
    "\n",
    "    df2['mean_test_f1_macro'] = (df2['mean_test_f1_1'] + df2['mean_test_f1_0']) / 2\n",
    "    df2['mean_test_f1_macro'] = (df2['std_test_f1_1'] + df2['std_test_f1_0']) / 2\n",
    "\n",
    "    # Concatena le righe\n",
    "    df_concatenato = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Salva il risultato in un nuovo CSV\n",
    "    df_concatenato.to_csv(concatenate_path, index=False)  #to concatenate the two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_see = ['mean_test_f1_micro', 'mean_test_f1_1', 'mean_test_f1_0', 'mean_test_f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/ada_boost_results.csv')\n",
    "# df.sort_values(by='mean_test_f1_micro', ascending=False, inplace=True)\n",
    "# params= [col for col in df.columns if col.startswith(\"param_classifier__\")]\n",
    "# df.head(n=10)[columns_to_see+params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['batch_size', 'epochs', 'units_layer1', 'units_layer2', 'drop_rate',\n",
      "       'learning_rate', 'mean_test_f1_micro', 'std_test_f1_micro',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'mean_test_f1_1', 'std_test_f1_1',\n",
      "       'mean_test_f1_macro'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "models = ['ada_boost', 'nn', 'xgb', 'naive_bayes', 'random_forest', 'decision_tree', 'svm', 'rule_based', 'knn']\n",
    "\n",
    "df_results = pd.read_csv('../../data/ml_datasets/oversampling/model_selection/nn_results.csv')\n",
    "df_results = df_results.rename(columns={'mean_f1_micro': 'mean_test_f1_micro', \n",
    "                                        'std_f1_micro': 'std_test_f1_micro',\n",
    "                                        'mean_f1_1': 'mean_test_f1_1',\n",
    "                                        'std_f1_1': 'std_test_f1_1',\n",
    "                                        'mean_f1_0': 'mean_test_f1_0',\n",
    "                                        'std_f1_0': 'std_test_f1_0',\n",
    "                                        'mean_f1_macro': 'mean_test_f1_macro', \n",
    "                                        'std_f1_macro': 'std_test_f1_macro',})\n",
    "print(df_results.columns)\n",
    "df_results = df_results[columns_to_see]\n",
    "df_results['model'] = 'nn'\n",
    "models.remove('nn')\n",
    "\n",
    "columns_to_see = ['model'] + columns_to_see\n",
    "for model in models:\n",
    "    path = f'../../data/ml_datasets/oversampling/model_selection/{model}_results.csv'\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df['model'] = model\n",
    "    df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "    df = df.head(10)\n",
    "    df = df[columns_to_see]\n",
    "\n",
    "    df_results = pd.concat([df_results, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_f1_micro</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.854396</td>\n",
       "      <td>0.485541</td>\n",
       "      <td>0.915198</td>\n",
       "      <td>0.700369</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.858062</td>\n",
       "      <td>0.479820</td>\n",
       "      <td>0.917819</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.858481</td>\n",
       "      <td>0.471561</td>\n",
       "      <td>0.918301</td>\n",
       "      <td>0.694931</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.844311</td>\n",
       "      <td>0.479672</td>\n",
       "      <td>0.908461</td>\n",
       "      <td>0.694066</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.838012</td>\n",
       "      <td>0.475128</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>0.689678</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.839732</td>\n",
       "      <td>0.471662</td>\n",
       "      <td>0.905539</td>\n",
       "      <td>0.688601</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.806650</td>\n",
       "      <td>0.471103</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>0.676402</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.804689</td>\n",
       "      <td>0.470015</td>\n",
       "      <td>0.880286</td>\n",
       "      <td>0.675151</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.804944</td>\n",
       "      <td>0.469089</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.674806</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880446</td>\n",
       "      <td>0.413018</td>\n",
       "      <td>0.933446</td>\n",
       "      <td>0.673232</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.848650</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.914112</td>\n",
       "      <td>0.638874</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.860845</td>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.922011</td>\n",
       "      <td>0.638447</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.856775</td>\n",
       "      <td>0.356807</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>0.638111</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.855788</td>\n",
       "      <td>0.355835</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.637320</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.782350</td>\n",
       "      <td>0.407543</td>\n",
       "      <td>0.866687</td>\n",
       "      <td>0.637115</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.848261</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.913980</td>\n",
       "      <td>0.635523</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.843728</td>\n",
       "      <td>0.358949</td>\n",
       "      <td>0.911018</td>\n",
       "      <td>0.634984</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.789981</td>\n",
       "      <td>0.396664</td>\n",
       "      <td>0.872862</td>\n",
       "      <td>0.634763</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.849832</td>\n",
       "      <td>0.354349</td>\n",
       "      <td>0.915036</td>\n",
       "      <td>0.634692</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.778579</td>\n",
       "      <td>0.405177</td>\n",
       "      <td>0.863971</td>\n",
       "      <td>0.634574</td>\n",
       "      <td>decision_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734139</td>\n",
       "      <td>0.411422</td>\n",
       "      <td>0.828289</td>\n",
       "      <td>0.619855</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.721241</td>\n",
       "      <td>0.405020</td>\n",
       "      <td>0.817981</td>\n",
       "      <td>0.611501</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.717067</td>\n",
       "      <td>0.401633</td>\n",
       "      <td>0.814732</td>\n",
       "      <td>0.608182</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.710932</td>\n",
       "      <td>0.398780</td>\n",
       "      <td>0.809723</td>\n",
       "      <td>0.604252</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.710229</td>\n",
       "      <td>0.397674</td>\n",
       "      <td>0.809225</td>\n",
       "      <td>0.603449</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.709286</td>\n",
       "      <td>0.398204</td>\n",
       "      <td>0.808353</td>\n",
       "      <td>0.603278</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.706174</td>\n",
       "      <td>0.398947</td>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.602254</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817109</td>\n",
       "      <td>0.309474</td>\n",
       "      <td>0.894596</td>\n",
       "      <td>0.602035</td>\n",
       "      <td>rule_based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.765397</td>\n",
       "      <td>0.336282</td>\n",
       "      <td>0.857517</td>\n",
       "      <td>0.596900</td>\n",
       "      <td>rule_based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.700727</td>\n",
       "      <td>0.391234</td>\n",
       "      <td>0.801595</td>\n",
       "      <td>0.596415</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.697256</td>\n",
       "      <td>0.392348</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.595379</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.699964</td>\n",
       "      <td>0.389403</td>\n",
       "      <td>0.801119</td>\n",
       "      <td>0.595261</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.724578</td>\n",
       "      <td>0.344317</td>\n",
       "      <td>0.825676</td>\n",
       "      <td>0.584997</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.724728</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.584787</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.339230</td>\n",
       "      <td>0.826820</td>\n",
       "      <td>0.583025</td>\n",
       "      <td>ada_boost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_f1_micro  mean_test_f1_1  mean_test_f1_0  mean_test_f1_macro  \\\n",
       "15            0.854396        0.485541        0.915198            0.700369   \n",
       "14            0.858062        0.479820        0.917819            0.698820   \n",
       "13            0.858481        0.471561        0.918301            0.694931   \n",
       "16            0.844311        0.479672        0.908461            0.694066   \n",
       "18            0.838012        0.475128        0.904227            0.689678   \n",
       "17            0.839732        0.471662        0.905539            0.688601   \n",
       "21            0.806650        0.471103        0.881701            0.676402   \n",
       "23            0.804689        0.470015        0.880286            0.675151   \n",
       "22            0.804944        0.469089        0.880524            0.674806   \n",
       "0             0.880446        0.413018        0.933446            0.673232   \n",
       "29            0.848650        0.363636        0.914112            0.638874   \n",
       "11            0.860845        0.354883        0.922011            0.638447   \n",
       "16            0.856775        0.356807        0.919415            0.638111   \n",
       "23            0.855788        0.355835        0.918805            0.637320   \n",
       "71            0.782350        0.407543        0.866687            0.637115   \n",
       "31            0.848261        0.357066        0.913980            0.635523   \n",
       "37            0.843728        0.358949        0.911018            0.634984   \n",
       "59            0.789981        0.396664        0.872862            0.634763   \n",
       "28            0.849832        0.354349        0.915036            0.634692   \n",
       "77            0.778579        0.405177        0.863971            0.634574   \n",
       "0             0.734139        0.411422        0.828289            0.619855   \n",
       "26            0.721241        0.405020        0.817981            0.611501   \n",
       "27            0.717067        0.401633        0.814732            0.608182   \n",
       "28            0.710932        0.398780        0.809723            0.604252   \n",
       "29            0.710229        0.397674        0.809225            0.603449   \n",
       "31            0.709286        0.398204        0.808353            0.603278   \n",
       "32            0.706174        0.398947        0.805561            0.602254   \n",
       "0             0.817109        0.309474        0.894596            0.602035   \n",
       "1             0.765397        0.336282        0.857517            0.596900   \n",
       "34            0.700727        0.391234        0.801595            0.596415   \n",
       "37            0.697256        0.392348        0.798410            0.595379   \n",
       "35            0.699964        0.389403        0.801119            0.595261   \n",
       "10            0.724578        0.344317        0.825676            0.584997   \n",
       "9             0.724728        0.343738        0.825837            0.584787   \n",
       "1             0.725566        0.339230        0.826820            0.583025   \n",
       "2             0.725566        0.339230        0.826820            0.583025   \n",
       "3             0.725566        0.339230        0.826820            0.583025   \n",
       "6             0.725566        0.339230        0.826820            0.583025   \n",
       "5             0.725566        0.339230        0.826820            0.583025   \n",
       "4             0.725566        0.339230        0.826820            0.583025   \n",
       "\n",
       "            model  \n",
       "15  random_forest  \n",
       "14  random_forest  \n",
       "13  random_forest  \n",
       "16  random_forest  \n",
       "18  random_forest  \n",
       "17  random_forest  \n",
       "21  random_forest  \n",
       "23  random_forest  \n",
       "22  random_forest  \n",
       "0   random_forest  \n",
       "29  decision_tree  \n",
       "11  decision_tree  \n",
       "16  decision_tree  \n",
       "23  decision_tree  \n",
       "71  decision_tree  \n",
       "31  decision_tree  \n",
       "37  decision_tree  \n",
       "59  decision_tree  \n",
       "28  decision_tree  \n",
       "77  decision_tree  \n",
       "0             xgb  \n",
       "26            xgb  \n",
       "27            xgb  \n",
       "28            xgb  \n",
       "29            xgb  \n",
       "31            xgb  \n",
       "32            xgb  \n",
       "0      rule_based  \n",
       "1      rule_based  \n",
       "34            xgb  \n",
       "37            xgb  \n",
       "35            xgb  \n",
       "10      ada_boost  \n",
       "9       ada_boost  \n",
       "1       ada_boost  \n",
       "2       ada_boost  \n",
       "3       ada_boost  \n",
       "6       ada_boost  \n",
       "5       ada_boost  \n",
       "4       ada_boost  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df_results.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winner models for oversampling:\n",
    "- Random Forests\n",
    "- XGB\n",
    "- Decision Tree\n",
    "- Ada-Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "train_data = pd.read_csv('../../data/ml_datasets/oversampling/train_set.csv').sample(frac = 1, random_state=RANDOM_STATE) # shuffling the data so not to introduce bias\n",
    "val_data = pd.read_csv('../../data/ml_datasets/oversampling/val_set.csv')\n",
    "testing_data = pd.read_csv('../../data/ml_datasets/oversampling/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.pop('label')\n",
    "val_label = val_data.pop('label')\n",
    "test_label = testing_data.pop('label')\n",
    "\n",
    "train_set = train_data\n",
    "train_set['race_season%autumn'] = train_set['race_season%autumn'].astype(int)\n",
    "train_set['race_season%spring'] = train_set['race_season%spring'].astype(int)\n",
    "train_set['race_season%summer'] = train_set['race_season%summer'].astype(int)\n",
    "train_set['race_season%winter'] = train_set['race_season%winter'].astype(int)\n",
    "\n",
    "val_set = val_data\n",
    "val_set['race_season%autumn'] = val_set['race_season%autumn'].astype(int)\n",
    "val_set['race_season%spring'] = val_set['race_season%spring'].astype(int)\n",
    "val_set['race_season%summer'] = val_set['race_season%summer'].astype(int)\n",
    "val_set['race_season%winter'] = val_set['race_season%winter'].astype(int)\n",
    "\n",
    "test_set = testing_data\n",
    "test_set['race_season%autumn'] = test_set['race_season%autumn'].astype(int)\n",
    "test_set['race_season%spring'] = test_set['race_season%spring'].astype(int)\n",
    "test_set['race_season%summer'] = test_set['race_season%summer'].astype(int)\n",
    "test_set['race_season%winter'] = test_set['race_season%winter'].astype(int)\n",
    "\n",
    "N_JOBS = 4\n",
    "USER = 'Jacopo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters' values you want to try\n",
    "def f1_class_scorer(class_index):\n",
    "    def score_function(y_true, y_pred):\n",
    "        # Calcola F1 per ciascuna classe e ritorna quella specificata\n",
    "        return f1_score(y_true, y_pred, average=None)[class_index]\n",
    "    return make_scorer(score_function)\n",
    "\n",
    "# Scorer per la classe 0 e 1\n",
    "f1_class_0 = f1_class_scorer(0)  # Classe 0\n",
    "f1_class_1 = f1_class_scorer(1)  # Classe 1\n",
    "\n",
    "\n",
    "scoring={\n",
    "        'f1_macro': 'f1_macro',   # F1 macro per entrambe le classi\n",
    "        'f1_0': f1_class_0,  # F1 solo per classe 0\n",
    "        'f1_1': f1_class_1   # F1 solo per classe 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "def func(*args):\n",
    "    global i\n",
    "    print(f'Configurazione: {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = len(train_set.iloc[0])\n",
    "\n",
    "train_set = train_set.to_numpy()\n",
    "train_label = train_label.to_numpy()\n",
    "\n",
    "val_set = val_set.to_numpy()\n",
    "val_label = val_label.to_numpy()\n",
    "\n",
    "split_index = np.concatenate([\n",
    "    np.full(len(train_set), -1),  # -1 per training\n",
    "    np.zeros(len(val_set))   # 0 per validation\n",
    "])\n",
    "\n",
    "X_combined = np.vstack((train_set, val_set))\n",
    "y_combined = np.concatenate((train_label, val_label))\n",
    "\n",
    "ps = PredefinedSplit(test_fold=split_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree:\n",
    "- Class Weight: NaN\n",
    "- criterion: entropy, gini\n",
    "- max_depth: 8-12\n",
    "- max_features: 11 in su\n",
    "- min_samples_leaf: 5-70\n",
    "- min_samples_split: 10-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"classifier__max_depth\": Integer(8, 20),\n",
    "              \"classifier__max_features\": Integer(11, N_FEATURES),\n",
    "              \"classifier__min_samples_split\": Integer(10, 50),\n",
    "              \"classifier__min_samples_leaf\": Integer(5, 70),\n",
    "              \"classifier__criterion\": Categorical(['gini', 'entropy'])}\n",
    "#define the number of iters\n",
    "n_iter_search = 100\n",
    "#define the model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "#define the grid search\n",
    "rand_search = BayesSearchCV(clf, search_spaces=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit='f1_macro',\n",
    "                            cv=ps)\n",
    "#run the grid search\n",
    "rand_search.fit(X_combined, y_combined, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_decision_tree_results_bayes.csv', index=False)\n",
    "df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

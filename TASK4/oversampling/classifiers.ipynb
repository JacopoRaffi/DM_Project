{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:29:38.494145: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-19 11:29:38.550414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734604178.576421   56529 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734604178.584572   56529 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-19 11:29:38.613071: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import wittgenstein as lw\n",
    "import keras_tuner\n",
    "import keras\n",
    "from keras_tuner import HyperParameters\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import loguniform as sp_loguniform\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../data/ml_datasets/oversampling/train_set.csv').sample(frac = 1, random_state=RANDOM_STATE) # Shuffling the data to not introduce bias\n",
    "val_data = pd.read_csv('../../data/ml_datasets/oversampling/val_set.csv')\n",
    "testing_data = pd.read_csv('../../data/ml_datasets/oversampling/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.pop('label')\n",
    "val_label = val_data.pop('label')\n",
    "test_label = testing_data.pop('label')\n",
    "\n",
    "train_set = train_data\n",
    "train_set['race_season%autumn'] = train_set['race_season%autumn'].astype(int)\n",
    "train_set['race_season%spring'] = train_set['race_season%spring'].astype(int)\n",
    "train_set['race_season%summer'] = train_set['race_season%summer'].astype(int)\n",
    "train_set['race_season%winter'] = train_set['race_season%winter'].astype(int)\n",
    "\n",
    "val_set = val_data\n",
    "val_set['race_season%autumn'] = val_set['race_season%autumn'].astype(int)\n",
    "val_set['race_season%spring'] = val_set['race_season%spring'].astype(int)\n",
    "val_set['race_season%summer'] = val_set['race_season%summer'].astype(int)\n",
    "val_set['race_season%winter'] = val_set['race_season%winter'].astype(int)\n",
    "\n",
    "test_set = testing_data\n",
    "test_set['race_season%autumn'] = test_set['race_season%autumn'].astype(int)\n",
    "test_set['race_season%spring'] = test_set['race_season%spring'].astype(int)\n",
    "test_set['race_season%summer'] = test_set['race_season%summer'].astype(int)\n",
    "test_set['race_season%winter'] = test_set['race_season%winter'].astype(int)\n",
    "\n",
    "N_JOBS = 4\n",
    "USER = 'Jacopo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = len(train_set.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.to_numpy()\n",
    "train_label = train_label.to_numpy()\n",
    "\n",
    "val_set = val_set.to_numpy()\n",
    "val_label = val_label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = np.concatenate([\n",
    "    np.full(len(train_set), -1),  # -1 for training\n",
    "    np.zeros(len(val_set))        # 0 for validation\n",
    "])\n",
    "\n",
    "X_combined = np.vstack((train_set, val_set))\n",
    "y_combined = np.concatenate((train_label, val_label))\n",
    "\n",
    "ps = PredefinedSplit(test_fold=split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for the best hyperparameters\n",
    "def f1_class_scorer(class_index):\n",
    "    # Function to calculate F1 score for a specific class\n",
    "    def score_function(y_true, y_pred):\n",
    "        return f1_score(y_true, y_pred, average=None)[class_index] # Compute the F1 score for each class and return the one specified\n",
    "    return make_scorer(score_function)\n",
    "\n",
    "# Scorer for class 0 and 1\n",
    "f1_class_0 = f1_class_scorer(0)\n",
    "f1_class_1 = f1_class_scorer(1)\n",
    "\n",
    "scoring={\n",
    "        'f1_macro': 'f1_macro', # F1 macro for each class\n",
    "        'f1_micro': 'f1_micro', # F1 micro for each class\n",
    "        'f1_0': f1_class_0,     # F1 only for class 0\n",
    "        'f1_1': f1_class_1      # F1 only for class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": [3, 5, 10, 15, 20, None],\n",
    "              \"max_features\": sp_randint(3, N_FEATURES + 1),\n",
    "              \"min_samples_split\": [20, 30, 50, 100],\n",
    "              \"min_samples_leaf\": [10, 20, 30, 50, 100],\n",
    "              \"criterion\": [\"entropy\", \"gini\"],\n",
    "              \"class_weight\":['balanced', None, {0: 0.8, 1: 0.2}, {0: 0.6, 1: 0.4}]} # Class weights are related to over/undersampling chosen\n",
    "n_iter_search = 400\n",
    "clf = tree.DecisionTreeClassifier() # Decision Tree\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit=False,\n",
    "                            cv=ps)\n",
    "rand_search.fit(X_combined, y_combined);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_decision_tree_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"C\": sp_loguniform(1e-4, 1e2)}\n",
    "n_iter_search = 100\n",
    "clf = LinearSVC() # Model\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit=False,\n",
    "                            cv=ps)\n",
    "rand_search.fit(X_combined, y_combined);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_svm_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = {\n",
    "    'recall': 'recall',\n",
    "    'precision': 'precision',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "param_dist = {}\n",
    "n_iter_search = 1 # Number of iterations\n",
    "clf = GaussianNB() # Model\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=1, \n",
    "                            scoring=scoring,\n",
    "                            refit=False,\n",
    "                            cv=ps)\n",
    "rand_search.fit(X_combined, y_combined);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_naive_bayes_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We risk that the mapping of ordinal categorical attributes (without one-hot encoding) may cause issues in K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_neighbors': [5, 15, 25, 40, 50],\n",
    "              'n_neighbors': [40, 50],\n",
    "              'algorithm': ['ball_tree', 'kd_tree', 'brute'],}\n",
    "\n",
    "tmp_train_set = train_data.drop(columns=['cyclist_age_group', 'race_season%autumn', 'race_season%spring', 'race_season%summer', 'race_season%winter']).to_numpy()\n",
    "tmp_val_set = val_data.drop(columns=['cyclist_age_group', 'race_season%autumn', 'race_season%spring', 'race_season%summer', 'race_season%winter']).to_numpy()\n",
    "\n",
    "split_index_knn = np.concatenate([\n",
    "    np.full(len(tmp_train_set), -1),  # -1 for training\n",
    "    np.zeros(len(tmp_val_set))        # 0 for validation\n",
    "])\n",
    "\n",
    "X_combined_knn = np.vstack((tmp_train_set, tmp_val_set))\n",
    "y_combined_knn = np.concatenate((train_label, val_label))\n",
    "\n",
    "ps_knn = PredefinedSplit(test_fold=split_index_knn)\n",
    "\n",
    "clf = KNeighborsClassifier() # Model\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = GridSearchCV(clf, param_grid=param_dist,\n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit=False,\n",
    "                            cv=ps_knn)\n",
    "rand_search.fit(X_combined_knn, y_combined_knn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_knn_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": [5, 10, 20, None],\n",
    "              \"max_features\": sp_randint(3, N_FEATURES + 1),\n",
    "              \"min_samples_split\": [20, 50, 100],\n",
    "              \"min_samples_leaf\": [10, 30, 50, 100],\n",
    "              \"criterion\": [\"entropy\", \"gini\"],\n",
    "              \"class_weight\":['balanced', None, {0: 0.8, 1: 0.2}, {0: 0.6, 1: 0.4}],\n",
    "              \"n_estimators\": [50, 100, 150]}\n",
    "n_iter_search = 100\n",
    "clf = RandomForestClassifier() # Model\n",
    "\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit=False,\n",
    "                            cv=ps)\n",
    "rand_search.fit(X_combined, y_combined);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_random_forest_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()\n",
    "param_dist = {\n",
    "    \"n_estimators\": [25, 50, 100, 250, 500],\n",
    "    \"max_depth\": [2, 3, 4, 5],  \n",
    "    \"learning_rate\": [1, 0.1, 0.01, 0.001, 0.0001] \n",
    "}\n",
    "\n",
    "rand_search = GridSearchCV(clf, param_grid=param_dist,  \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit=False,\n",
    "                            cv=ps)\n",
    "rand_search.fit(X_combined, y_combined);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_xgb_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "param_dist = {\n",
    "    \"n_estimators\": [25, 50, 100, 250, 500],\n",
    "    \"learning_rate\": [1, 0.1, 0.01, 0.001, 0.0001],  \n",
    "    \"algorithm\": ['SAMME'] \n",
    "}\n",
    "\n",
    "rand_search = GridSearchCV(clf, param_grid=param_dist, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit=False,\n",
    "                            cv=ps)\n",
    "rand_search.fit(X_combined, y_combined);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_ada_boost_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp, units, dropout_rate, learning_rate):\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dense(\n",
    "            units,\n",
    "            activation='relu')),\n",
    "        model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "        model.add(keras.layers.Dense(\n",
    "            units//2,\n",
    "            activation='relu'))\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Configures the optimizer with the chosen learning rate\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        f1 = keras.metrics.F1Score(average='macro', threshold=0.5, name=\"f1_macro\", dtype=None)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[f1])\n",
    "  \n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, x, y, epochs, batch_size, **kwargs):\n",
    "        return model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=False,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=512, epochs=20, units_layer1=64, drop_rate=0.8, learning_rate=0.0001467799267622069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734604188.190632   56529 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734604190.089631   56819 service.cc:148] XLA service 0x7f38380049d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734604190.089758   56819 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2024-12-19 11:29:50.128266: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1734604190.330105   56819 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1734604191.538145   56819 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=1024, epochs=20, units_layer1=256, drop_rate=0.6000000000000001, learning_rate=4.641588833612782e-05\n",
      "Training with batch_size=256, epochs=30, units_layer1=256, drop_rate=0.2, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=256, epochs=30, units_layer1=128, drop_rate=0.2, learning_rate=1.4677992676220705e-05\n",
      "Training with batch_size=512, epochs=10, units_layer1=32, drop_rate=0.0, learning_rate=6.812920690579608e-05\n",
      "Training with batch_size=256, epochs=20, units_layer1=128, drop_rate=0.0, learning_rate=2.1544346900318823e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:39:09.465439: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=256, epochs=20, units_layer1=64, drop_rate=0.6000000000000001, learning_rate=6.812920690579608e-05\n",
      "Training with batch_size=512, epochs=10, units_layer1=32, drop_rate=0.6000000000000001, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=1024, epochs=30, units_layer1=64, drop_rate=0.2, learning_rate=6.812920690579608e-05\n",
      "Training with batch_size=1024, epochs=30, units_layer1=256, drop_rate=0.0, learning_rate=0.00031622776601683794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:45:28.647071: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375_0', 48 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:29.192912: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375_0', 664 bytes spill stores, 636 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:29.195874: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:33.069389: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138_0', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:33.712980: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:33.783340: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 44 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:33.920270: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375_0', 780 bytes spill stores, 804 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:34.111958: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 320 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:34.148968: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 16 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:34.179558: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375_0', 68 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:34.254070: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:34.325300: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 24 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-12-19 11:45:34.902785: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 2004 bytes spill stores, 1812 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=256, epochs=10, units_layer1=128, drop_rate=0.8, learning_rate=1.4677992676220705e-05\n",
      "Training with batch_size=256, epochs=20, units_layer1=64, drop_rate=0.0, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=1024, epochs=30, units_layer1=64, drop_rate=0.8, learning_rate=1e-05\n",
      "Training with batch_size=512, epochs=30, units_layer1=32, drop_rate=0.4, learning_rate=1e-05\n",
      "Training with batch_size=256, epochs=10, units_layer1=128, drop_rate=0.6000000000000001, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=1024, epochs=30, units_layer1=256, drop_rate=0.4, learning_rate=2.1544346900318823e-05\n",
      "Training with batch_size=512, epochs=10, units_layer1=64, drop_rate=0.6000000000000001, learning_rate=6.812920690579608e-05\n",
      "Training with batch_size=256, epochs=10, units_layer1=256, drop_rate=0.6000000000000001, learning_rate=3.1622776601683795e-05\n",
      "Training with batch_size=1024, epochs=30, units_layer1=128, drop_rate=0.0, learning_rate=1.4677992676220705e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:57:26.960554: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375_0', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:27.789798: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:28.256929: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:32.339446: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:32.383154: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:32.899145: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 16 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:33.065570: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375_0', 24 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:33.400918: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:33.555423: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 320 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-12-19 11:57:33.667468: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 2124 bytes spill stores, 1872 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=512, epochs=30, units_layer1=32, drop_rate=0.4, learning_rate=1.4677992676220705e-05\n",
      "Training with batch_size=512, epochs=20, units_layer1=256, drop_rate=0.6000000000000001, learning_rate=0.0001\n",
      "Training with batch_size=1024, epochs=20, units_layer1=128, drop_rate=0.6000000000000001, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=256, epochs=10, units_layer1=256, drop_rate=0.6000000000000001, learning_rate=3.1622776601683795e-05\n",
      "Training with batch_size=512, epochs=10, units_layer1=256, drop_rate=0.6000000000000001, learning_rate=3.1622776601683795e-05\n",
      "Training with batch_size=1024, epochs=10, units_layer1=64, drop_rate=0.8, learning_rate=1.4677992676220705e-05\n",
      "Training with batch_size=1024, epochs=10, units_layer1=32, drop_rate=0.8, learning_rate=6.812920690579608e-05\n",
      "Training with batch_size=512, epochs=10, units_layer1=64, drop_rate=0.4, learning_rate=0.00021544346900318823\n",
      "Training with batch_size=256, epochs=30, units_layer1=256, drop_rate=0.2, learning_rate=1.4677992676220705e-05\n",
      "Training with batch_size=1024, epochs=10, units_layer1=64, drop_rate=0.4, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=512, epochs=20, units_layer1=128, drop_rate=0.8, learning_rate=0.00021544346900318823\n",
      "Training with batch_size=512, epochs=30, units_layer1=256, drop_rate=0.6000000000000001, learning_rate=3.1622776601683795e-05\n",
      "Training with batch_size=256, epochs=20, units_layer1=256, drop_rate=0.4, learning_rate=0.0001\n",
      "Training with batch_size=256, epochs=10, units_layer1=128, drop_rate=0.0, learning_rate=0.0001\n",
      "Training with batch_size=512, epochs=20, units_layer1=32, drop_rate=0.2, learning_rate=2.1544346900318823e-05\n",
      "Training with batch_size=1024, epochs=30, units_layer1=32, drop_rate=0.4, learning_rate=0.0001467799267622069\n",
      "Training with batch_size=256, epochs=10, units_layer1=128, drop_rate=0.2, learning_rate=4.641588833612782e-05\n",
      "Training with batch_size=512, epochs=30, units_layer1=64, drop_rate=0.4, learning_rate=0.0001\n",
      "Training with batch_size=1024, epochs=30, units_layer1=128, drop_rate=0.6000000000000001, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=1024, epochs=10, units_layer1=64, drop_rate=0.4, learning_rate=2.1544346900318823e-05\n",
      "Training with batch_size=512, epochs=20, units_layer1=128, drop_rate=0.8, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=1024, epochs=10, units_layer1=256, drop_rate=0.8, learning_rate=3.1622776601683795e-05\n",
      "Training with batch_size=512, epochs=30, units_layer1=32, drop_rate=0.0, learning_rate=6.812920690579608e-05\n",
      "Training with batch_size=512, epochs=10, units_layer1=64, drop_rate=0.6000000000000001, learning_rate=6.812920690579608e-05\n",
      "Training with batch_size=1024, epochs=30, units_layer1=64, drop_rate=0.0, learning_rate=0.00021544346900318823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 12:30:33.253869: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-12-19 12:30:37.187463: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375', 320 bytes spill stores, 324 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=256, epochs=20, units_layer1=128, drop_rate=0.8, learning_rate=0.00031622776601683794\n",
      "Training with batch_size=1024, epochs=20, units_layer1=128, drop_rate=0.2, learning_rate=4.641588833612782e-05\n",
      "Training with batch_size=256, epochs=20, units_layer1=256, drop_rate=0.0, learning_rate=6.812920690579608e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 12:34:53.443162: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_375_0', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=512, epochs=30, units_layer1=256, drop_rate=0.4, learning_rate=0.0001467799267622069\n",
      "Training with batch_size=256, epochs=10, units_layer1=128, drop_rate=0.8, learning_rate=3.1622776601683795e-05\n",
      "Training with batch_size=512, epochs=30, units_layer1=128, drop_rate=0.8, learning_rate=0.00021544346900318823\n"
     ]
    }
   ],
   "source": [
    "rounds = 50\n",
    "config_results = []\n",
    "\n",
    "for _ in range(rounds):\n",
    "    hp = HyperParameters()\n",
    "    hyper_ae = MyHyperModel()\n",
    "    batch_size = hp.Fixed(\"batch_size\", random.choice([256, 512, 1024])) \n",
    "    epochs = hp.Fixed(\"epochs\", random.choice([10, 20, 30])) \n",
    "    units_layer1 = hp.Fixed('units_layer1', random.choice([32, 64, 128, 256]))  \n",
    "    drop_rate = hp.Fixed('rate', random.choice(np.arange(0., 0.9, 0.2))) \n",
    "    learning_rate = hp.Fixed(\"learning_rate\", random.choice(np.logspace(-5, -3.5, num=10))) # Jacopo\n",
    "    #learning_rate = hp.Fixed(\"learning_rate\", random.choice(np.logspace(-3.5, -2, num=10))) Simone\n",
    "\n",
    "    print(f\"Training with batch_size={batch_size}, epochs={epochs}, units_layer1={units_layer1}, drop_rate={drop_rate}, learning_rate={learning_rate}\")\n",
    "\n",
    "    model = hyper_ae.build(hp, units_layer1, drop_rate, learning_rate)\n",
    "\n",
    "    y_val = val_label.reshape(-1, 1)\n",
    "    y_train = train_label.reshape(-1, 1)\n",
    "    \n",
    "    # Adapt the model with the training and validation data\n",
    "    metrics = hyper_ae.fit(hp, model, train_set, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    val_out = model.predict(val_set, verbose=False)\n",
    "    val_out = (val_out >= 0.5).astype(int)\n",
    "    f1_0 = f1_class_0._score_func(y_val, val_out)\n",
    "    f1_1 = f1_class_1._score_func(y_val, val_out)\n",
    "    f1_micro = f1_score(y_val, val_out, average='micro')\n",
    "    f1_macro = f1_score(y_val, val_out, average='macro')\n",
    "\n",
    "    config = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"units_layer1\": units_layer1,\n",
    "        \"units_layer2\": units_layer1//2,\n",
    "        \"drop_rate\": drop_rate,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_0\": f1_0,\n",
    "        \"f1_1\": f1_1,\n",
    "    }\n",
    "\n",
    "    config_results.append(config)\n",
    "\n",
    "df = pd.DataFrame(config_results)\n",
    "# In reality we exploited macro average, calculating it afterwards\n",
    "df.sort_values(by='f1_micro', inplace=True, ascending=False)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_nn_results.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'prune_size': sp_uniform(0.1, 0.4),  # Uniform distribution between 0.1 and 0.5\n",
    "    'k': sp_randint(1, 11)               # Int between 1 and 10\n",
    "}\n",
    "n_iter_search = 20 # Number of iterations\n",
    "clf = lw.RIPPER(\n",
    "    max_rules=10,        # Moderate rule complexity\n",
    "    max_rule_conds=7,    # Enough room for moderately complex conditions\n",
    "    max_total_conds=35   # Cap total conditions to avoid runaway complexity\n",
    ")\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, n_iter=n_iter_search, \n",
    "                                 scoring=scoring, \n",
    "                                 refit=False, \n",
    "                                 n_jobs=2,\n",
    "                                 cv=ps)\n",
    "rand_search.fit(X_combined, y_combined);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_rule_based_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

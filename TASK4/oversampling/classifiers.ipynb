{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the best set of parameter setting, we can run a grid search\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import wittgenstein as lw\n",
    "import keras_tuner\n",
    "import keras\n",
    "from keras_tuner import HyperParameters\n",
    "import tensorflow as tf\n",
    "\n",
    "from statistics import mean, stdev\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('../data/ml_datasets/oversampling/dev_set.csv').sample(frac = 1, random_state=RANDOM_STATE) # shuffling the data so not to introduce bias\n",
    "testing_data = pd.read_csv('../data/ml_datasets/oversampling/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_label = dev_data.pop('label')\n",
    "test_label = testing_data.pop('label')\n",
    "\n",
    "dev_set = dev_data\n",
    "dev_set['race_season%autumn'] = dev_set['race_season%autumn'].astype(int)\n",
    "dev_set['race_season%spring'] = dev_set['race_season%spring'].astype(int)\n",
    "dev_set['race_season%summer'] = dev_set['race_season%summer'].astype(int)\n",
    "dev_set['race_season%winter'] = dev_set['race_season%winter'].astype(int)\n",
    "\n",
    "test_set = testing_data\n",
    "test_set['race_season%autumn'] = test_set['race_season%autumn'].astype(int)\n",
    "test_set['race_season%spring'] = test_set['race_season%spring'].astype(int)\n",
    "test_set['race_season%summer'] = test_set['race_season%summer'].astype(int)\n",
    "test_set['race_season%winter'] = test_set['race_season%winter'].astype(int)\n",
    "\n",
    "N_JOBS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters' values you want to try\n",
    "scoring_metrics = {\n",
    "    'recall': 'recall',\n",
    "    'precision': 'precision',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "param_dist = {\"max_depth\": [2,3,5,6,7,10,12,None],\n",
    "              \"max_features\": sp_randint(1, len(dev_set.iloc[0]) + 1),\n",
    "              \"min_samples_split\": sp_randint(10, 51),\n",
    "              \"min_samples_leaf\": sp_randint(10, 51),\n",
    "              \"criterion\": [\"entropy\", \"gini\"],\n",
    "              \"class_weight\":['balanced', None, {0: 0.3, 1: 0.7}]}\n",
    "#define the number of iters\n",
    "n_iter_search = 200\n",
    "#define the model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters' values you want to try\n",
    "param_dist = {\"C\": sp_uniform(0.1, 10.0)}\n",
    "#define the number of iters\n",
    "n_iter_search = 1\n",
    "#define the model\n",
    "clf = LinearSVC()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters' values you want to try\n",
    "scoring_metrics = {\n",
    "    'recall': 'recall',\n",
    "    'precision': 'precision',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "param_dist = {}\n",
    "#define the number of iters\n",
    "n_iter_search = 1\n",
    "#define the model\n",
    "clf = GaussianNB()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, #CrossValidation per confrontabilit√†, non model selection\n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=1, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rischiamo che il mapping degli attributi categorici ordinali (senza one-hot) crei problemi nel K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_neighbors': sp_randint(10, 20),\n",
    "              'algorithm': ['ball_tree', 'kd_tree', 'brute'],}\n",
    "\n",
    "tmp_dev_set = dev_set.drop(columns=['cyclist_age_group_num', 'race_season%autumn', 'race_season%spring', 'race_season%summer', 'race_season%winter'])\n",
    "#define the number of iters\n",
    "n_iter_search = 10\n",
    "#define the model\n",
    "clf = KNeighborsClassifier()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(tmp_dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "\n",
    "#define the number of iters\n",
    "n_iter_search = 10\n",
    "#define the model\n",
    "clf = lw.RIPPER()\n",
    "#define the grid search\n",
    "rand_search = GridSearchCV(estimator=clf, param_grid=param_dist, scoring='f1_macro', n_jobs=N_JOBS)\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\"max_depth\": [2,3,5,6,7,10,12,None],\n",
    "              \"max_features\": sp_randint(1, len(dev_set.iloc[0]) + 1),\n",
    "              \"min_samples_split\": sp_randint(10, 51),\n",
    "              \"min_samples_leaf\": sp_randint(10, 51),\n",
    "              \"criterion\": [\"entropy\", \"gini\"],\n",
    "              \"class_weight\":['balanced', None, {0: 0.3, 1: 0.7}],\n",
    "              \"n_estimators\": [33, 100, 250]}\n",
    "\n",
    "n_iter_search = 10\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()\n",
    "param_dist = {\n",
    "    \"n_estimators\": [25, 100, 250],\n",
    "    \"max_depth\": [2, 3],\n",
    "    \"learning_rate\": [1, 0.1, 0.001, 0.0001]\n",
    "}\n",
    "n_iter_search = 20\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "param_dist = {\n",
    "    \"n_estimators\": [25, 100, 250],\n",
    "    \"learning_rate\": [1, 0.1, 0.001, 0.0001],\n",
    "    \"algorithm\": ['SAMME']\n",
    "}\n",
    "n_iter_search = 10\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp, units, dropout_rate, learning_rate):\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dense(\n",
    "            units,\n",
    "            activation='relu')),\n",
    "        model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "        model.add(keras.layers.Dense(\n",
    "            units//2,\n",
    "            activation='relu'))\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Configura l'ottimizzatore con il learning rate scelto\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        f1 = keras.metrics.F1Score(average='macro', threshold=0.5, name=\"f1_score\", dtype=None)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[f1])\n",
    "  \n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, x, y, validation_data, epochs, batch_size, **kwargs):\n",
    "        return model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            validation_data=validation_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=False,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri di KFold\n",
    "dev_x = dev_set.to_numpy()\n",
    "dev_y = dev_label.to_numpy()\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=False)\n",
    "hyper_ae = MyHyperModel()\n",
    "hp = HyperParameters()\n",
    "\n",
    "rounds = 5\n",
    "config_results = []\n",
    "\n",
    "for _ in range(rounds):\n",
    "    batch_size = hp.Choice(\"batch_size\", [512, 1024])\n",
    "    epochs = hp.Choice(\"epochs\", [2, 3])\n",
    "    units_layer1 = hp.Choice('units_layer1', [32, 64, 128])\n",
    "    drop_rate = hp.Float('rate', 0, 0.5, step=0.1)\n",
    "    learning_rate = hp.Float(\"learning_rate\", 1e-5, 1e-2, sampling=\"log\")\n",
    "\n",
    "    model = hyper_ae.build(hp, units_layer1, drop_rate, learning_rate)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(dev_x, dev_y):\n",
    "        x_train, x_val = dev_x[train_index], dev_x[val_index]\n",
    "        y_train, y_val = dev_y[train_index], dev_y[val_index]\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        \n",
    "        # Adatta il modello con i dati di training e validazione \n",
    "        metrics = hyper_ae.fit(hp, model, x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)\n",
    "        f1_scores.append(metrics.history['val_f1_score'][-1])\n",
    "    \n",
    "    mean_f1, std_f1 = mean(f1_scores), stdev(f1_scores)\n",
    "    config = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"units_layer1\": units_layer1,\n",
    "        \"units_layer2\": units_layer1//2,\n",
    "        \"drop_rate\": drop_rate,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"mean_f1\": mean_f1,\n",
    "        \"std_f1\": std_f1\n",
    "    }\n",
    "\n",
    "    config_results.append(config)\n",
    "\n",
    "df = pd.DataFrame(config_results)\n",
    "df.sort_values(by='mean_f1', inplace=True, ascending=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

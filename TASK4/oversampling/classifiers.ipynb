{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 17:01:25.867314: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-12 17:01:26.236284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734019286.377456   56517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734019286.417072   56517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-12 17:01:26.746509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#to find the best set of parameter setting, we can run a grid search\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import wittgenstein as lw\n",
    "import keras_tuner\n",
    "import keras\n",
    "from keras_tuner import HyperParameters\n",
    "import tensorflow as tf\n",
    "\n",
    "from statistics import mean, stdev\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import loguniform as sp_loguniform\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('../../data/ml_datasets/oversampling/dev_set.csv').sample(frac = 1, random_state=RANDOM_STATE) # shuffling the data so not to introduce bias\n",
    "testing_data = pd.read_csv('../../data/ml_datasets/oversampling/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_label = dev_data.pop('label')\n",
    "test_label = testing_data.pop('label')\n",
    "\n",
    "dev_set = dev_data\n",
    "dev_set['race_season%autumn'] = dev_set['race_season%autumn'].astype(int)\n",
    "dev_set['race_season%spring'] = dev_set['race_season%spring'].astype(int)\n",
    "dev_set['race_season%summer'] = dev_set['race_season%summer'].astype(int)\n",
    "dev_set['race_season%winter'] = dev_set['race_season%winter'].astype(int)\n",
    "\n",
    "test_set = testing_data\n",
    "test_set['race_season%autumn'] = test_set['race_season%autumn'].astype(int)\n",
    "test_set['race_season%spring'] = test_set['race_season%spring'].astype(int)\n",
    "test_set['race_season%summer'] = test_set['race_season%summer'].astype(int)\n",
    "test_set['race_season%winter'] = test_set['race_season%winter'].astype(int)\n",
    "\n",
    "N_JOBS = 8\n",
    "USER = 'Jacopo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 573950 entries, 453303 to 121958\n",
      "Data columns (total 14 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   length                       573950 non-null  float64\n",
      " 1   cyclist_bmi                  573950 non-null  float64\n",
      " 2   cyclist_age_group            573950 non-null  int64  \n",
      " 3   climb_percentage             573950 non-null  float64\n",
      " 4   race_physical_effort         573950 non-null  float64\n",
      " 5   race_prestige                573950 non-null  float64\n",
      " 6   previous_mean_position       573950 non-null  float64\n",
      " 7   previous_mean_delta          573950 non-null  float64\n",
      " 8   previous_mean_cp             573950 non-null  float64\n",
      " 9   cyclist_previous_experience  573950 non-null  float64\n",
      " 10  race_season%autumn           573950 non-null  int64  \n",
      " 11  race_season%spring           573950 non-null  int64  \n",
      " 12  race_season%summer           573950 non-null  int64  \n",
      " 13  race_season%winter           573950 non-null  int64  \n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 65.7 MB\n"
     ]
    }
   ],
   "source": [
    "dev_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters' values you want to try\n",
    "scoring_metrics = {\n",
    "    'recall': 'recall',\n",
    "    'precision': 'precision',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "param_dist = {\"max_depth\": [3, 5, 10, 15, 20, None],\n",
    "              \"max_features\": sp_randint(3, len(dev_set.iloc[0]) + 1),\n",
    "              \"min_samples_split\": [20, 30, 50, 100],\n",
    "              \"min_samples_leaf\": [10, 20, 30, 50, 100],\n",
    "              \"criterion\": [\"entropy\", \"gini\"],\n",
    "              \"class_weight\":['balanced', None, {0: 0.8, 1: 0.2}, {0: 0.6, 1: 0.4}]} # class weights are related to over/undersampling chosen\n",
    "#define the number of iters\n",
    "n_iter_search = 200 # Total-Iteration: 400\n",
    "#define the model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.718205</td>\n",
       "      <td>0.116322</td>\n",
       "      <td>0.066384</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.769941</td>\n",
       "      <td>0.767211</td>\n",
       "      <td>0.770764</td>\n",
       "      <td>0.770186</td>\n",
       "      <td>0.769687</td>\n",
       "      <td>0.769558</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.864221</td>\n",
       "      <td>0.368792</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.766210</td>\n",
       "      <td>0.771548</td>\n",
       "      <td>0.769093</td>\n",
       "      <td>0.769469</td>\n",
       "      <td>0.762214</td>\n",
       "      <td>0.767707</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.582958</td>\n",
       "      <td>0.379503</td>\n",
       "      <td>0.054124</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.746586</td>\n",
       "      <td>0.747104</td>\n",
       "      <td>0.742633</td>\n",
       "      <td>0.750681</td>\n",
       "      <td>0.746374</td>\n",
       "      <td>0.746676</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.212434</td>\n",
       "      <td>0.131978</td>\n",
       "      <td>0.041943</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.710613</td>\n",
       "      <td>0.705177</td>\n",
       "      <td>0.710442</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>0.708564</td>\n",
       "      <td>0.709361</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.380584</td>\n",
       "      <td>0.145474</td>\n",
       "      <td>0.050397</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.704350</td>\n",
       "      <td>0.701955</td>\n",
       "      <td>0.706879</td>\n",
       "      <td>0.699936</td>\n",
       "      <td>0.698219</td>\n",
       "      <td>0.702268</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        4.718205      0.116322         0.066384        0.006037   \n",
       "1        7.864221      0.368792         0.067114        0.007817   \n",
       "11       4.582958      0.379503         0.054124        0.012172   \n",
       "10       8.212434      0.131978         0.041943        0.004535   \n",
       "3        3.380584      0.145474         0.050397        0.004474   \n",
       "\n",
       "   param_class_weight param_criterion  param_max_depth  param_max_features  \\\n",
       "6                None            gini               20                   6   \n",
       "1            balanced            gini               15                   9   \n",
       "11               None            gini               15                   7   \n",
       "10           balanced         entropy               10                  13   \n",
       "3                None            gini               10                   6   \n",
       "\n",
       "    param_min_samples_leaf  param_min_samples_split  \\\n",
       "6                       20                      100   \n",
       "1                       10                       30   \n",
       "11                      20                      100   \n",
       "10                      10                       30   \n",
       "3                      100                       30   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "6   {'class_weight': None, 'criterion': 'gini', 'm...           0.769941   \n",
       "1   {'class_weight': 'balanced', 'criterion': 'gin...           0.766210   \n",
       "11  {'class_weight': None, 'criterion': 'gini', 'm...           0.746586   \n",
       "10  {'class_weight': 'balanced', 'criterion': 'ent...           0.710613   \n",
       "3   {'class_weight': None, 'criterion': 'gini', 'm...           0.704350   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "6            0.767211           0.770764           0.770186   \n",
       "1            0.771548           0.769093           0.769469   \n",
       "11           0.747104           0.742633           0.750681   \n",
       "10           0.705177           0.710442           0.712007   \n",
       "3            0.701955           0.706879           0.699936   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "6            0.769687         0.769558        0.001226                1  \n",
       "1            0.762214         0.767707        0.003231                2  \n",
       "11           0.746374         0.746676        0.002556                3  \n",
       "10           0.708564         0.709361        0.002361                4  \n",
       "3            0.698219         0.702268        0.003083                5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_decision_tree_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters' values you want to try\n",
    "param_dist = {\"C\": sp_loguniform(1e-4, 1e2)}\n",
    "#define the number of iters\n",
    "n_iter_search = 50 # Total-Iteration: 100\n",
    "#define the model\n",
    "clf = LinearSVC()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.546039</td>\n",
       "      <td>0.637382</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>{'C': 0.002744023535579013}</td>\n",
       "      <td>0.661214</td>\n",
       "      <td>0.656598</td>\n",
       "      <td>0.660915</td>\n",
       "      <td>0.659334</td>\n",
       "      <td>0.659234</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.289573</td>\n",
       "      <td>0.722306</td>\n",
       "      <td>0.049562</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.169163</td>\n",
       "      <td>{'C': 0.16916283055859838}</td>\n",
       "      <td>0.661302</td>\n",
       "      <td>0.656146</td>\n",
       "      <td>0.661021</td>\n",
       "      <td>0.659361</td>\n",
       "      <td>0.658747</td>\n",
       "      <td>0.659315</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.172099</td>\n",
       "      <td>1.993295</td>\n",
       "      <td>0.029893</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.032113</td>\n",
       "      <td>{'C': 0.032113036509577364}</td>\n",
       "      <td>0.661198</td>\n",
       "      <td>0.655910</td>\n",
       "      <td>0.661125</td>\n",
       "      <td>0.659291</td>\n",
       "      <td>0.658930</td>\n",
       "      <td>0.659291</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.063736</td>\n",
       "      <td>0.681037</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.041119</td>\n",
       "      <td>{'C': 0.041118676935830094}</td>\n",
       "      <td>0.661154</td>\n",
       "      <td>0.656050</td>\n",
       "      <td>0.661099</td>\n",
       "      <td>0.659282</td>\n",
       "      <td>0.658695</td>\n",
       "      <td>0.659256</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.871431</td>\n",
       "      <td>0.657744</td>\n",
       "      <td>0.043008</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>1.115890</td>\n",
       "      <td>{'C': 1.115889685389457}</td>\n",
       "      <td>0.660876</td>\n",
       "      <td>0.656085</td>\n",
       "      <td>0.661108</td>\n",
       "      <td>0.659422</td>\n",
       "      <td>0.658782</td>\n",
       "      <td>0.659255</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time   param_C  \\\n",
       "8      10.546039      0.637382         0.045529        0.006342  0.002744   \n",
       "7      11.289573      0.722306         0.049562        0.004089  0.169163   \n",
       "9       8.172099      1.993295         0.029893        0.007193  0.032113   \n",
       "3      10.063736      0.681037         0.048676        0.002149  0.041119   \n",
       "4       9.871431      0.657744         0.043008        0.002558  1.115890   \n",
       "\n",
       "                        params  split0_test_score  split1_test_score  \\\n",
       "8  {'C': 0.002744023535579013}           0.661214           0.656598   \n",
       "7   {'C': 0.16916283055859838}           0.661302           0.656146   \n",
       "9  {'C': 0.032113036509577364}           0.661198           0.655910   \n",
       "3  {'C': 0.041118676935830094}           0.661154           0.656050   \n",
       "4     {'C': 1.115889685389457}           0.660876           0.656085   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "8           0.660915           0.659334           0.659234         0.659459   \n",
       "7           0.661021           0.659361           0.658747         0.659315   \n",
       "9           0.661125           0.659291           0.658930         0.659291   \n",
       "3           0.661099           0.659282           0.658695         0.659256   \n",
       "4           0.661108           0.659422           0.658782         0.659255   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "8        0.001640                1  \n",
       "7        0.001856                2  \n",
       "9        0.001927                3  \n",
       "3        0.001876                4  \n",
       "4        0.001809                5  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_svm_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters' values you want to try\n",
    "scoring_metrics = {\n",
    "    'recall': 'recall',\n",
    "    'precision': 'precision',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "param_dist = {}\n",
    "#define the number of iters\n",
    "n_iter_search = 1\n",
    "#define the model\n",
    "clf = GaussianNB()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, #CrossValidation per confrontabilità, non model selection\n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=1, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184915</td>\n",
       "      <td>0.028362</td>\n",
       "      <td>0.041469</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.622823</td>\n",
       "      <td>0.625776</td>\n",
       "      <td>0.628748</td>\n",
       "      <td>0.62317</td>\n",
       "      <td>0.624071</td>\n",
       "      <td>0.624917</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time params  \\\n",
       "0       0.184915      0.028362         0.041469        0.016511     {}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.622823           0.625776           0.628748            0.62317   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.624071         0.624917        0.002171                1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_naive_bayes_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rischiamo che il mapping degli attributi categorici ordinali (senza one-hot) crei problemi nel K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_neighbors': [5, 15, 25], # Jacopo\n",
    "              #'n_neighbors': [40, 50], # Simone\n",
    "              'algorithm': ['ball_tree', 'kd_tree', 'brute'],}\n",
    "\n",
    "tmp_dev_set = dev_set.drop(columns=['cyclist_age_group', 'race_season%autumn', 'race_season%spring', 'race_season%summer', 'race_season%winter'])\n",
    "#define the model\n",
    "clf = KNeighborsClassifier()\n",
    "#define the grid search\n",
    "rand_search = GridSearchCV(clf, param_grid=param_dist,\n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "#run the grid search\n",
    "rand_search.fit(tmp_dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.452134</td>\n",
       "      <td>0.140745</td>\n",
       "      <td>27.782911</td>\n",
       "      <td>0.584419</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>22</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 22}</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>0.658517</td>\n",
       "      <td>0.660607</td>\n",
       "      <td>0.662303</td>\n",
       "      <td>0.659689</td>\n",
       "      <td>0.660865</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.793398</td>\n",
       "      <td>0.077293</td>\n",
       "      <td>33.511456</td>\n",
       "      <td>0.540421</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>26</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 26}</td>\n",
       "      <td>0.655777</td>\n",
       "      <td>0.651345</td>\n",
       "      <td>0.654920</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.653741</td>\n",
       "      <td>0.654470</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.088340</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>189.716327</td>\n",
       "      <td>1.626455</td>\n",
       "      <td>brute</td>\n",
       "      <td>25</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 25}</td>\n",
       "      <td>0.654567</td>\n",
       "      <td>0.652546</td>\n",
       "      <td>0.654936</td>\n",
       "      <td>0.656247</td>\n",
       "      <td>0.653374</td>\n",
       "      <td>0.654334</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081664</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>214.730393</td>\n",
       "      <td>20.522446</td>\n",
       "      <td>brute</td>\n",
       "      <td>29</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 29}</td>\n",
       "      <td>0.649895</td>\n",
       "      <td>0.647049</td>\n",
       "      <td>0.648713</td>\n",
       "      <td>0.650648</td>\n",
       "      <td>0.647800</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.196515</td>\n",
       "      <td>0.204794</td>\n",
       "      <td>11.631383</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>31</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 31}</td>\n",
       "      <td>0.647298</td>\n",
       "      <td>0.644601</td>\n",
       "      <td>0.647479</td>\n",
       "      <td>0.648676</td>\n",
       "      <td>0.646566</td>\n",
       "      <td>0.646924</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9       1.452134      0.140745        27.782911        0.584419   \n",
       "4       1.793398      0.077293        33.511456        0.540421   \n",
       "6       0.088340      0.014553       189.716327        1.626455   \n",
       "2       0.081664      0.010948       214.730393       20.522446   \n",
       "5       2.196515      0.204794        11.631383        0.073614   \n",
       "\n",
       "  param_algorithm  param_n_neighbors  \\\n",
       "9       ball_tree                 22   \n",
       "4       ball_tree                 26   \n",
       "6           brute                 25   \n",
       "2           brute                 29   \n",
       "5         kd_tree                 31   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "9  {'algorithm': 'ball_tree', 'n_neighbors': 22}           0.663209   \n",
       "4  {'algorithm': 'ball_tree', 'n_neighbors': 26}           0.655777   \n",
       "6      {'algorithm': 'brute', 'n_neighbors': 25}           0.654567   \n",
       "2      {'algorithm': 'brute', 'n_neighbors': 29}           0.649895   \n",
       "5    {'algorithm': 'kd_tree', 'n_neighbors': 31}           0.647298   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "9           0.658517           0.660607           0.662303           0.659689   \n",
       "4           0.651345           0.654920           0.656566           0.653741   \n",
       "6           0.652546           0.654936           0.656247           0.653374   \n",
       "2           0.647049           0.648713           0.650648           0.647800   \n",
       "5           0.644601           0.647479           0.648676           0.646566   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "9         0.660865        0.001704                1  \n",
       "4         0.654470        0.001822                2  \n",
       "6         0.654334        0.001280                3  \n",
       "2         0.648821        0.001318                4  \n",
       "5         0.646924        0.001345                5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_knn_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'prune_size': sp_uniform(0.1, 0.4),  # Distribuzione uniforme tra 0.1 e 0.5\n",
    "    'k': sp_randint(1, 11)               # Interi tra 1 e 10\n",
    "}\n",
    "\n",
    "#define the number of iters\n",
    "n_iter_search = 10\n",
    "#define the model\n",
    "clf = lw.RIPPER()\n",
    "#define the grid search\n",
    "rand_search = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, n_iter=n_iter_search, \n",
    "                                 scoring='f1_macro', n_jobs=N_JOBS)\n",
    "#run the grid search\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_rule_based_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\"max_depth\": [5, 10, 20, None],\n",
    "              \"max_features\": sp_randint(3, len(dev_set.iloc[0]) + 1),\n",
    "              \"min_samples_split\": [20, 50, 100],\n",
    "              \"min_samples_leaf\": [10, 30, 50, 100],\n",
    "              \"criterion\": [\"entropy\", \"gini\"],\n",
    "              \"class_weight\":['balanced', None, {0: 0.8, 1: 0.2}, {0: 0.6, 1: 0.4}],\n",
    "              \"n_estimators\": [50, 100, 150]}\n",
    "\n",
    "n_iter_search = 10\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_random_forest_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()\n",
    "param_dist = {\n",
    "    \"n_estimators\": [25, 50, 100, 250, 500],  \n",
    "    \"max_depth\": [2, 3, 4, 5],  \n",
    "    \"learning_rate\": [1, 0.1, 0.01, 0.001, 0.0001] \n",
    "}\n",
    "n_iter_search = 20\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_xgb_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "param_dist = {\n",
    "    \"n_estimators\": [25, 50, 100, 250, 500],  # Aggiunto 50 e 500 per una maggiore flessibilità\n",
    "    \"learning_rate\": [1, 0.1, 0.01, 0.001, 0.0001],  # Aggiunto 0.01 per esplorare un valore intermedio\n",
    "    \"algorithm\": ['SAMME']  # Aggiunto 'SAMME.R' come opzione alternativa\n",
    "}\n",
    "n_iter_search = 10\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring='f1_macro')\n",
    "rand_search.fit(dev_set, dev_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_score', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_ada_boost_results.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp, units, dropout_rate, learning_rate):\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dense(\n",
    "            units,\n",
    "            activation='relu')),\n",
    "        model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "        model.add(keras.layers.Dense(\n",
    "            units//2,\n",
    "            activation='relu'))\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Configura l'ottimizzatore con il learning rate scelto\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        f1 = keras.metrics.F1Score(average='macro', threshold=0.5, name=\"f1_score\", dtype=None)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[f1])\n",
    "  \n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, x, y, validation_data, epochs, batch_size, **kwargs):\n",
    "        return model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            validation_data=validation_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=False,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri di KFold\n",
    "dev_x = dev_set.to_numpy()\n",
    "dev_y = dev_label.to_numpy()\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=False)\n",
    "hyper_ae = MyHyperModel()\n",
    "hp = HyperParameters()\n",
    "\n",
    "rounds = 10\n",
    "config_results = []\n",
    "\n",
    "for _ in range(rounds):\n",
    "    batch_size = hp.Choice(\"batch_size\", [256, 512, 1024])  \n",
    "    epochs = hp.Choice(\"epochs\", [2, 3, 5, 10]) \n",
    "    units_layer1 = hp.Choice('units_layer1', [32, 64, 128, 256])  \n",
    "    drop_rate = hp.Float('rate', 0, 0.5, step=0.05) \n",
    "    learning_rate = hp.Float(\"learning_rate\", 1e-5, 1e-2, sampling=\"log\")\n",
    "\n",
    "    model = hyper_ae.build(hp, units_layer1, drop_rate, learning_rate)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(dev_x, dev_y):\n",
    "        x_train, x_val = dev_x[train_index], dev_x[val_index]\n",
    "        y_train, y_val = dev_y[train_index], dev_y[val_index]\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        \n",
    "        # Adatta il modello con i dati di training e validazione \n",
    "        metrics = hyper_ae.fit(hp, model, x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)\n",
    "        f1_scores.append(metrics.history['val_f1_score'][-1])\n",
    "    \n",
    "    mean_f1, std_f1 = mean(f1_scores), stdev(f1_scores)\n",
    "    config = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"units_layer1\": units_layer1,\n",
    "        \"units_layer2\": units_layer1//2,\n",
    "        \"drop_rate\": drop_rate,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"mean_f1\": mean_f1,\n",
    "        \"std_f1\": std_f1\n",
    "    }\n",
    "\n",
    "    config_results.append(config)\n",
    "\n",
    "df = pd.DataFrame(config_results)\n",
    "df.sort_values(by='mean_f1', inplace=True, ascending=False)\n",
    "df.to_csv(f'../../data/ml_datasets/oversampling/model_selection/{USER}_nn_results.csv', index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

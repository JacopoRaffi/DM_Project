{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Bayesian Search - Undersampled Dataset\n",
    "\n",
    "### Data Mining Project 2024/25\n",
    "\n",
    "Authors: Nicola Emmolo, Simone Marzeddu, Jacopo Raffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import tree\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "import wittgenstein as lw\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge results from previous random search\n",
    "USER_1 = 'Jacopo'\n",
    "USER_2 = 'Simone'\n",
    "\n",
    "models = ['ada_boost', 'nn', 'xgb', 'naive_bayes', 'random_forest', 'decision_tree', 'svm', 'rule_based', 'knn']\n",
    "\n",
    "for model in models:\n",
    "    path_1 = f'../../data/ml_datasets/undersampling/model_selection/{USER_1}_{model}_results.csv'\n",
    "    path_2 = f'../../data/ml_datasets/undersampling/model_selection/{USER_2}_{model}_results.csv'\n",
    "\n",
    "    concatenate_path = f'../../data/ml_datasets/undersampling/model_selection/{model}_results.csv'\n",
    "\n",
    "    df1 = pd.read_csv(path_1)\n",
    "    df2 = pd.read_csv(path_2)\n",
    "\n",
    "    df1['mean_test_f1_macro'] = (df1['mean_test_f1_1'] + df1['mean_test_f1_0']) / 2\n",
    "    df2['mean_test_f1_macro'] = (df2['mean_test_f1_1'] + df2['mean_test_f1_0']) / 2\n",
    "\n",
    "    df1['std_test_f1_macro'] = (df1['std_test_f1_1'] + df1['std_test_f1_0']) / 2\n",
    "    df2['std_test_f1_macro'] = (df2['std_test_f1_1'] + df2['std_test_f1_0']) / 2\n",
    "\n",
    "    df_concat = pd.concat([df1, df2], ignore_index=True) # Concat the two files\n",
    "    df_concat.to_csv(concatenate_path, index=False)  # Save the result in a new CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_see = ['mean_test_f1_micro', 'std_test_f1_micro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0', 'mean_test_f1_macro', 'std_test_f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../../data/ml_datasets/undersampling/model_selection/ada_boost_results.csv')\n",
    "# df.sort_values(by='mean_test_f1_micro', ascending=False, inplace=True)\n",
    "# params= [col for col in df.columns if col.startswith(\"param_classifier__\")]\n",
    "# df.head(n=10)[columns_to_see+params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['batch_size', 'epochs', 'units_layer1', 'units_layer2', 'drop_rate',\n",
      "       'learning_rate', 'mean_test_f1_micro', 'std_test_f1_micro',\n",
      "       'mean_test_f1_0', 'std_test_f1_0', 'mean_test_f1_1', 'std_test_f1_1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "models = ['ada_boost', 'nn', 'xgb', 'naive_bayes', 'random_forest', 'decision_tree', 'svm', 'rule_based', 'knn']\n",
    "\n",
    "df_results = pd.read_csv('../../data/ml_datasets/undersampling/model_selection/nn_results.csv')\n",
    "df_results = df_results.rename(columns={'mean_f1_micro': 'mean_test_f1_micro', \n",
    "                                        'std_f1_micro': 'std_test_f1_micro',\n",
    "                                        'mean_f1_1': 'mean_test_f1_1',\n",
    "                                        'std_f1_1': 'std_test_f1_1',\n",
    "                                        'mean_f1_0': 'mean_test_f1_0',\n",
    "                                        'std_f1_0': 'std_test_f1_0'})\n",
    "print(df_results.columns)\n",
    "df_results = df_results[columns_to_see]\n",
    "df_results['model'] = 'nn'\n",
    "models.remove('nn')\n",
    "\n",
    "columns_to_see = ['model'] + columns_to_see\n",
    "for model in models:\n",
    "    path = f'../../data/ml_datasets/undersampling/model_selection/{model}_results.csv'\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df['model'] = model\n",
    "    df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "    df = df.head(10)\n",
    "    df = df[columns_to_see]\n",
    "\n",
    "    df_results = pd.concat([df_results, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_f1_micro</th>\n",
       "      <th>std_test_f1_micro</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "      <th>model</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.725322</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.419911</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.820059</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.619985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.724990</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.419359</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.819827</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.619593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.722791</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.417092</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.818156</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.617624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.722686</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.417035</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.818071</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.617553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.722207</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.415785</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.817781</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.616783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.722276</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.415650</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.817853</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.616752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.721899</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.414652</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.817626</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.616139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.719406</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.411937</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.815744</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.613841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.718787</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.411841</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.815219</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.613530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.718341</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.411940</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.814824</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.613382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.703584</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.803476</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.600317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703584</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.803476</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.600317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.704853</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.395221</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.804793</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.704853</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.395221</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.804793</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.702061</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.394692</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.598546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.702061</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.394692</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.598546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798183</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>0.315831</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.881225</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.598528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.795672</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.316241</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>0.879338</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.597790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.702561</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.392437</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.803073</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.597755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.702561</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.392437</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.803073</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.597755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.701846</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.392661</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.802426</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.597543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.701846</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.392661</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.802426</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.597543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.778166</td>\n",
       "      <td>0.020706</td>\n",
       "      <td>0.328230</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>0.866782</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.597506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821989</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>0.284754</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>0.898117</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.591436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.701202</td>\n",
       "      <td>0.017249</td>\n",
       "      <td>0.378276</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.803175</td>\n",
       "      <td>0.014059</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.590726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.763810</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>0.320414</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.855098</td>\n",
       "      <td>0.037705</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.587756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.695322</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.375949</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.798452</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.587200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.694678</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.376340</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.797786</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.587063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.751244</td>\n",
       "      <td>0.042112</td>\n",
       "      <td>0.328082</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.846025</td>\n",
       "      <td>0.031720</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.587054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.694810</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.376116</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.797945</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.587030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.694720</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>0.375729</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.797873</td>\n",
       "      <td>0.010021</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.586801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.692999</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.375477</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.796448</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.585963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.694762</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.373663</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>0.798168</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.585916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.689636</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.378040</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.793199</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.585620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.692341</td>\n",
       "      <td>0.011993</td>\n",
       "      <td>0.375255</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.795820</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.585538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.739887</td>\n",
       "      <td>0.035660</td>\n",
       "      <td>0.333287</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.837405</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.585346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.688478</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.377339</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.792260</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.584799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.827974</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.266277</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>0.902253</td>\n",
       "      <td>0.010464</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.584265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.827462</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.266467</td>\n",
       "      <td>0.042034</td>\n",
       "      <td>0.901912</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.584189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827424</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.264720</td>\n",
       "      <td>0.044007</td>\n",
       "      <td>0.901908</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.583314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_f1_micro  std_test_f1_micro  mean_test_f1_1  std_test_f1_1  \\\n",
       "0              0.725322           0.002026        0.419911       0.003151   \n",
       "50             0.724990           0.002114        0.419359       0.003605   \n",
       "51             0.722791           0.002282        0.417092       0.003846   \n",
       "1              0.722686           0.002104        0.417035       0.003778   \n",
       "52             0.722207           0.002004        0.415785       0.003599   \n",
       "2              0.722276           0.002406        0.415650       0.003703   \n",
       "53             0.721899           0.001767        0.414652       0.003378   \n",
       "3              0.719406           0.001844        0.411937       0.003243   \n",
       "4              0.718787           0.001393        0.411841       0.002804   \n",
       "56             0.718341           0.001925        0.411940       0.003375   \n",
       "61             0.703584           0.002056        0.397159       0.003974   \n",
       "1              0.703584           0.002056        0.397159       0.003974   \n",
       "0              0.704853           0.001445        0.395221       0.002892   \n",
       "60             0.704853           0.001445        0.395221       0.002892   \n",
       "3              0.702061           0.001298        0.394692       0.002899   \n",
       "63             0.702061           0.001298        0.394692       0.002899   \n",
       "4              0.798183           0.022769        0.315831       0.011196   \n",
       "5              0.795672           0.025764        0.316241       0.015176   \n",
       "2              0.702561           0.003559        0.392437       0.004376   \n",
       "62             0.702561           0.003559        0.392437       0.004376   \n",
       "4              0.701846           0.001311        0.392661       0.002041   \n",
       "64             0.701846           0.001311        0.392661       0.002041   \n",
       "21             0.778166           0.020706        0.328230       0.011707   \n",
       "3              0.821989           0.012140        0.284754       0.039780   \n",
       "152            0.701202           0.017249        0.378276       0.007695   \n",
       "6              0.763810           0.050026        0.320414       0.014379   \n",
       "5              0.695322           0.004868        0.375949       0.003095   \n",
       "7              0.694678           0.009614        0.376340       0.003497   \n",
       "22             0.751244           0.042112        0.328082       0.010079   \n",
       "153            0.694810           0.009417        0.376116       0.004031   \n",
       "6              0.694720           0.012140        0.375729       0.005519   \n",
       "156            0.692999           0.006977        0.375477       0.003657   \n",
       "154            0.694762           0.007985        0.373663       0.004313   \n",
       "19             0.689636           0.007103        0.378040       0.003387   \n",
       "10             0.692341           0.011993        0.375255       0.004496   \n",
       "23             0.739887           0.035660        0.333287       0.004861   \n",
       "25             0.688478           0.005550        0.377339       0.003949   \n",
       "1              0.827974           0.015286        0.266277       0.043537   \n",
       "20             0.827462           0.015923        0.266467       0.042034   \n",
       "2              0.827424           0.015875        0.264720       0.044007   \n",
       "\n",
       "     mean_test_f1_0  std_test_f1_0          model  mean_test_f1_macro  \n",
       "0          0.820059       0.001453  random_forest            0.619985  \n",
       "50         0.819827       0.001481  random_forest            0.619593  \n",
       "51         0.818156       0.001593  random_forest            0.617624  \n",
       "1          0.818071       0.001451  random_forest            0.617553  \n",
       "52         0.817781       0.001380  random_forest            0.616783  \n",
       "2          0.817853       0.001732  random_forest            0.616752  \n",
       "53         0.817626       0.001220  random_forest            0.616139  \n",
       "3          0.815744       0.001277  random_forest            0.613841  \n",
       "4          0.815219       0.000973  random_forest            0.613530  \n",
       "56         0.814824       0.001332  random_forest            0.613382  \n",
       "61         0.803476       0.001468            xgb            0.600317  \n",
       "1          0.803476       0.001468            xgb            0.600317  \n",
       "0          0.804793       0.001010            xgb            0.600007  \n",
       "60         0.804793       0.001010            xgb            0.600007  \n",
       "3          0.802400       0.000853            xgb            0.598546  \n",
       "63         0.802400       0.000853            xgb            0.598546  \n",
       "4          0.881225       0.016210     rule_based            0.598528  \n",
       "5          0.879338       0.018505     rule_based            0.597790  \n",
       "2          0.803073       0.002757            xgb            0.597755  \n",
       "62         0.803073       0.002757            xgb            0.597755  \n",
       "4          0.802426       0.000989            xgb            0.597543  \n",
       "64         0.802426       0.000989            xgb            0.597543  \n",
       "21         0.866782       0.014832     rule_based            0.597506  \n",
       "3          0.898117       0.008389     rule_based            0.591436  \n",
       "152        0.803175       0.014059  decision_tree            0.590726  \n",
       "6          0.855098       0.037705     rule_based            0.587756  \n",
       "5          0.798452       0.003953  decision_tree            0.587200  \n",
       "7          0.797786       0.008244  decision_tree            0.587063  \n",
       "22         0.846025       0.031720     rule_based            0.587054  \n",
       "153        0.797945       0.007819  decision_tree            0.587030  \n",
       "6          0.797873       0.010021  decision_tree            0.586801  \n",
       "156        0.796448       0.005787  decision_tree            0.585963  \n",
       "154        0.798168       0.006652  decision_tree            0.585916  \n",
       "19         0.793199       0.005924  decision_tree            0.585620  \n",
       "10         0.795820       0.010190  decision_tree            0.585538  \n",
       "23         0.837405       0.028186     rule_based            0.585346  \n",
       "25         0.792260       0.004586  decision_tree            0.584799  \n",
       "1          0.902253       0.010464     rule_based            0.584265  \n",
       "20         0.901912       0.010862     rule_based            0.584189  \n",
       "2          0.901908       0.010858     rule_based            0.583314  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df_results.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winner models for UnderSampling:\n",
    "- Random Forests\n",
    "- XGB\n",
    "- Decision Tree\n",
    "- Rule-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__k</th>\n",
       "      <th>param_classifier__prune_size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_micro</th>\n",
       "      <th>split1_test_f1_micro</th>\n",
       "      <th>split2_test_f1_micro</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>split1_test_f1_1</th>\n",
       "      <th>split2_test_f1_1</th>\n",
       "      <th>split3_test_f1_1</th>\n",
       "      <th>split4_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.650580</td>\n",
       "      <td>0.959798</td>\n",
       "      <td>0.535664</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215088</td>\n",
       "      <td>{'classifier__k': 2, 'classifier__prune_size':...</td>\n",
       "      <td>0.776664</td>\n",
       "      <td>0.817019</td>\n",
       "      <td>0.764813</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.326869</td>\n",
       "      <td>0.308588</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.305433</td>\n",
       "      <td>0.306434</td>\n",
       "      <td>0.315831</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>16</td>\n",
       "      <td>0.598528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.549836</td>\n",
       "      <td>1.029161</td>\n",
       "      <td>0.539264</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>2</td>\n",
       "      <td>0.417199</td>\n",
       "      <td>{'classifier__k': 2, 'classifier__prune_size':...</td>\n",
       "      <td>0.814475</td>\n",
       "      <td>0.817019</td>\n",
       "      <td>0.764813</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.297786</td>\n",
       "      <td>0.308588</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.336566</td>\n",
       "      <td>0.306434</td>\n",
       "      <td>0.316241</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>15</td>\n",
       "      <td>0.597790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23.981485</td>\n",
       "      <td>1.940627</td>\n",
       "      <td>0.447366</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>2</td>\n",
       "      <td>0.323858</td>\n",
       "      <td>{'classifier__k': 2, 'classifier__prune_size':...</td>\n",
       "      <td>0.776664</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>0.764813</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.326869</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.336566</td>\n",
       "      <td>0.306434</td>\n",
       "      <td>0.328230</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>16</td>\n",
       "      <td>0.597506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.038901</td>\n",
       "      <td>0.575556</td>\n",
       "      <td>0.534869</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313911</td>\n",
       "      <td>{'classifier__k': 1, 'classifier__prune_size':...</td>\n",
       "      <td>0.814475</td>\n",
       "      <td>0.817019</td>\n",
       "      <td>0.846032</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.297786</td>\n",
       "      <td>0.308588</td>\n",
       "      <td>0.205528</td>\n",
       "      <td>0.305433</td>\n",
       "      <td>0.306434</td>\n",
       "      <td>0.284754</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>17</td>\n",
       "      <td>0.591436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.157996</td>\n",
       "      <td>2.206756</td>\n",
       "      <td>0.531289</td>\n",
       "      <td>0.029043</td>\n",
       "      <td>3</td>\n",
       "      <td>0.279260</td>\n",
       "      <td>{'classifier__k': 3, 'classifier__prune_size':...</td>\n",
       "      <td>0.776664</td>\n",
       "      <td>0.817019</td>\n",
       "      <td>0.815044</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.326869</td>\n",
       "      <td>0.308588</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.333602</td>\n",
       "      <td>0.334503</td>\n",
       "      <td>0.320414</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>14</td>\n",
       "      <td>0.587756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27.272839</td>\n",
       "      <td>2.364907</td>\n",
       "      <td>0.448736</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188670</td>\n",
       "      <td>{'classifier__k': 3, 'classifier__prune_size':...</td>\n",
       "      <td>0.703211</td>\n",
       "      <td>0.817019</td>\n",
       "      <td>0.764813</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.328924</td>\n",
       "      <td>0.308588</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.336566</td>\n",
       "      <td>0.334503</td>\n",
       "      <td>0.328082</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>17</td>\n",
       "      <td>0.587054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32.916554</td>\n",
       "      <td>3.984933</td>\n",
       "      <td>0.430428</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>9</td>\n",
       "      <td>0.123937</td>\n",
       "      <td>{'classifier__k': 9, 'classifier__prune_size':...</td>\n",
       "      <td>0.776664</td>\n",
       "      <td>0.698962</td>\n",
       "      <td>0.764813</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.326869</td>\n",
       "      <td>0.341160</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.335825</td>\n",
       "      <td>0.330750</td>\n",
       "      <td>0.333287</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>10</td>\n",
       "      <td>0.585346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.768717</td>\n",
       "      <td>0.640888</td>\n",
       "      <td>0.536343</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294978</td>\n",
       "      <td>{'classifier__k': 1, 'classifier__prune_size':...</td>\n",
       "      <td>0.814475</td>\n",
       "      <td>0.817019</td>\n",
       "      <td>0.815044</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.297786</td>\n",
       "      <td>0.308588</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.217252</td>\n",
       "      <td>0.209250</td>\n",
       "      <td>0.266277</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>18</td>\n",
       "      <td>0.584265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18.636901</td>\n",
       "      <td>1.071154</td>\n",
       "      <td>0.459237</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260647</td>\n",
       "      <td>{'classifier__k': 1, 'classifier__prune_size':...</td>\n",
       "      <td>0.814475</td>\n",
       "      <td>0.847154</td>\n",
       "      <td>0.815044</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297786</td>\n",
       "      <td>0.221358</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.305433</td>\n",
       "      <td>0.209250</td>\n",
       "      <td>0.266467</td>\n",
       "      <td>0.042034</td>\n",
       "      <td>20</td>\n",
       "      <td>0.584189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.040209</td>\n",
       "      <td>2.100988</td>\n",
       "      <td>0.518756</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>1</td>\n",
       "      <td>0.184002</td>\n",
       "      <td>{'classifier__k': 1, 'classifier__prune_size':...</td>\n",
       "      <td>0.814475</td>\n",
       "      <td>0.846960</td>\n",
       "      <td>0.815044</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.297786</td>\n",
       "      <td>0.212625</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.305433</td>\n",
       "      <td>0.209250</td>\n",
       "      <td>0.264720</td>\n",
       "      <td>0.044007</td>\n",
       "      <td>19</td>\n",
       "      <td>0.583314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       29.650580      0.959798         0.535664        0.009432   \n",
       "5       29.549836      1.029161         0.539264        0.007292   \n",
       "21      23.981485      1.940627         0.447366        0.011247   \n",
       "3       22.038901      0.575556         0.534869        0.014071   \n",
       "6       33.157996      2.206756         0.531289        0.029043   \n",
       "22      27.272839      2.364907         0.448736        0.027963   \n",
       "23      32.916554      3.984933         0.430428        0.022475   \n",
       "1       22.768717      0.640888         0.536343        0.008657   \n",
       "20      18.636901      1.071154         0.459237        0.015773   \n",
       "2       22.040209      2.100988         0.518756        0.013818   \n",
       "\n",
       "    param_classifier__k  param_classifier__prune_size  \\\n",
       "4                     2                      0.215088   \n",
       "5                     2                      0.417199   \n",
       "21                    2                      0.323858   \n",
       "3                     1                      0.313911   \n",
       "6                     3                      0.279260   \n",
       "22                    3                      0.188670   \n",
       "23                    9                      0.123937   \n",
       "1                     1                      0.294978   \n",
       "20                    1                      0.260647   \n",
       "2                     1                      0.184002   \n",
       "\n",
       "                                               params  split0_test_f1_micro  \\\n",
       "4   {'classifier__k': 2, 'classifier__prune_size':...              0.776664   \n",
       "5   {'classifier__k': 2, 'classifier__prune_size':...              0.814475   \n",
       "21  {'classifier__k': 2, 'classifier__prune_size':...              0.776664   \n",
       "3   {'classifier__k': 1, 'classifier__prune_size':...              0.814475   \n",
       "6   {'classifier__k': 3, 'classifier__prune_size':...              0.776664   \n",
       "22  {'classifier__k': 3, 'classifier__prune_size':...              0.703211   \n",
       "23  {'classifier__k': 9, 'classifier__prune_size':...              0.776664   \n",
       "1   {'classifier__k': 1, 'classifier__prune_size':...              0.814475   \n",
       "20  {'classifier__k': 1, 'classifier__prune_size':...              0.814475   \n",
       "2   {'classifier__k': 1, 'classifier__prune_size':...              0.814475   \n",
       "\n",
       "    split1_test_f1_micro  split2_test_f1_micro  ...  rank_test_f1_0  \\\n",
       "4               0.817019              0.764813  ...               5   \n",
       "5               0.817019              0.764813  ...               6   \n",
       "21              0.767297              0.764813  ...               2   \n",
       "3               0.817019              0.846032  ...               4   \n",
       "6               0.817019              0.815044  ...               7   \n",
       "22              0.817019              0.764813  ...               3   \n",
       "23              0.698962              0.764813  ...               4   \n",
       "1               0.817019              0.815044  ...               2   \n",
       "20              0.847154              0.815044  ...               1   \n",
       "2               0.846960              0.815044  ...               3   \n",
       "\n",
       "    split0_test_f1_1  split1_test_f1_1  split2_test_f1_1  split3_test_f1_1  \\\n",
       "4           0.326869          0.308588          0.331831          0.305433   \n",
       "5           0.297786          0.308588          0.331831          0.336566   \n",
       "21          0.326869          0.339450          0.331831          0.336566   \n",
       "3           0.297786          0.308588          0.205528          0.305433   \n",
       "6           0.326869          0.308588          0.298507          0.333602   \n",
       "22          0.328924          0.308588          0.331831          0.336566   \n",
       "23          0.326869          0.341160          0.331831          0.335825   \n",
       "1           0.297786          0.308588          0.298507          0.217252   \n",
       "20          0.297786          0.221358          0.298507          0.305433   \n",
       "2           0.297786          0.212625          0.298507          0.305433   \n",
       "\n",
       "    split4_test_f1_1  mean_test_f1_1  std_test_f1_1  rank_test_f1_1  \\\n",
       "4           0.306434        0.315831       0.011196              16   \n",
       "5           0.306434        0.316241       0.015176              15   \n",
       "21          0.306434        0.328230       0.011707              16   \n",
       "3           0.306434        0.284754       0.039780              17   \n",
       "6           0.334503        0.320414       0.014379              14   \n",
       "22          0.334503        0.328082       0.010079              17   \n",
       "23          0.330750        0.333287       0.004861              10   \n",
       "1           0.209250        0.266277       0.043537              18   \n",
       "20          0.209250        0.266467       0.042034              20   \n",
       "2           0.209250        0.264720       0.044007              19   \n",
       "\n",
       "    mean_test_f1_macro  \n",
       "4             0.598528  \n",
       "5             0.597790  \n",
       "21            0.597506  \n",
       "3             0.591436  \n",
       "6             0.587756  \n",
       "22            0.587054  \n",
       "23            0.585346  \n",
       "1             0.584265  \n",
       "20            0.584189  \n",
       "2             0.583314  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/undersampling/model_selection/rule_based_results.csv')\n",
    "df['mean_test_f1_macro'] = (df['mean_test_f1_1'] + df['mean_test_f1_0']) / 2\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule Based:\n",
    "- k: 1,2,3\n",
    "- prune_size: 0.2-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier__class_weight</th>\n",
       "      <th>param_classifier__criterion</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__max_features</th>\n",
       "      <th>param_classifier__min_samples_leaf</th>\n",
       "      <th>param_classifier__min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_micro</th>\n",
       "      <th>split1_test_f1_micro</th>\n",
       "      <th>split2_test_f1_micro</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>split1_test_f1_1</th>\n",
       "      <th>split2_test_f1_1</th>\n",
       "      <th>split3_test_f1_1</th>\n",
       "      <th>split4_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.681814</td>\n",
       "      <td>0.732374</td>\n",
       "      <td>0.694996</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.372028</td>\n",
       "      <td>0.392995</td>\n",
       "      <td>0.374839</td>\n",
       "      <td>0.372937</td>\n",
       "      <td>0.378581</td>\n",
       "      <td>0.378276</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.694592</td>\n",
       "      <td>0.704019</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.375256</td>\n",
       "      <td>0.382018</td>\n",
       "      <td>0.374874</td>\n",
       "      <td>0.373493</td>\n",
       "      <td>0.374102</td>\n",
       "      <td>0.375949</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>6</td>\n",
       "      <td>0.587200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.693006</td>\n",
       "      <td>0.681694</td>\n",
       "      <td>0.704647</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.370509</td>\n",
       "      <td>0.374232</td>\n",
       "      <td>0.379959</td>\n",
       "      <td>0.378871</td>\n",
       "      <td>0.378130</td>\n",
       "      <td>0.376340</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>4</td>\n",
       "      <td>0.587063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.698333</td>\n",
       "      <td>0.710842</td>\n",
       "      <td>0.690941</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.376110</td>\n",
       "      <td>0.383749</td>\n",
       "      <td>0.373882</td>\n",
       "      <td>0.372105</td>\n",
       "      <td>0.374731</td>\n",
       "      <td>0.376116</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>3</td>\n",
       "      <td>0.587030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.696972</td>\n",
       "      <td>0.693246</td>\n",
       "      <td>0.681186</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.374514</td>\n",
       "      <td>0.377569</td>\n",
       "      <td>0.368213</td>\n",
       "      <td>0.384972</td>\n",
       "      <td>0.373377</td>\n",
       "      <td>0.375729</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>7</td>\n",
       "      <td>0.586801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.690388</td>\n",
       "      <td>0.697450</td>\n",
       "      <td>0.682847</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.373843</td>\n",
       "      <td>0.380818</td>\n",
       "      <td>0.370590</td>\n",
       "      <td>0.373712</td>\n",
       "      <td>0.378422</td>\n",
       "      <td>0.375477</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>5</td>\n",
       "      <td>0.585963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.709690</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.688338</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.376342</td>\n",
       "      <td>0.375839</td>\n",
       "      <td>0.369907</td>\n",
       "      <td>0.367353</td>\n",
       "      <td>0.378875</td>\n",
       "      <td>0.373663</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>13</td>\n",
       "      <td>0.585916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.683834</td>\n",
       "      <td>0.685555</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.374556</td>\n",
       "      <td>0.376724</td>\n",
       "      <td>0.374790</td>\n",
       "      <td>0.381558</td>\n",
       "      <td>0.382572</td>\n",
       "      <td>0.378040</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.706338</td>\n",
       "      <td>0.694637</td>\n",
       "      <td>0.681216</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.376873</td>\n",
       "      <td>0.381388</td>\n",
       "      <td>0.370289</td>\n",
       "      <td>0.377881</td>\n",
       "      <td>0.369842</td>\n",
       "      <td>0.375255</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>10</td>\n",
       "      <td>0.585538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.679929</td>\n",
       "      <td>0.687680</td>\n",
       "      <td>0.690523</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.371352</td>\n",
       "      <td>0.379721</td>\n",
       "      <td>0.374664</td>\n",
       "      <td>0.378293</td>\n",
       "      <td>0.382666</td>\n",
       "      <td>0.377339</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>2</td>\n",
       "      <td>0.584799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_classifier__class_weight param_classifier__criterion  \\\n",
       "152                             NaN                     entropy   \n",
       "5                               NaN                     entropy   \n",
       "7                               NaN                        gini   \n",
       "153                             NaN                     entropy   \n",
       "6                               NaN                     entropy   \n",
       "156                             NaN                     entropy   \n",
       "154                             NaN                        gini   \n",
       "19                              NaN                        gini   \n",
       "10                              NaN                     entropy   \n",
       "25                              NaN                        gini   \n",
       "\n",
       "     param_classifier__max_depth  param_classifier__max_features  \\\n",
       "152                         10.0                              14   \n",
       "5                           10.0                              15   \n",
       "7                           10.0                              12   \n",
       "153                         10.0                              12   \n",
       "6                           10.0                              11   \n",
       "156                         10.0                              11   \n",
       "154                         10.0                               6   \n",
       "19                          15.0                               8   \n",
       "10                          10.0                              11   \n",
       "25                           NaN                              10   \n",
       "\n",
       "     param_classifier__min_samples_leaf  param_classifier__min_samples_split  \\\n",
       "152                                  10                                   20   \n",
       "5                                    10                                   20   \n",
       "7                                    30                                  100   \n",
       "153                                  50                                  100   \n",
       "6                                    10                                   30   \n",
       "156                                  50                                   30   \n",
       "154                                 100                                   30   \n",
       "19                                  100                                   50   \n",
       "10                                   50                                   20   \n",
       "25                                  100                                   20   \n",
       "\n",
       "                                                params  split0_test_f1_micro  \\\n",
       "152  {'classifier__class_weight': None, 'classifier...              0.681814   \n",
       "5    {'classifier__class_weight': None, 'classifier...              0.694592   \n",
       "7    {'classifier__class_weight': None, 'classifier...              0.693006   \n",
       "153  {'classifier__class_weight': None, 'classifier...              0.698333   \n",
       "6    {'classifier__class_weight': None, 'classifier...              0.696972   \n",
       "156  {'classifier__class_weight': None, 'classifier...              0.690388   \n",
       "154  {'classifier__class_weight': None, 'classifier...              0.709690   \n",
       "19   {'classifier__class_weight': None, 'classifier...              0.683834   \n",
       "10   {'classifier__class_weight': None, 'classifier...              0.706338   \n",
       "25   {'classifier__class_weight': None, 'classifier...              0.679929   \n",
       "\n",
       "     split1_test_f1_micro  split2_test_f1_micro  ...  rank_test_f1_0  \\\n",
       "152              0.732374              0.694996  ...               3   \n",
       "5                0.704019              0.694293  ...               7   \n",
       "7                0.681694              0.704647  ...              10   \n",
       "153              0.710842              0.690941  ...               5   \n",
       "6                0.693246              0.681186  ...               8   \n",
       "156              0.697450              0.682847  ...               7   \n",
       "154              0.693859              0.688338  ...               4   \n",
       "19               0.685555              0.682353  ...              22   \n",
       "10               0.694637              0.681216  ...              11   \n",
       "25               0.687680              0.690523  ...              34   \n",
       "\n",
       "     split0_test_f1_1  split1_test_f1_1  split2_test_f1_1  split3_test_f1_1  \\\n",
       "152          0.372028          0.392995          0.374839          0.372937   \n",
       "5            0.375256          0.382018          0.374874          0.373493   \n",
       "7            0.370509          0.374232          0.379959          0.378871   \n",
       "153          0.376110          0.383749          0.373882          0.372105   \n",
       "6            0.374514          0.377569          0.368213          0.384972   \n",
       "156          0.373843          0.380818          0.370590          0.373712   \n",
       "154          0.376342          0.375839          0.369907          0.367353   \n",
       "19           0.374556          0.376724          0.374790          0.381558   \n",
       "10           0.376873          0.381388          0.370289          0.377881   \n",
       "25           0.371352          0.379721          0.374664          0.378293   \n",
       "\n",
       "     split4_test_f1_1  mean_test_f1_1  std_test_f1_1  rank_test_f1_1  \\\n",
       "152          0.378581        0.378276       0.007695               1   \n",
       "5            0.374102        0.375949       0.003095               6   \n",
       "7            0.378130        0.376340       0.003497               4   \n",
       "153          0.374731        0.376116       0.004031               3   \n",
       "6            0.373377        0.375729       0.005519               7   \n",
       "156          0.378422        0.375477       0.003657               5   \n",
       "154          0.378875        0.373663       0.004313              13   \n",
       "19           0.382572        0.378040       0.003387               1   \n",
       "10           0.369842        0.375255       0.004496              10   \n",
       "25           0.382666        0.377339       0.003949               2   \n",
       "\n",
       "     mean_test_f1_macro  \n",
       "152            0.590726  \n",
       "5              0.587200  \n",
       "7              0.587063  \n",
       "153            0.587030  \n",
       "6              0.586801  \n",
       "156            0.585963  \n",
       "154            0.585916  \n",
       "19             0.585620  \n",
       "10             0.585538  \n",
       "25             0.584799  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/undersampling/model_selection/decision_tree_results.csv')\n",
    "df['mean_test_f1_macro'] = (df['mean_test_f1_1'] + df['mean_test_f1_0']) / 2\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df = df.drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree:\n",
    "- Class Weight: NaN\n",
    "- criterion: entropy, gini\n",
    "- max_depth: 8-12\n",
    "- max_features: 11 in su\n",
    "- min_samples_leaf: 5-70\n",
    "- min_samples_split: 10-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_micro</th>\n",
       "      <th>split1_test_f1_micro</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>split1_test_f1_1</th>\n",
       "      <th>split2_test_f1_1</th>\n",
       "      <th>split3_test_f1_1</th>\n",
       "      <th>split4_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548884</td>\n",
       "      <td>0.045819</td>\n",
       "      <td>0.095229</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 0.1, 'classifier...</td>\n",
       "      <td>0.700952</td>\n",
       "      <td>0.705620</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.394914</td>\n",
       "      <td>0.402297</td>\n",
       "      <td>0.392420</td>\n",
       "      <td>0.394662</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.424271</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 0.1, 'classifier...</td>\n",
       "      <td>0.700952</td>\n",
       "      <td>0.705620</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.394914</td>\n",
       "      <td>0.402297</td>\n",
       "      <td>0.392420</td>\n",
       "      <td>0.394662</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.315308</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.044142</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.702702</td>\n",
       "      <td>0.706877</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.393257</td>\n",
       "      <td>0.399963</td>\n",
       "      <td>0.392393</td>\n",
       "      <td>0.393311</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>0.395221</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.405435</td>\n",
       "      <td>0.023237</td>\n",
       "      <td>0.070110</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.702702</td>\n",
       "      <td>0.706877</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.393257</td>\n",
       "      <td>0.399963</td>\n",
       "      <td>0.392393</td>\n",
       "      <td>0.393311</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>0.395221</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481480</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.081959</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.701760</td>\n",
       "      <td>0.704199</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.392391</td>\n",
       "      <td>0.399575</td>\n",
       "      <td>0.391826</td>\n",
       "      <td>0.393311</td>\n",
       "      <td>0.396355</td>\n",
       "      <td>0.394692</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>3</td>\n",
       "      <td>0.598546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.349926</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.055526</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.701760</td>\n",
       "      <td>0.704199</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.392391</td>\n",
       "      <td>0.399575</td>\n",
       "      <td>0.391826</td>\n",
       "      <td>0.393311</td>\n",
       "      <td>0.396355</td>\n",
       "      <td>0.394692</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>3</td>\n",
       "      <td>0.598546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.232823</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.034679</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.707431</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.389296</td>\n",
       "      <td>0.399349</td>\n",
       "      <td>0.390053</td>\n",
       "      <td>0.387777</td>\n",
       "      <td>0.395708</td>\n",
       "      <td>0.392437</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>7</td>\n",
       "      <td>0.597755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288855</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>0.057673</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.707431</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.389296</td>\n",
       "      <td>0.399349</td>\n",
       "      <td>0.390053</td>\n",
       "      <td>0.387777</td>\n",
       "      <td>0.395708</td>\n",
       "      <td>0.392437</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>7</td>\n",
       "      <td>0.597755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.554791</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>0.089254</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.700937</td>\n",
       "      <td>0.704019</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.390101</td>\n",
       "      <td>0.394354</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>0.393883</td>\n",
       "      <td>0.394702</td>\n",
       "      <td>0.392661</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>6</td>\n",
       "      <td>0.597543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.416122</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.070775</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.700937</td>\n",
       "      <td>0.704019</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.390101</td>\n",
       "      <td>0.394354</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>0.393883</td>\n",
       "      <td>0.394702</td>\n",
       "      <td>0.392661</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>6</td>\n",
       "      <td>0.597543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1        0.548884      0.045819         0.095229        0.010362   \n",
       "61       0.424271      0.014148         0.063366        0.001371   \n",
       "60       0.315308      0.015292         0.044142        0.004323   \n",
       "0        0.405435      0.023237         0.070110        0.006422   \n",
       "3        0.481480      0.016178         0.081959        0.012720   \n",
       "63       0.349926      0.013094         0.055526        0.003796   \n",
       "62       0.232823      0.010379         0.034679        0.003098   \n",
       "2        0.288855      0.012391         0.057673        0.005300   \n",
       "4        0.554791      0.021151         0.089254        0.009682   \n",
       "64       0.416122      0.008778         0.070775        0.011573   \n",
       "\n",
       "    param_classifier__learning_rate  param_classifier__max_depth  \\\n",
       "1                               0.1                            5   \n",
       "61                              0.1                            5   \n",
       "60                              1.0                            3   \n",
       "0                               1.0                            3   \n",
       "3                               1.0                            4   \n",
       "63                              1.0                            4   \n",
       "62                              1.0                            3   \n",
       "2                               1.0                            3   \n",
       "4                               1.0                            5   \n",
       "64                              1.0                            5   \n",
       "\n",
       "    param_classifier__n_estimators  \\\n",
       "1                              100   \n",
       "61                             100   \n",
       "60                             100   \n",
       "0                              100   \n",
       "3                              100   \n",
       "63                             100   \n",
       "62                              50   \n",
       "2                               50   \n",
       "4                              100   \n",
       "64                             100   \n",
       "\n",
       "                                               params  split0_test_f1_micro  \\\n",
       "1   {'classifier__learning_rate': 0.1, 'classifier...              0.700952   \n",
       "61  {'classifier__learning_rate': 0.1, 'classifier...              0.700952   \n",
       "60  {'classifier__learning_rate': 1, 'classifier__...              0.702702   \n",
       "0   {'classifier__learning_rate': 1, 'classifier__...              0.702702   \n",
       "3   {'classifier__learning_rate': 1, 'classifier__...              0.701760   \n",
       "63  {'classifier__learning_rate': 1, 'classifier__...              0.701760   \n",
       "62  {'classifier__learning_rate': 1, 'classifier__...              0.697106   \n",
       "2   {'classifier__learning_rate': 1, 'classifier__...              0.697106   \n",
       "4   {'classifier__learning_rate': 1, 'classifier__...              0.700937   \n",
       "64  {'classifier__learning_rate': 1, 'classifier__...              0.700937   \n",
       "\n",
       "    split1_test_f1_micro  ...  rank_test_f1_0  split0_test_f1_1  \\\n",
       "1               0.705620  ...               2          0.394914   \n",
       "61              0.705620  ...               2          0.394914   \n",
       "60              0.706877  ...               1          0.393257   \n",
       "0               0.706877  ...               1          0.393257   \n",
       "3               0.704199  ...              10          0.392391   \n",
       "63              0.704199  ...              10          0.392391   \n",
       "62              0.707431  ...               8          0.389296   \n",
       "2               0.707431  ...               8          0.389296   \n",
       "4               0.704019  ...               9          0.390101   \n",
       "64              0.704019  ...               9          0.390101   \n",
       "\n",
       "    split1_test_f1_1  split2_test_f1_1  split3_test_f1_1  split4_test_f1_1  \\\n",
       "1           0.402297          0.392420          0.394662          0.401500   \n",
       "61          0.402297          0.392420          0.394662          0.401500   \n",
       "60          0.399963          0.392393          0.393311          0.397178   \n",
       "0           0.399963          0.392393          0.393311          0.397178   \n",
       "3           0.399575          0.391826          0.393311          0.396355   \n",
       "63          0.399575          0.391826          0.393311          0.396355   \n",
       "62          0.399349          0.390053          0.387777          0.395708   \n",
       "2           0.399349          0.390053          0.387777          0.395708   \n",
       "4           0.394354          0.390263          0.393883          0.394702   \n",
       "64          0.394354          0.390263          0.393883          0.394702   \n",
       "\n",
       "    mean_test_f1_1  std_test_f1_1  rank_test_f1_1  mean_test_f1_macro  \n",
       "1         0.397159       0.003974               1            0.600317  \n",
       "61        0.397159       0.003974               1            0.600317  \n",
       "60        0.395221       0.002892               2            0.600007  \n",
       "0         0.395221       0.002892               2            0.600007  \n",
       "3         0.394692       0.002899               3            0.598546  \n",
       "63        0.394692       0.002899               3            0.598546  \n",
       "62        0.392437       0.004376               7            0.597755  \n",
       "2         0.392437       0.004376               7            0.597755  \n",
       "4         0.392661       0.002041               6            0.597543  \n",
       "64        0.392661       0.002041               6            0.597543  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/undersampling/model_selection/xgb_results.csv')\n",
    "df['mean_test_f1_macro'] = (df['mean_test_f1_1'] + df['mean_test_f1_0']) / 2\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB:\n",
    "- lr: 0.1-1\n",
    "- max_depth: 3-8\n",
    "- n_estimators: 75, 100, 150, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier__class_weight</th>\n",
       "      <th>param_classifier__criterion</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__max_features</th>\n",
       "      <th>param_classifier__min_samples_leaf</th>\n",
       "      <th>param_classifier__min_samples_split</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1_micro</th>\n",
       "      <th>split1_test_f1_micro</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>split1_test_f1_1</th>\n",
       "      <th>split2_test_f1_1</th>\n",
       "      <th>split3_test_f1_1</th>\n",
       "      <th>split4_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.722214</td>\n",
       "      <td>0.727451</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416470</td>\n",
       "      <td>0.423594</td>\n",
       "      <td>0.415902</td>\n",
       "      <td>0.421063</td>\n",
       "      <td>0.422525</td>\n",
       "      <td>0.419911</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.722723</td>\n",
       "      <td>0.728379</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417026</td>\n",
       "      <td>0.425120</td>\n",
       "      <td>0.414789</td>\n",
       "      <td>0.418380</td>\n",
       "      <td>0.421482</td>\n",
       "      <td>0.419359</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.720359</td>\n",
       "      <td>0.726314</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.412942</td>\n",
       "      <td>0.422578</td>\n",
       "      <td>0.414019</td>\n",
       "      <td>0.415162</td>\n",
       "      <td>0.420761</td>\n",
       "      <td>0.417092</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.720373</td>\n",
       "      <td>0.726329</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.413434</td>\n",
       "      <td>0.423647</td>\n",
       "      <td>0.414025</td>\n",
       "      <td>0.415358</td>\n",
       "      <td>0.418710</td>\n",
       "      <td>0.417035</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.719999</td>\n",
       "      <td>0.725685</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.411892</td>\n",
       "      <td>0.421508</td>\n",
       "      <td>0.412524</td>\n",
       "      <td>0.414891</td>\n",
       "      <td>0.418112</td>\n",
       "      <td>0.415785</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.616783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.719027</td>\n",
       "      <td>0.725880</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.412012</td>\n",
       "      <td>0.421023</td>\n",
       "      <td>0.411833</td>\n",
       "      <td>0.414488</td>\n",
       "      <td>0.418897</td>\n",
       "      <td>0.415650</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>3</td>\n",
       "      <td>0.616752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.720418</td>\n",
       "      <td>0.724922</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.412440</td>\n",
       "      <td>0.420356</td>\n",
       "      <td>0.411584</td>\n",
       "      <td>0.412188</td>\n",
       "      <td>0.416690</td>\n",
       "      <td>0.414652</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>4</td>\n",
       "      <td>0.616139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.718219</td>\n",
       "      <td>0.722693</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.410431</td>\n",
       "      <td>0.417330</td>\n",
       "      <td>0.407887</td>\n",
       "      <td>0.410466</td>\n",
       "      <td>0.413573</td>\n",
       "      <td>0.411937</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>5</td>\n",
       "      <td>0.613841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.716947</td>\n",
       "      <td>0.720822</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.410189</td>\n",
       "      <td>0.415952</td>\n",
       "      <td>0.408287</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.414185</td>\n",
       "      <td>0.411841</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>6</td>\n",
       "      <td>0.613530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__class_weight': None, 'classifier...</td>\n",
       "      <td>0.716274</td>\n",
       "      <td>0.721226</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.408768</td>\n",
       "      <td>0.417144</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.410856</td>\n",
       "      <td>0.414481</td>\n",
       "      <td>0.411940</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>5</td>\n",
       "      <td>0.613382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_classifier__class_weight param_classifier__criterion  \\\n",
       "0                              NaN                        gini   \n",
       "50                             NaN                        gini   \n",
       "51                             NaN                     entropy   \n",
       "1                              NaN                     entropy   \n",
       "52                             NaN                        gini   \n",
       "2                              NaN                        gini   \n",
       "53                             NaN                        gini   \n",
       "3                              NaN                     entropy   \n",
       "4                              NaN                     entropy   \n",
       "56                             NaN                     entropy   \n",
       "\n",
       "    param_classifier__max_depth  param_classifier__max_features  \\\n",
       "0                          20.0                               9   \n",
       "50                          NaN                              15   \n",
       "51                         20.0                              13   \n",
       "1                          20.0                              14   \n",
       "52                          NaN                              15   \n",
       "2                          20.0                               4   \n",
       "53                         20.0                               4   \n",
       "3                           NaN                               5   \n",
       "4                           NaN                               6   \n",
       "56                         20.0                              12   \n",
       "\n",
       "    param_classifier__min_samples_leaf  param_classifier__min_samples_split  \\\n",
       "0                                   10                                   20   \n",
       "50                                  10                                   20   \n",
       "51                                  10                                   50   \n",
       "1                                   10                                   50   \n",
       "52                                  10                                   50   \n",
       "2                                   10                                   50   \n",
       "53                                  10                                   50   \n",
       "3                                   10                                  100   \n",
       "4                                   30                                   20   \n",
       "56                                  30                                   50   \n",
       "\n",
       "    param_classifier__n_estimators  \\\n",
       "0                               50   \n",
       "50                              50   \n",
       "51                             100   \n",
       "1                              100   \n",
       "52                             100   \n",
       "2                              100   \n",
       "53                              50   \n",
       "3                              150   \n",
       "4                              150   \n",
       "56                             100   \n",
       "\n",
       "                                               params  split0_test_f1_micro  \\\n",
       "0   {'classifier__class_weight': None, 'classifier...              0.722214   \n",
       "50  {'classifier__class_weight': None, 'classifier...              0.722723   \n",
       "51  {'classifier__class_weight': None, 'classifier...              0.720359   \n",
       "1   {'classifier__class_weight': None, 'classifier...              0.720373   \n",
       "52  {'classifier__class_weight': None, 'classifier...              0.719999   \n",
       "2   {'classifier__class_weight': None, 'classifier...              0.719027   \n",
       "53  {'classifier__class_weight': None, 'classifier...              0.720418   \n",
       "3   {'classifier__class_weight': None, 'classifier...              0.718219   \n",
       "4   {'classifier__class_weight': None, 'classifier...              0.716947   \n",
       "56  {'classifier__class_weight': None, 'classifier...              0.716274   \n",
       "\n",
       "    split1_test_f1_micro  ...  rank_test_f1_0  split0_test_f1_1  \\\n",
       "0               0.727451  ...               1          0.416470   \n",
       "50              0.728379  ...               1          0.417026   \n",
       "51              0.726314  ...               2          0.412942   \n",
       "1               0.726329  ...               2          0.413434   \n",
       "52              0.725685  ...               3          0.411892   \n",
       "2               0.725880  ...               3          0.412012   \n",
       "53              0.724922  ...               4          0.412440   \n",
       "3               0.722693  ...               4          0.410431   \n",
       "4               0.720822  ...               5          0.410189   \n",
       "56              0.721226  ...               7          0.408768   \n",
       "\n",
       "    split1_test_f1_1  split2_test_f1_1  split3_test_f1_1  split4_test_f1_1  \\\n",
       "0           0.423594          0.415902          0.421063          0.422525   \n",
       "50          0.425120          0.414789          0.418380          0.421482   \n",
       "51          0.422578          0.414019          0.415162          0.420761   \n",
       "1           0.423647          0.414025          0.415358          0.418710   \n",
       "52          0.421508          0.412524          0.414891          0.418112   \n",
       "2           0.421023          0.411833          0.414488          0.418897   \n",
       "53          0.420356          0.411584          0.412188          0.416690   \n",
       "3           0.417330          0.407887          0.410466          0.413573   \n",
       "4           0.415952          0.408287          0.410590          0.414185   \n",
       "56          0.417144          0.408451          0.410856          0.414481   \n",
       "\n",
       "    mean_test_f1_1  std_test_f1_1  rank_test_f1_1  mean_test_f1_macro  \n",
       "0         0.419911       0.003151               1            0.619985  \n",
       "50        0.419359       0.003605               1            0.619593  \n",
       "51        0.417092       0.003846               2            0.617624  \n",
       "1         0.417035       0.003778               2            0.617553  \n",
       "52        0.415785       0.003599               3            0.616783  \n",
       "2         0.415650       0.003703               3            0.616752  \n",
       "53        0.414652       0.003378               4            0.616139  \n",
       "3         0.411937       0.003243               5            0.613841  \n",
       "4         0.411841       0.002804               6            0.613530  \n",
       "56        0.411940       0.003375               5            0.613382  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/ml_datasets/undersampling/model_selection/random_forest_results.csv')\n",
    "df['mean_test_f1_macro'] = (df['mean_test_f1_1'] + df['mean_test_f1_0']) / 2\n",
    "df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df = df.drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "- class_weight: NaN\n",
    "- criterion: entropy, gini\n",
    "- max_depth: None\n",
    "- max_features: 4 in su\n",
    "- min_samples_leaf: 5-30\n",
    "- min_samples_split: 10-50\n",
    "- n_estimators: 50, 75, 100, 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "dev_data = pd.read_csv('../../data/ml_datasets/undersampling/dev_set.csv').sample(frac = 1, random_state=RANDOM_STATE) # Shuffling the data to not introduce bias\n",
    "testing_data = pd.read_csv('../../data/ml_datasets/undersampling/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_label = dev_data.pop('label')\n",
    "test_label = testing_data.pop('label')\n",
    "\n",
    "dev_set = dev_data\n",
    "dev_set['race_season%autumn'] = dev_set['race_season%autumn'].astype(int)\n",
    "dev_set['race_season%spring'] = dev_set['race_season%spring'].astype(int)\n",
    "dev_set['race_season%summer'] = dev_set['race_season%summer'].astype(int)\n",
    "dev_set['race_season%winter'] = dev_set['race_season%winter'].astype(int)\n",
    "\n",
    "test_set = testing_data\n",
    "test_set['race_season%autumn'] = test_set['race_season%autumn'].astype(int)\n",
    "test_set['race_season%spring'] = test_set['race_season%spring'].astype(int)\n",
    "test_set['race_season%summer'] = test_set['race_season%summer'].astype(int)\n",
    "test_set['race_season%winter'] = test_set['race_season%winter'].astype(int)\n",
    "\n",
    "N_JOBS = 6\n",
    "USER = 'Jacopo'\n",
    "RUS = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for the best hyperparameters\n",
    "def f1_class_scorer(class_index):\n",
    "    # Function to calculate F1 score for a specific class\n",
    "    def score_function(y_true, y_pred):\n",
    "        return f1_score(y_true, y_pred, average=None)[class_index] # Compute the F1 score for each class and return the one specified\n",
    "    return make_scorer(score_function)\n",
    "\n",
    "# Scorer for class 0 and 1\n",
    "f1_class_0 = f1_class_scorer(0)\n",
    "f1_class_1 = f1_class_scorer(1)\n",
    "\n",
    "scoring={\n",
    "        'f1_macro': 'f1_macro', # F1 macro for each class\n",
    "        'f1_0': f1_class_0,     # F1 only for class 0\n",
    "        'f1_1': f1_class_1      # F1 only for class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "def func(*args):\n",
    "    global i\n",
    "    print(f'Configurazione: {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree:\n",
    "- Class Weight: NaN\n",
    "- criterion: entropy, gini\n",
    "- max_depth: 8-12\n",
    "- max_features: 11 in su\n",
    "- min_samples_leaf: 5-70\n",
    "- min_samples_split: 10-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurazione: 1\n",
      "Configurazione: 2\n",
      "Configurazione: 3\n",
      "Configurazione: 4\n",
      "Configurazione: 5\n",
      "Configurazione: 6\n",
      "Configurazione: 7\n",
      "Configurazione: 8\n",
      "Configurazione: 9\n",
      "Configurazione: 10\n",
      "Configurazione: 11\n",
      "Configurazione: 12\n",
      "Configurazione: 13\n",
      "Configurazione: 14\n",
      "Configurazione: 15\n",
      "Configurazione: 16\n",
      "Configurazione: 17\n",
      "Configurazione: 18\n",
      "Configurazione: 19\n",
      "Configurazione: 20\n",
      "Configurazione: 21\n",
      "Configurazione: 22\n",
      "Configurazione: 23\n",
      "Configurazione: 24\n",
      "Configurazione: 25\n",
      "Configurazione: 26\n",
      "Configurazione: 27\n",
      "Configurazione: 28\n",
      "Configurazione: 29\n",
      "Configurazione: 30\n",
      "Configurazione: 31\n",
      "Configurazione: 32\n",
      "Configurazione: 33\n",
      "Configurazione: 34\n",
      "Configurazione: 35\n",
      "Configurazione: 36\n",
      "Configurazione: 37\n",
      "Configurazione: 38\n",
      "Configurazione: 39\n",
      "Configurazione: 40\n",
      "Configurazione: 41\n",
      "Configurazione: 42\n",
      "Configurazione: 43\n",
      "Configurazione: 44\n",
      "Configurazione: 45\n",
      "Configurazione: 46\n",
      "Configurazione: 47\n",
      "Configurazione: 48\n",
      "Configurazione: 49\n",
      "Configurazione: 50\n",
      "Configurazione: 51\n",
      "Configurazione: 52\n",
      "Configurazione: 53\n",
      "Configurazione: 54\n",
      "Configurazione: 55\n",
      "Configurazione: 56\n",
      "Configurazione: 57\n",
      "Configurazione: 58\n",
      "Configurazione: 59\n",
      "Configurazione: 60\n",
      "Configurazione: 61\n",
      "Configurazione: 62\n",
      "Configurazione: 63\n",
      "Configurazione: 64\n",
      "Configurazione: 65\n",
      "Configurazione: 66\n",
      "Configurazione: 67\n",
      "Configurazione: 68\n",
      "Configurazione: 69\n",
      "Configurazione: 70\n",
      "Configurazione: 71\n",
      "Configurazione: 72\n",
      "Configurazione: 73\n",
      "Configurazione: 74\n",
      "Configurazione: 75\n",
      "Configurazione: 76\n",
      "Configurazione: 77\n",
      "Configurazione: 78\n",
      "Configurazione: 79\n",
      "Configurazione: 80\n",
      "Configurazione: 81\n",
      "Configurazione: 82\n",
      "Configurazione: 83\n",
      "Configurazione: 84\n",
      "Configurazione: 85\n",
      "Configurazione: 86\n",
      "Configurazione: 87\n",
      "Configurazione: 88\n",
      "Configurazione: 89\n",
      "Configurazione: 90\n",
      "Configurazione: 91\n",
      "Configurazione: 92\n",
      "Configurazione: 93\n",
      "Configurazione: 94\n",
      "Configurazione: 95\n",
      "Configurazione: 96\n",
      "Configurazione: 97\n",
      "Configurazione: 98\n",
      "Configurazione: 99\n",
      "Configurazione: 100\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\"classifier__max_depth\": Integer(8, 20),\n",
    "              \"classifier__max_features\": Integer(11, len(dev_set.iloc[0]) + 1),\n",
    "              \"classifier__min_samples_split\": Integer(10, 50),\n",
    "              \"classifier__min_samples_leaf\": Integer(5, 70),\n",
    "              \"classifier__criterion\": Categorical(['gini', 'entropy'])}\n",
    "n_iter_search = 100 # Number of iterations\n",
    "clf = tree.DecisionTreeClassifier() # Model\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('undersampler', RUS),\n",
    "    ('classifier', clf)\n",
    "], verbose=False)\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = BayesSearchCV(pipeline, search_spaces=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=scoring,\n",
    "                            refit='f1_macro',\n",
    "                            cv=SKF)\n",
    "rand_search.fit(dev_set, dev_label, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.589865</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.379240</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.800490</td>\n",
       "      <td>0.009114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.589708</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.800509</td>\n",
       "      <td>0.010439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.589376</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.378843</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.799910</td>\n",
       "      <td>0.009264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.589347</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.378873</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.799821</td>\n",
       "      <td>0.009290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.589266</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.378745</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.799787</td>\n",
       "      <td>0.009285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.589205</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.378612</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.799798</td>\n",
       "      <td>0.008643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.588867</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.377841</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.799893</td>\n",
       "      <td>0.009166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.587546</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.376905</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.798187</td>\n",
       "      <td>0.004870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.587449</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.376643</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.798255</td>\n",
       "      <td>0.003668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.587365</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.376102</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.798627</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_f1_macro  std_test_f1_macro  mean_test_f1_1  std_test_f1_1  \\\n",
       "80            0.589865           0.007046        0.379240       0.005130   \n",
       "86            0.589708           0.008169        0.378906       0.006153   \n",
       "81            0.589376           0.007442        0.378843       0.005704   \n",
       "98            0.589347           0.007082        0.378873       0.005044   \n",
       "79            0.589266           0.007023        0.378745       0.004921   \n",
       "97            0.589205           0.006667        0.378612       0.004887   \n",
       "89            0.588867           0.007048        0.377841       0.005296   \n",
       "94            0.587546           0.004514        0.376905       0.004301   \n",
       "82            0.587449           0.003263        0.376643       0.003004   \n",
       "84            0.587365           0.003048        0.376102       0.002533   \n",
       "\n",
       "    mean_test_f1_0  std_test_f1_0  \n",
       "80        0.800490       0.009114  \n",
       "86        0.800509       0.010439  \n",
       "81        0.799910       0.009264  \n",
       "98        0.799821       0.009290  \n",
       "79        0.799787       0.009285  \n",
       "97        0.799798       0.008643  \n",
       "89        0.799893       0.009166  \n",
       "94        0.798187       0.004870  \n",
       "82        0.798255       0.003668  \n",
       "84        0.798627       0.003690  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/undersampling/model_selection/{USER}_decision_tree_results_bayes.csv', index=False)\n",
    "df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB:\n",
    "- lr: 0.1-1\n",
    "- max_depth: 3-8\n",
    "- n_estimators: 75, 100, 150, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_dist = {\n",
    "#     \"classifier__n_estimators\": Categorical([75, 100, 150, 200]), #Jacopo\n",
    "#     \"classifier__max_depth\": Integer(3, 8), \n",
    "#     \"classifier__learning_rate\": Real(0.1, 1)\n",
    "# }\n",
    "# clf = XGBClassifier() # Model\n",
    "# n_iter_search = 1000  # Number of iterations\n",
    "\n",
    "# pipeline = ImbPipeline([\n",
    "#     ('undersampler', RUS),\n",
    "#     ('classifier', clf)\n",
    "# ], verbose=False)\n",
    "\n",
    "# # Define the grid search\n",
    "# rand_search = BayesSearchCV(pipeline, search_spaces=param_dist, \n",
    "#                             n_iter=n_iter_search, \n",
    "#                             n_jobs=N_JOBS, \n",
    "#                             scoring=scoring,\n",
    "#                             refit='f1_macro',\n",
    "#                             cv=SKF)\n",
    "# i = 1\n",
    "# rand_search.fit(dev_set, dev_label, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(rand_search.cv_results_)\n",
    "# df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "# df.to_csv(f'../../data/ml_datasets/undersampling/model_selection/{USER}_xgb_results_bayes.csv', index=False)\n",
    "# df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "- class_weight: NaN\n",
    "- criterion: entropy, gini\n",
    "- max_depth: None\n",
    "- max_features: 4 in su\n",
    "- min_samples_leaf: 5-30\n",
    "- min_samples_split: 10-50\n",
    "- n_estimators: 50, 75, 100, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_dist = {\"classifier__max_depth\": Integer(8, 12),\n",
    "#               \"classifier__max_features\": Integer(11, len(dev_set.iloc[0]) + 1),\n",
    "#               \"classifier__min_samples_split\": Integer(10, 50),\n",
    "#               \"classifier__min_samples_leaf\": Integer(5, 70),\n",
    "#               \"classifier__criterion\": Categorical(['gini', 'entropy']),\n",
    "#               \"classifier__n_estimators\": Categorical(50, 75, 100, 150, 200)}\n",
    "# n_iter_search = 1000 # Number of iterations (Total-Iteration: 400)\n",
    "# clf = RandomForestClassifier() # Model\n",
    "\n",
    "# pipeline = ImbPipeline([\n",
    "#     ('undersampler', RUS),\n",
    "#     ('classifier', clf)\n",
    "# ], verbose=False)\n",
    "\n",
    "# # Define the grid search\n",
    "# rand_search = BayesSearchCV(pipeline, search_spaces=param_dist, \n",
    "#                             n_iter=n_iter_search, \n",
    "#                             n_jobs=N_JOBS, \n",
    "#                             scoring=scoring,\n",
    "#                             refit='f1_macro',\n",
    "#                             cv=SKF)\n",
    "# i = 1\n",
    "# rand_search.fit(dev_set, dev_label, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(rand_search.cv_results_)\n",
    "# df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "# df.to_csv(f'../../data/ml_datasets/undersampling/model_selection/{USER}_random_forest_results_bayes.csv', index=False)\n",
    "# df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule Based:\n",
    "- k: 1,2,3\n",
    "- prune_size: 0.2-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurazione: 1\n",
      "Configurazione: 2\n",
      "Configurazione: 3\n",
      "Configurazione: 4\n",
      "Configurazione: 5\n",
      "Configurazione: 6\n",
      "Configurazione: 7\n",
      "Configurazione: 8\n",
      "Configurazione: 9\n",
      "Configurazione: 10\n",
      "Configurazione: 11\n",
      "Configurazione: 12\n",
      "Configurazione: 13\n",
      "Configurazione: 14\n",
      "Configurazione: 15\n",
      "Configurazione: 16\n",
      "Configurazione: 17\n",
      "Configurazione: 18\n",
      "Configurazione: 19\n",
      "Configurazione: 20\n",
      "Configurazione: 21\n",
      "Configurazione: 22\n",
      "Configurazione: 23\n",
      "Configurazione: 24\n",
      "Configurazione: 25\n",
      "Configurazione: 26\n",
      "Configurazione: 27\n",
      "Configurazione: 28\n",
      "Configurazione: 29\n",
      "Configurazione: 30\n",
      "Configurazione: 31\n",
      "Configurazione: 32\n",
      "Configurazione: 33\n",
      "Configurazione: 34\n",
      "Configurazione: 35\n",
      "Configurazione: 36\n",
      "Configurazione: 37\n",
      "Configurazione: 38\n",
      "Configurazione: 39\n",
      "Configurazione: 40\n",
      "Configurazione: 41\n",
      "Configurazione: 42\n",
      "Configurazione: 43\n",
      "Configurazione: 44\n",
      "Configurazione: 45\n",
      "Configurazione: 46\n",
      "Configurazione: 47\n",
      "Configurazione: 48\n",
      "Configurazione: 49\n",
      "Configurazione: 50\n",
      "Configurazione: 51\n",
      "Configurazione: 52\n",
      "Configurazione: 53\n",
      "Configurazione: 54\n",
      "Configurazione: 55\n",
      "Configurazione: 56\n",
      "Configurazione: 57\n",
      "Configurazione: 58\n",
      "Configurazione: 59\n",
      "Configurazione: 60\n",
      "Configurazione: 61\n",
      "Configurazione: 62\n",
      "Configurazione: 63\n",
      "Configurazione: 64\n",
      "Configurazione: 65\n",
      "Configurazione: 66\n",
      "Configurazione: 67\n",
      "Configurazione: 68\n",
      "Configurazione: 69\n",
      "Configurazione: 70\n",
      "Configurazione: 71\n",
      "Configurazione: 72\n",
      "Configurazione: 73\n",
      "Configurazione: 74\n",
      "Configurazione: 75\n",
      "Configurazione: 76\n",
      "Configurazione: 77\n",
      "Configurazione: 78\n",
      "Configurazione: 79\n",
      "Configurazione: 80\n",
      "Configurazione: 81\n",
      "Configurazione: 82\n",
      "Configurazione: 83\n",
      "Configurazione: 84\n",
      "Configurazione: 85\n",
      "Configurazione: 86\n",
      "Configurazione: 87\n",
      "Configurazione: 88\n",
      "Configurazione: 89\n",
      "Configurazione: 90\n",
      "Configurazione: 91\n",
      "Configurazione: 92\n",
      "Configurazione: 93\n",
      "Configurazione: 94\n",
      "Configurazione: 95\n",
      "Configurazione: 96\n",
      "Configurazione: 97\n",
      "Configurazione: 98\n",
      "Configurazione: 99\n",
      "Configurazione: 100\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'classifier__prune_size': Real(0.2, 0.4),\n",
    "    'classifier__k': Categorical([1, 2, 3])\n",
    "}\n",
    "\n",
    "n_iter_search = 100 # Number of iterations\n",
    "clf = lw.RIPPER(\n",
    "    max_rules=10,        # Moderate rule complexity\n",
    "    max_rule_conds=7,    # Enough room for moderately complex conditions\n",
    "    max_total_conds=35   # Cap total conditions to avoid runaway complexity\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('undersampler', RUS),\n",
    "    ('classifier', clf)\n",
    "], verbose=False)\n",
    "\n",
    "# Define the grid search\n",
    "rand_search = BayesSearchCV(pipeline, search_spaces=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=3, \n",
    "                            scoring=scoring,\n",
    "                            refit='f1_macro',\n",
    "                            cv=SKF)\n",
    "i = 1\n",
    "rand_search.fit(dev_set, dev_label, callback=func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.598815</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.309166</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.888463</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.598815</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.309166</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.888463</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.598815</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.309166</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.888463</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.598815</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.309166</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.888463</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.598606</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.893862</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.598606</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.893862</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.598606</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.893862</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.598606</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.893862</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.598528</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.315831</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.881225</td>\n",
       "      <td>0.016210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.598322</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.315339</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.881306</td>\n",
       "      <td>0.015604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_f1_macro  std_test_f1_macro  mean_test_f1_1  std_test_f1_1  \\\n",
       "1             0.598815           0.002274        0.309166       0.009474   \n",
       "19            0.598815           0.002274        0.309166       0.009474   \n",
       "56            0.598815           0.002274        0.309166       0.009474   \n",
       "85            0.598815           0.002274        0.309166       0.009474   \n",
       "46            0.598606           0.002513        0.303350       0.004375   \n",
       "98            0.598606           0.002513        0.303350       0.004375   \n",
       "77            0.598606           0.002513        0.303350       0.004375   \n",
       "2             0.598606           0.002513        0.303350       0.004375   \n",
       "59            0.598528           0.002668        0.315831       0.011196   \n",
       "17            0.598322           0.001851        0.315339       0.015330   \n",
       "\n",
       "    mean_test_f1_0  std_test_f1_0  \n",
       "1         0.888463       0.011218  \n",
       "19        0.888463       0.011218  \n",
       "56        0.888463       0.011218  \n",
       "85        0.888463       0.011218  \n",
       "46        0.893862       0.001096  \n",
       "98        0.893862       0.001096  \n",
       "77        0.893862       0.001096  \n",
       "2         0.893862       0.001096  \n",
       "59        0.881225       0.016210  \n",
       "17        0.881306       0.015604  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rand_search.cv_results_)\n",
    "df.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df.to_csv(f'../../data/ml_datasets/undersampling/model_selection/{USER}_rule_based_bayes.csv', index=False)\n",
    "df.head(n=10)[['mean_test_f1_macro', 'std_test_f1_macro', 'mean_test_f1_1', 'std_test_f1_1', 'mean_test_f1_0', 'std_test_f1_0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_see = ['mean_test_f1_1', 'mean_test_f1_0', 'mean_test_f1_macro', 'model']\n",
    "USER_1 = 'Jacopo'\n",
    "USER_2 = 'Simone'\n",
    "\n",
    "models = ['rule_based', 'xgb', 'random_forest']\n",
    "path_dt = f'../../data/ml_datasets/undersampling/model_selection/{USER_1}_decision_tree_results_bayes.csv'\n",
    "path_rb = f'../../data/ml_datasets/undersampling/model_selection/{USER_1}_rule_based_bayes.csv'\n",
    "path_xgb = f'../../data/ml_datasets/undersampling/model_selection/{USER_2}_xgb_results_bayes.csv'\n",
    "path_rf = f'../../data/ml_datasets/undersampling/model_selection/{USER_2}_random_forest_results_bayes.csv'\n",
    "\n",
    "path_list = [path_rb, path_xgb, path_rf]\n",
    "\n",
    "df_results = pd.read_csv(path_dt)\n",
    "df_results['model'] = 'decision_tree'\n",
    "df_results = df_results[columns_to_see]\n",
    "\n",
    "for i, path in enumerate(path_list):\n",
    "    df = pd.read_csv(path)\n",
    "    df['model'] = models[i]\n",
    "    df.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "    df = df[columns_to_see]\n",
    "\n",
    "    df_results = pd.concat([df_results, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>mean_test_f1_0</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.431856</td>\n",
       "      <td>0.826390</td>\n",
       "      <td>0.629123</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.431154</td>\n",
       "      <td>0.826642</td>\n",
       "      <td>0.628898</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430332</td>\n",
       "      <td>0.826244</td>\n",
       "      <td>0.628288</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430424</td>\n",
       "      <td>0.825812</td>\n",
       "      <td>0.628118</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.825693</td>\n",
       "      <td>0.627988</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.429974</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.627890</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.429133</td>\n",
       "      <td>0.825637</td>\n",
       "      <td>0.627385</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.429415</td>\n",
       "      <td>0.825207</td>\n",
       "      <td>0.627311</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428722</td>\n",
       "      <td>0.825204</td>\n",
       "      <td>0.626963</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.428434</td>\n",
       "      <td>0.825062</td>\n",
       "      <td>0.626748</td>\n",
       "      <td>xgb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_f1_1  mean_test_f1_0  mean_test_f1_macro          model\n",
       "0        0.431856        0.826390            0.629123            xgb\n",
       "1        0.431154        0.826642            0.628898            xgb\n",
       "2        0.430332        0.826244            0.628288            xgb\n",
       "3        0.430424        0.825812            0.628118            xgb\n",
       "4        0.430282        0.825693            0.627988            xgb\n",
       "5        0.429974        0.825806            0.627890            xgb\n",
       "6        0.429133        0.825637            0.627385            xgb\n",
       "7        0.429415        0.825207            0.627311            xgb\n",
       "0        0.428722        0.825204            0.626963  random_forest\n",
       "8        0.428434        0.825062            0.626748            xgb"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='mean_test_f1_macro', ascending=False, inplace=True)\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner model is the \"XGBoost\", next step is to take the \"best\" hyperparameters and retrain the model on the whole developmente set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>split1_test_f1_macro</th>\n",
       "      <th>split2_test_f1_macro</th>\n",
       "      <th>split3_test_f1_macro</th>\n",
       "      <th>split4_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_f1_0</th>\n",
       "      <th>rank_test_f1_0</th>\n",
       "      <th>split0_test_f1_1</th>\n",
       "      <th>split1_test_f1_1</th>\n",
       "      <th>split2_test_f1_1</th>\n",
       "      <th>split3_test_f1_1</th>\n",
       "      <th>split4_test_f1_1</th>\n",
       "      <th>mean_test_f1_1</th>\n",
       "      <th>std_test_f1_1</th>\n",
       "      <th>rank_test_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108715</td>\n",
       "      <td>13</td>\n",
       "      <td>200</td>\n",
       "      <td>0.628735</td>\n",
       "      <td>0.630668</td>\n",
       "      <td>0.626354</td>\n",
       "      <td>0.630071</td>\n",
       "      <td>0.629789</td>\n",
       "      <td>0.629123</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>2</td>\n",
       "      <td>0.431153</td>\n",
       "      <td>0.434547</td>\n",
       "      <td>0.427617</td>\n",
       "      <td>0.432834</td>\n",
       "      <td>0.433131</td>\n",
       "      <td>0.431856</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100231</td>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>0.628445</td>\n",
       "      <td>0.630068</td>\n",
       "      <td>0.626806</td>\n",
       "      <td>0.627934</td>\n",
       "      <td>0.631238</td>\n",
       "      <td>0.628898</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.433799</td>\n",
       "      <td>0.427756</td>\n",
       "      <td>0.429542</td>\n",
       "      <td>0.434372</td>\n",
       "      <td>0.431154</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>0.628431</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.625652</td>\n",
       "      <td>0.627744</td>\n",
       "      <td>0.630681</td>\n",
       "      <td>0.628288</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>3</td>\n",
       "      <td>0.430343</td>\n",
       "      <td>0.432376</td>\n",
       "      <td>0.425606</td>\n",
       "      <td>0.429445</td>\n",
       "      <td>0.433889</td>\n",
       "      <td>0.430332</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104429</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>0.628407</td>\n",
       "      <td>0.628220</td>\n",
       "      <td>0.626120</td>\n",
       "      <td>0.628743</td>\n",
       "      <td>0.629102</td>\n",
       "      <td>0.628118</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>4</td>\n",
       "      <td>0.430261</td>\n",
       "      <td>0.430904</td>\n",
       "      <td>0.427270</td>\n",
       "      <td>0.430959</td>\n",
       "      <td>0.432728</td>\n",
       "      <td>0.430424</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101535</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>0.627108</td>\n",
       "      <td>0.627773</td>\n",
       "      <td>0.626306</td>\n",
       "      <td>0.628548</td>\n",
       "      <td>0.630202</td>\n",
       "      <td>0.627988</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>6</td>\n",
       "      <td>0.428845</td>\n",
       "      <td>0.430693</td>\n",
       "      <td>0.427342</td>\n",
       "      <td>0.430784</td>\n",
       "      <td>0.433747</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_classifier__learning_rate  param_classifier__max_depth  \\\n",
       "0                         0.108715                           13   \n",
       "1                         0.100231                           14   \n",
       "2                         0.100000                           15   \n",
       "3                         0.104429                           12   \n",
       "4                         0.101535                           15   \n",
       "\n",
       "   param_classifier__n_estimators  split0_test_f1_macro  split1_test_f1_macro  \\\n",
       "0                             200              0.628735              0.630668   \n",
       "1                             200              0.628445              0.630068   \n",
       "2                             200              0.628431              0.628931   \n",
       "3                             200              0.628407              0.628220   \n",
       "4                             150              0.627108              0.627773   \n",
       "\n",
       "   split2_test_f1_macro  split3_test_f1_macro  split4_test_f1_macro  \\\n",
       "0              0.626354              0.630071              0.629789   \n",
       "1              0.626806              0.627934              0.631238   \n",
       "2              0.625652              0.627744              0.630681   \n",
       "3              0.626120              0.628743              0.629102   \n",
       "4              0.626306              0.628548              0.630202   \n",
       "\n",
       "   mean_test_f1_macro  std_test_f1_macro  ...  std_test_f1_0  rank_test_f1_0  \\\n",
       "0            0.629123           0.001520  ...       0.000734               2   \n",
       "1            0.628898           0.001572  ...       0.000768               1   \n",
       "2            0.628288           0.001637  ...       0.000707               3   \n",
       "3            0.628118           0.001043  ...       0.000625               4   \n",
       "4            0.627988           0.001332  ...       0.000679               6   \n",
       "\n",
       "   split0_test_f1_1  split1_test_f1_1  split2_test_f1_1  split3_test_f1_1  \\\n",
       "0          0.431153          0.434547          0.427617          0.432834   \n",
       "1          0.430303          0.433799          0.427756          0.429542   \n",
       "2          0.430343          0.432376          0.425606          0.429445   \n",
       "3          0.430261          0.430904          0.427270          0.430959   \n",
       "4          0.428845          0.430693          0.427342          0.430784   \n",
       "\n",
       "   split4_test_f1_1  mean_test_f1_1  std_test_f1_1  rank_test_f1_1  \n",
       "0          0.433131        0.431856       0.002379               1  \n",
       "1          0.434372        0.431154       0.002539               2  \n",
       "2          0.433889        0.430332       0.002827               4  \n",
       "3          0.432728        0.430424       0.001778               3  \n",
       "4          0.433747        0.430282       0.002151               5  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_2 = 'Simone'\n",
    "path_xgb = f'../../data/ml_datasets/undersampling/model_selection/{USER_2}_xgb_results_bayes.csv'\n",
    "df_xgb = pd.read_csv(path_xgb).drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'params'])\n",
    "df_xgb.sort_values(by='rank_test_f1_macro', inplace=True)\n",
    "df_xgb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.865241\n",
       "1    0.134759\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = pd.read_csv('../../data/ml_datasets/undersampling/dev_set.csv')\n",
    "dev_label = dev_set.pop('label')\n",
    "test_set = pd.read_csv('../../data/ml_datasets/undersampling/test_set.csv')\n",
    "test_label = test_set.pop('label')\n",
    "dev_label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "RUS = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "dev_set, dev_label = RUS.fit_resample(dev_set, dev_label)\n",
    "dev_set, dev_label = shuffle(dev_set, dev_label, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     27446\n",
      "           1       0.26      0.73      0.38      4203\n",
      "\n",
      "    accuracy                           0.68     31649\n",
      "   macro avg       0.60      0.70      0.58     31649\n",
      "weighted avg       0.85      0.68      0.73     31649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_xgb = XGBClassifier(n_estimators=200, max_depth=13, learning_rate=0.108715)\n",
    "rf_xgb.fit(dev_set, dev_label)\n",
    "\n",
    "predicitions = rf_xgb.predict(test_set)\n",
    "print(classification_report(test_label, predicitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f931a2a2830>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABvXElEQVR4nO3dd1RU19oG8GdoQy/SBERRkWLFijUqYjAqthjsPYktxkjuTdQkovFG06NfYouxxt67JgbUWIid2CgiCIp06Z2Z/f2Bjk5EAwocBp7fWqwl+5yZeTkg87DPe/aRCSEEiIiIiCSiJXUBREREVLsxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJLSkbqAslAqlXjw4AFMTEwgk8mkLoeIiIjKQAiBrKws2NvbQ0vr+fMfGhFGHjx4AEdHR6nLICIiopdw79491KtX77nbNSKMmJiYACj5YkxNTSWuhoiIiMoiMzMTjo6Oqvfx59GIMPL41IypqSnDCBERkYb5txYLNrASERGRpBhGiIiISFIMI0RERCQpjegZKQuFQoGioiKpyyAiemna2trQ0dHhEgZU69SIMJKdnY379+9DCCF1KUREr8TQ0BB2dnbQ09OTuhSiKqPxYUShUOD+/fswNDSEtbU1/6IgIo0khEBhYSGSk5MRHR2NJk2avHCRKKKaROPDSFFREYQQsLa2hoGBgdTlEBG9NAMDA+jq6iImJgaFhYXQ19eXuiSiKlFjYjdnRIioJuBsCNVG/KknIiIiSZU7jPz555/w9fWFvb09ZDIZ9u3b96+POXnyJNq0aQO5XA5nZ2esX7/+JUolIiKimqjcYSQnJwetWrXCsmXLyrR/dHQ0+vXrh549eyIkJAQffPAB3n77bfz222/lLpaIiIhqnnKHkTfeeAP/+9//MHjw4DLtv3LlSjRs2BDfffcd3N3d8d5772Ho0KH44Ycfyl1sTaFQKNC5c2cMGTJEbTwjIwOOjo745JNP1MZ3794NLy8vWFhYwMDAAK6urpg4cSKuXr2q2mf9+vWQyWSqD2NjY7Rt2xZ79uypkq/psR49euCDDz6o0tesLEIIzJs3D3Z2djAwMIC3tzdu3779wsc4OTmpfR8ef0yfPl21T35+PqZPnw5LS0sYGxvjzTffRGJiYqnPl5qainr16kEmkyE9Pb3Ufc6ePQsdHR14eHg8sy0uLg6jR4+GpaUlDAwM0KJFC1y6dEm1vbRaZTIZvvnmG7XnOXz4MDw9PWFgYAALCwsMGjRIbfvFixfRq1cvmJubw8LCAj4+Pvj777/V9hFC4Ntvv4WLiwvkcjkcHBzwxRdfqO1TUFCATz75BA0aNIBcLoeTkxPWrl2r2t6jR49S6+3Xr1+px2bKlCmQyWRYsmSJ2viVK1fQu3dvmJubw9LSEu+++y6ys7PV9nn//ffRtm1byOXyUo/tyZMnMXDgQNjZ2cHIyAgeHh7YvHnzM/stWbIErq6uMDAwgKOjI2bNmoX8/PxS6yWqrSq9ZyQ4OBje3t5qYz4+PggODn7uYwoKCpCZman2UZNoa2tj/fr1OHbsmNovrxkzZqBOnToICAhQjX388ccYNmwYPDw8cODAAYSHh2PLli1o1KgR5syZo/a8pqamiI+PR3x8PK5evQofHx/4+fkhPDy8yr62muTrr7/G//3f/2HlypU4f/48jIyM4OPj88I3kosXL6q+B/Hx8Th+/DgA4K233lLtM2vWLBw8eBA7d+7EqVOn8ODBg2eC6WOTJk1Cy5Ytn/t66enpGDt2LHr16vXMtrS0NHTp0gW6uro4evQobt26he+++w4WFhaqfZ6uNT4+HmvXroVMJsObb76p2mf37t0YM2YMJkyYgL///htnz57FyJEjVduzs7PRp08f1K9fH+fPn8eZM2dgYmICHx8ftYUIZ86ciV9++QXffvstwsLCcODAAXTo0EGtZj8/PwQGBmLNmjUIDw/H1q1b4erqqtq+Z88etXpv3LgBbW1tteP72N69e/HXX3/B3t5ebfzBgwfw9vaGs7Mzzp8/j2PHjuHmzZsYP378M88xceJEDBs2rNRjf+7cObRs2RK7d+/GtWvXMGHCBIwdOxaHDh1S7bNlyxbMnj0bAQEBCA0NxZo1a7B9+3bMnTu31OckqmpXwpIxY9EpTP71EgqKFdIVIl4BALF3794X7tOkSROxaNEitbHDhw8LACI3N7fUxwQEBAgAz3xkZGQ8s29eXp64deuWyMvLE0IIoVQqRU5BkSQfSqWyXMdv6dKlwsLCQjx48EDs27dP6OrqipCQENX24OBgAUAsXbq01Mc//Xrr1q0TZmZmatsVCoXQ1dUVO3bsUI09fPhQjBkzRpibmwsDAwPRp08fERERofa4Xbt2iaZNmwo9PT3RoEED8e2336ptX7ZsmXB2dhZyuVzY2NiIN998UwghxLhx4575nkVHR5fpWERGRooBAwYIGxsbYWRkJNq1ayeOHz+utk9pP29mZmZi3bp1qs/v3bsnhg8fLiwsLIShoaFo27at+Ouvv8pUw9OUSqWoW7eu+Oabb1Rj6enpQi6Xi61bt5b5eWbOnCkaN26s+l6lp6cLXV1dsXPnTtU+oaGhAoAIDg5We+zy5ctF9+7dRWBgoAAg0tLSnnn+YcOGiU8//VQEBASIVq1aqW37+OOPRdeuXctcqxBCDBw4UHh5eak+LyoqEg4ODuKXX3557mMuXrwoAIjY2FjV2LVr1wQAcfv2bSGEELdu3RI6OjoiLCzsuc9z9OhRYWZmJlJTU8tc7w8//CBMTExEdna22vj9+/eFg4ODuHHjhmjQoIH44YcfVNtWrVolbGxshEKheG69Tyvt2D5P3759xYQJE1SfT58+Xe14CiGEv7+/6NKly3Of45+/04gqUlGxQlyIThVfHg0VbSbvFVqG/xPQWiDqjt4m/oxIqvDXy8jIeO7799Oq5Tojc+bMgb+/v+rzzMxMODo6lumxeUUKNJ0nTT/Krc99YKhX9kM6Y8YM7N27F2PGjMH169cxb948tGrVSrV969atMDY2xrRp00p9/IsuZ1YoFNi4cSMAoE2bNqrx8ePH4/bt2zhw4ABMTU3x8ccfo2/fvrh16xZ0dXVx+fJl+Pn5Yf78+Rg2bBjOnTuHadOmwdLSEuPHj8elS5fw/vvv49dff0Xnzp3x8OFDnD59GgCwdOlSREREoHnz5vj8888BANbW1mU6FtnZ2ejbty+++OILyOVybNy4Eb6+vggPD0f9+vXL/Bzdu3eHg4MDDhw4gLp16+LKlStQKpUAgNOnT+ONN9544XOsWrUKo0aNQnR0NBISEtRm9czMzODp6Yng4GAMHz78X+spLCzEpk2b4O/vr/peXb58GUVFRWrP6+bmhvr16yM4OBgdO3YEANy6dQuff/45zp8/j6ioqFKff926dYiKisKmTZvwv//975ntBw4cgI+PD9566y2cOnUKDg4OmDZtGt55551Sny8xMRGHDx/Ghg0bVGNXrlxBXFwctLS00Lp1ayQkJMDDwwPffPMNmjdvDgBwdXWFpaUl1qxZg7lz50KhUGDNmjVwd3eHk5MTAODgwYNo1KgRDh06hD59+kAIAW9vb3z99deoU6eOqt527drh66+/xq+//gojIyMMGDAACxcufO4aQmvWrMHw4cNhZGSkGlMqlRgzZgz++9//olmzZs88pqCgAHp6emqX0D5+/jNnzsDZ2bnU1yqLjIwMuLu7qz7v3LkzNm3ahAsXLqBDhw6IiorCkSNHMGbMmJd+DaLySs8txKmIZASFJeFURDLSc0tmLJNPxUKZWwwAMAxJRSMroxc9TaWq9DBSt27dZ86HJyYmwtTU9Lm/YORyOeRyeWWXJjmZTIYVK1bA3d0dLVq0wOzZs9W2R0REoFGjRtDRefJt+v777zFv3jzV53FxcTAzMwNQ8ovQ2NgYAJCXlwddXV38/PPPaNy4MQCoQsjZs2fRuXNnAMDmzZvh6OiIffv24a233sL333+PXr164bPPPgMAuLi44NatW/jmm28wfvx4xMbGwsjICP3794eJiQkaNGiA1q1bAyh5s9bT04OhoSHq1q1brmPRqlUrtSC2cOFC7N27FwcOHMB7771XpufYsmULkpOTcfHiRdUb3NNvLO3atUNISMgLn8PW1hYAkJCQoPb509sfb/s3+/btQ3p6utr0f0JCAvT09GBubv7c5y0oKMCIESPwzTffoH79+qWGkdu3b2P27Nk4ffq02s/H06KiorBixQr4+/tj7ty5uHjxIt5//33o6elh3Lhxz+y/YcMGmJiYqJ0yevza8+fPx/fffw8nJyd899136NGjByIiIlCnTh2YmJjg5MmTGDRoEBYuXAgAaNKkCX777TdVbVFRUYiJicHOnTuxceNGKBQKzJo1C0OHDkVQUJBqnzNnzkBfXx979+5FSkoKpk2bhtTUVKxbt+6Zei9cuIAbN25gzZo1auNfffUVdHR08P7775d6XLy8vODv749vvvkGM2fORE5Ojur/Xnx8fKmPKYsdO3bg4sWLWLVqlWps5MiRSElJQdeuXSGEQHFxMaZMmcLTNFSphBCISMxGUFgSToQl4VLMQyifuluKmYEuurtYo2O/pvhk3AG4u1lh48bBsLIwlKzmSg8jnTp1wpEjR9TGjh8/jk6dOlXK6xnoauPW5z6V8txlee3yWrt2LQwNDREdHY379++r/pJ8nokTJ2LAgAE4f/48Ro8erXY/HhMTE1y5cgUAkJubiz/++ANTpkyBpaUlfH19ERoaCh0dHXh6eqoeY2lpCVdXV4SGhgIAQkNDMXDgQLXX7NKlC5YsWQKFQoHevXujQYMGaNSoEfr06YM+ffpg8ODBMDR8tR/i7OxszJ8/H4cPH0Z8fDyKi4uRl5eH2NjYMj9HSEgIWrdurQoi/2RgYPBKf/WW15o1a/DGG28807Pwb+bMmQN3d3eMHj261O0KhQIjR47EggUL4OLi8tznUSqVaNeuHRYtWgQAaN26NW7cuIGVK1eWGkbWrl2LUaNGqa36+XhW6ZNPPlH1kaxbtw716tXDzp07MXnyZOTl5WHSpEno0qULtm7dCoVCgW+//Rb9+vXDxYsXYWBgAKVSiYKCAmzcuFFV85o1a9C2bVuEh4fD1dUVSqUSMpkMmzdvVgXs77//HkOHDsXy5cuf+eNlzZo1aNGihVrfyeXLl7F06VJcuXLluTOHzZo1w4YNG+Dv7485c+ZAW1sb77//PmxtbV96wbETJ05gwoQJWL16tdpszMmTJ7Fo0SIsX74cnp6eiIyMxMyZM7Fw4UJV4CeqCPlFCgRHpSIoNAlBYUmIS89T2+5ia4yODubo394RbeqbQ0e75Ge9x5mJqFvXGFpa0i4cWu7/ednZ2QgJCVH9hRkdHY2QkBDVm8acOXMwduxY1f5TpkxBVFQUPvroI4SFhWH58uXYsWMHZs2aVTFfwT/IZDIY6ulI8lHeVWDPnTuHH374AYcOHUKHDh0wadIktXDRpEkTREVFqTUBmpubw9nZGQ4ODs88n5aWFpydneHs7IyWLVvC398fPXr0wFdfffXyB/QfHgeerVu3ws7OTnVq6XlXepTVf/7zH+zduxeLFi3C6dOnERISghYtWqCwsFC1j0wme+ZmiE8fm3+7HcDp06dhbGz8wo/HDcWPZ3ZKm9Ury6xPTEwM/vjjD7z99ttq43Xr1kVhYeEzx+vp5w0KCsLOnTuho6MDHR0dVXOqlZUVAgICkJWVhUuXLuG9995T7fP555/j77//ho6Ojmqmwc7ODk2bNlV7HXd391ID3unTpxEeHv5MvXZ2dgCg9jxyuRyNGjVSPc+WLVtw9+5drFu3Du3bt0fHjh2xZcsWREdHY//+/arn0dHRUQtPj09nPH4eOzs7ODg4qILI432EELh//75aXTk5Odi2bRsmTZr0zNeRlJSE+vXrq45NTEwMPvzwQ7WgP3LkSCQkJCAuLg6pqamYP38+kpOT0ahRo2eOzb85deoUfH198cMPP6j97gOAzz77DGPGjMHbb7+NFi1aYPDgwVi0aBEWL16sCnpELys+Iw+bz8fg7Q0X4fH575iw7iJ+/SsGcel50NPRQg9Xaywc2AxBs16DR3whVkz/Hfa6OqogAgD29iaSBxHgJWZGLl26hJ49e6o+f9zbMW7cOKxfvx7x8fFqv+waNmyIw4cPY9asWVi6dCnq1auHX375BT4+0sxeVBe5ubkYP348pk6dip49e6Jhw4Zo0aIFVq5cialTpwIARowYgR9//BHLly/HzJkzX+p1tLW1kZdXkpDd3d1RXFyM8+fPq07TpKamIjw8XPVm4+7ujrNnz6o9x9mzZ+Hi4gJt7ZKZHx0dHXh7e8Pb2xsBAQEwNzdHUFAQhgwZAj09PSgU5e/IPnv2LMaPH6+6ZDw7Oxt3795V28fa2lptGv327dvIzc1Vfd6yZUv88ssvePjwYamzI+U5TdOwYUPUrVsXgYGBqss6MzMzcf78edX350XWrVsHGxubZy45bdu2LXR1dREYGKiaaQgPD0dsbKxqtnD37t2q7xlQcoXOxIkTcfr0aTRu3Bimpqa4fv262vMuX74cQUFB2LVrFxo2bAigZEbrn1dSRUREoEGDBs/U+3iW4ulTZY/rlcvlCA8PR9euXQGUBMC7d++qnic3NxdaWlpqYfzx54/fcLt06YLi4mLcuXNHddowIiICAFTP06VLF+zcuRPZ2dmq040RERHQ0tJCvXr11OrauXMnCgoKnpk9GjNmTKlX7z2+GuifHn+/165dC319ffTu3fuZfV7k5MmT6N+/P7766iu8++67z2x/fGye9vj/0T+DNdG/USgFQu6l40RYEgLDkhAar36laV1TfXi528DL1QadnS1hqKeDmJh0DB+0A3/9VRLohw/fhZMnx0NHp5otwF7hrbOV4EXduJraef7+++8LZ2dnkZOToxpbuXKlMDY2VrsC5cMPPxTa2tpi1qxZ4vTp0+Lu3bsiODhYjB49WshkMtUxWbdunTA1NRXx8fEiPj5eREVFiVWrVgltbW2xYMEC1fMNHDhQNG3aVJw+fVqEhISIPn36CGdnZ1FYWCiEEOLy5ctCS0tLfP755yI8PFysX79eGBgYqK5YOXjwoFi6dKm4evWquHv3rli+fLnQ0tISN27cEEII8c4774j27duL6OhokZycrHbFwosMHjxYeHh4iKtXr4qQkBDh6+srTExMxMyZM1X7DB8+XLi7u4srV66IixcvCi8vL6Grq6uqraCgQLi4uIhu3bqJM2fOiDt37ohdu3aJc+fOlffbI4QQ4ssvvxTm5uZi//794tq1a2LgwIGiYcOGaj9rXl5e4scff1R7nEKhEPXr1xcff/xxqc87ZcoUUb9+fREUFCQuXbokOnXqJDp16vTcOk6cOPHcq2keK+2KjwsXLggdHR3xxRdfiNu3b4vNmzcLQ0NDsWnTJrX9MjIyhKGhoVixYkWpzz1z5kzh4OAgfvvtNxEWFiYmTZokbGxsxMOHD4UQJVcDyeVyMXXqVHHr1i1x48YNMXr0aGFmZiYePHigOiZt2rQRr732mrhy5Yq4dOmS8PT0FL1791a9TlZWlqhXr54YOnSouHnzpjh16pRo0qSJePvtt5+pqWvXrmLYsGHPPR5P++fVNEII8eOPP4rLly+L8PBw8dNPPwkDA4Nnrlq7ffu2uHr1qpg8ebJwcXERV69eFVevXhUFBQVCCCGCgoKEoaGhmDNnjur/XXx8vNrVQAEBAcLExERs3bpVREVFid9//100btxY+Pn5PbdeTf2dRpUjPbdQHPw7TszadlW0/vx30eDjQ6oPp9mHxOBlZ8SPgRHiZlzGM1d07tsXKiwsvhTAfAHMF7q6n4sffggu95Wfr6KsV9MwjEjg5MmTQltbW5w+ffqZba+//rrw8vJS+2HZvn276NGjhzAzMxO6urqiXr16YuTIkWqXrK5bt07tklq5XC5cXFzEF198IYqLi1X7Pb6018zMTBgYGAgfH5/nXtqrq6sr6tevr3Z56+nTp0X37t2FhYWFMDAwEC1bthTbt29XbQ8PDxcdO3YUBgYGapf2NmjQQAQEBDz3mERHR4uePXsKAwMD4ejoKH766SfRvXt3tTASFxcnXn/9dWFkZCSaNGkijhw58sylvXfv3hVvvvmmMDU1FYaGhqJdu3bi/Pnzz33dF1EqleKzzz4Ttra2Qi6Xi169eonw8HC1fUr7un777TcB4Jl9H8vLyxPTpk1TXX48ePBgER8f/9w6XjaMCFESHps3by7kcrlwc3MTP//88zP7rFq1ShgYGIj09PRSn7uwsFB8+OGHwsbGRpiYmAhvb29V+Hzs999/F126dBFmZmbCwsJCeHl5PXOpclxcnBgyZIgwNjYWtra2Yvz48c9cxhsaGiq8vb2FgYGBqFevnvD3939mCYCwsDABQPz+++/PPR5PKy2MjBkzRtSpU0fo6emJli1bio0bNz7zuO7du5e6xMDjn+nSLmUHILp37656jqKiIjF//nzRuHFjoa+vLxwdHcW0adNe+L3UxN9pVHGUSqW4nZgpVp2KFMNWnRON5hxWCyDNA46J6Zsvi92X74mUrPxSn6OgoFh88MFRVQgB5gsnpyXiwoX7VfzVlD2MyISo/nOFmZmZMDMzQ0ZGBkxNTdW25efnIzo6Gg0bNuTttqup3NxcWFpa4ujRo+jRo4fU5RBVa/ydVvsUFCtwPuohgsJKmk9jH+aqbXe2MYaXmw283GzQtoEFdLWff4olOjoNw4btwsWLD1RjQ4a4Y82aATA3r/qfpxe9fz+tWq4zQjXLiRMn4OXlxSBCRPRIYmY+TjwKH2ciU5Bb+KTXTk9bC56N6qCXmw283GxR37JsVyvu3x+GceP2ISOjoOR59LTx/fevY9q09uW+wKKqMYxQpevXr99z7x1CRFQbKJUC1+IyHs1+JOJGnHrzqY2JHF5uNujpZoOuzlYwkpf/7VmhEKog0rixBXbseAtt2thVSP2VjWGEiIioEmTlF+H07RQEhSXhZHgSUrKfXqoAaFnPHF6uNujlboOmdqavfIntkCHueO+99khOzsXPP/vC1FRzFg9lGCEiIqogUcnZqt6Pi3cfokjxpC3TWK6D11ys0NPVBj1cbWBt8mphITj4Hjp2rKd2CuaHH/pAW1tW7U/L/FONCSMa0IdLRPSv+LtMsxQWK3Hx7kMEhibhRHgSolNy1LY3sjJCTzcb9HKzQTunOtCrgPU98vKK8MEHx/Dzz1ewdu0ATJjQWrWt2q0fUkYaH0YeLyBUWFj4rytwEhFVd48X8tPV1ZW4Enqe5KwCnAgvue/L6dspyC4oVm3T1ZahQ8M68HKzhZebDRpW8M3nwsJS4Oe3E9evJwEApk8/Am/vRnB0NPuXR1ZvGh9GdHR0YGhoiOTkZOjq6r70vSWIiKQkhEBubi6SkpJgbm6u+kOLpKdUCtx8kKlqPv37fobaditjPfR0Lbn0tmsTK5joV06Q/PXXvzF16mHk5JTcBsPAQAc//dQX9eo9/5JZTaHxYUQmk8HOzg7R0dGIiYmRuhwioldibm5e7rteU8XLLijGmdspOBFWcvolKatAbXsLBzPV6ZcWDmaVen+X3NwivPfeEaxbF6Iaa9rUGjt2DEWzZjaV9rpVSePDCADo6emhSZMmajdVIyLSNLq6upwRkVBMao6q+fR81EMUKp7czNBQTxvdmliVXH7ragMb06pZQOzmzST4+e3CrVvJqrEJEzzw449vwMhIr0pqqAo1IowAJTfm4mqFRERUVkUKJS7dTUNQWCKCwpJwJ1m9+bR+HUN4uZVcetuhYR3Idao2KP7++x0MGrQNeXklPSlGRrpYsaIfxoxp9S+P1Dw1JowQERH9m9TsApwMT0ZQeBL+jEhGVv6T5lMdLRnaOVmgl5sterrZoLG1kaSXyLZuXRcWFgbIy8tCixY22LHjLbi5WUlWT2ViGCEiohpLCIFb8Zk4EZaEwLAkhNxLx9NXT9cx0kMPV2t4udmgWxNrmBlUn6uYrK2NsG3bm9i8+Tp++MEHBtWotorGMEJERDVKbmExzkamIiis5PLbhMx8te1N7UzRy71k6fVW9cyhXYnNp2UlhMD69SHo188FNjZPLgfu1q0BunVrIGFlVYNhhIiINN69h7k4EZ6EwNAkBEelorD4SfOpga42ujg/aj51s4adWfVakyozswDvvnsQ27ffxOuvN8bRo6Mq9eqc6ohhhIiINE6xQokrsekIDEvEibAkRCRmq22vZ2EAL7eStT86NrKEvm71vErpypV4DBu2C5GRDwGUNK0eP34HPj7OEldWtRhGiIhII6TlFOJURDKCwpJwKiIZGXlFqm3aWjK0rW8BL/eSANLExrha359FCIFlyy7iww9/R2GhAgBgairHmjUDal0QARhGiIiomhJCIDwxq2Ttj9AkXIlNg/Kp5lNzQ130cLGGl7stujexhpmhZjR4pqfnY9KkA9izJ1Q11q6dPbZvH4pGjSwkrEw6DCNERFRt5BcpcO5OyqPm02TEpeepbXera6I6/dK6vkW1aD4tjwsX4jBs2C7cvZuuGvvgA0989VVv6OlVz1NJVYFhhIiIJPUgPU+18um5OynIL3rSfCrX0UIXZyv0fBRAHMyrV/NpeYSFpaBr17UoevT1mZvrY/36gRg40E3iyqTHMEJERFVKoRS4GpumCiBhCVlq2+3N9FW9H50aWcGghswYuLlZYeTIFtiw4W907FgP27a9iQYNzKUuq1pgGCEiokqXkVuEU7eTERSaiFMRyUjLfdJ8qiUD2tS3KLnxnLsNXG1NqnXz6atYtqwvmja1xqxZHaFbTa/wkQLDCBERVTghBCKTshH4aPbjckwaFE91n5rq66C7a8ldb7u7WMOiBt30DQCUSoHvvjuHhg0tMHRoU9W4kZEePvqoi4SVVU8MI0REVCHyixT4KypVtfT6/TT15tMmNsYlp19cbdC2gQV0tLUkqrRypaTkYty4fThy5DZMTeVo08au1l4lU1YMI0RE9NISMvJVK5+ejUxBXpFCtU1PRwudGlmqrn5xrGMoYaVV4/TpGIwYsRtxcSV9MJmZBTh+/A4mT24ncWXVG8MIERGVmUIp8Pf9dJx4dPrl5oNMte22pnJ4udnCy80GXZwtYahXO95mlEqBxYtPY968k1A+Oh1lbW2IX38dXCsXMSuv2vFTQkRELy0zvwinI1IQGJaIU+HJSM0pVG2TyQAPR3N4udrAy90GTe1Ma2zz6fMkJmZjzJi9OH48SjXWo4cTNm8eAnt7Ewkr0xwMI0REpEYIgaiUHASFlsx+XLz7EMVPNZ+ayHXwmos1vNxs0MPVGpbGcgmrlVZQUDRGjdqDhISSe+PIZMC8ed3x2WevQbuG9sRUBoYRIiJCQbECF6Ifqtb+iEnNVdve2Nro0V1vbdDeqQ50+UaL3NwijBy5G4mJOQCAunWNsXnzEHh5NZS4Ms3DMEJEVEslZeXjZFgyAsMSceZ2CnIKn2o+1daCZ6M6qubTBpZGElZaPRka6mLduoHo23cLvL0bYdOmwbC1NZa6LI3EMEJEVEsolQLX4zJK7vsSnoRr9zPUtlubyOHlWjL70bWJFYzlfIv4J6VSQOup++G88UYTBAaORffuDXha5hXwJ42IqAbLLijGmdvJCAxNwonwZKRkF6htb1XPrGTlUzdbNLM3VXujpSeKi5WYP/8kwsNTsWPHULUmXZ6WeXUMI0RENczdlBwEhiXhRFgSzkenokjxpPnUSE8b3ZpYw8u9pPnUxkRfwko1w/37mRg5cjdOn44FACxbdhHvvddB4qpqFoYRIiINV1isxKW7T5pPo1Jy1LY7WRqq1v7o0LAO9HR4OqGsjh69jTFj9iI1tWQ1WW1tGYqeWtiNKgbDCBGRBkrJLsCJR70fpyNSkFVQrNqmoyVDh4ZPmk8bWbOpsryKihT49NMgfP31OdWYo6Mptm0bis6dHSWsrGZiGCEi0gBCCNx8kImgR/d9uXY/HeLJ2RdYGeuhh2tJ+OjaxAqm+rrSFavhYmMzMHz4LgQH31eN+fq6YP36QahTx0DCymouhhEiomoqp6AYZyNTVFe/JGaqN582dzB9tPKpLVo6mLH5tAIcOBCO8eP3IS0tHwCgo6OFr7/2xgcfdKx1K8tWJYYRIqJqJDY1F0FhiQgKT8Zfd1JRqFCqthnqaaOLsxV6PVp8zNaUzacV7ddfr6mCiJOTObZvH4oOHRwkrqrmYxghIpJQkUKJyzFpOPHo9EtkUrbadsc6Buj1qPnUs1EdyHW0Jaq0dli92heXLj1A69Z1sXbtQJibM/BVBYYRIqIq9jCnECfDS658ORWRjKz8J82n2loytGtggV7uJf0fja2NeXqgEqWk5MLKylD1ubm5PoKDJ8HW1ojHvQoxjBARVTIhBELjs3AiPAmBoYm4ek+9+dTCUBc9H618+pqLNcwM2Hxa2QoKivGf//yObdtuIiRkMhwcTFXb6tbl1UdVjWGEiKgS5BUqSppPw0sWH4vPyFfb7m5nqur98HA0hzabT6tMZORDDBu2C1euxAMARo7cg6CgsVzOXUIMI0REFeR+Wq6q9yP4TioKip80n+rraqGrsxV6utmgp6sN7M15iagUtm+/gXfeOYisrEIAgFyujVGjWvBKJIkxjBARvaRihRJX76WX3PclLAnhiVlq2x3MDUoWHnO3QadGltDXZfOpVPLyijBr1m9YteqyaszFxRI7d76Fli1tJayMAIYRIqJySc8txKmIZASFJeFkeDIy8opU27RkQNsGFqql111s2XxaHYSHp8DPbxeuXUtUjY0e3RIrVvSDsbGehJXRYwwjREQvIIRARGL2o/u+JOJyTBqUTzWfmhnoooerNbzcbNDdxRrmhnxzq062b7+BSZMOICenJDQaGOjgp5/6YsIEDwbFaoRhhIjoH/KLFAi+k6q68Vxcep7adldbE3g9uvS2taM5dNj4WG1paclUQcTd3Qo7d76FZs1sJK6K/olhhIgIQHxGXkn4CE3C2TspyC960nwq19FC58aW8Hp09Us9C8MXPBNVJ2+91QxTp95FXl4xfvrpDRgZceaqOmIYIaJaSaEUCLmXXrL0elgyQuMz1bbbmemjp5sNernZoHNjKxjosfm0uhNC4MyZWHTr1kBt/Mcf3+Blu9UcwwgR1RoZeUX4MyIZJ8KScDIiGQ9zClXbZDKgTX2LktkPVxu425mwp0CDZGcXYtq0w/j112vYuHEQxoxppdrGIFL9MYwQUY0lhMCd5JLm08DQJFyKSYPiqe5TE30ddHexRi93G3R3sUEdTuFrpGvXEuHntxPh4akAgKlTD6N378ZcSVWDMIwQUY2SX6TA+eiHOPGo+TT2Ya7admcbY9XKp20bWECXfzVrLCEEVq++gpkzjyH/0f19jI31sHq1L4OIhmEYISKNl5iZr1r59GxkCnILFaptetpa6NjYEl6u1vBys0V9Szaf1gSZmQWYPPkQtm27oRpr3boutm8fiiZNLCWsjF4GwwgRaRylUuBaXAaCQhMRFJ6EG3Hqzac2JvKSlU/dbNDF2QpGcv6qq0muXo2Hn98uREY+VI1Nn94e3377OvT1+b3WRPyuEZFGyMovwunbKY9WPk1CSrZ682mreuaqANLM3pTNpzXUoUMRePPNHSh8NPtlairHmjUDMHRoU4kro1fBMEJE1VZUcrZq4bEL0Q9R/HTzqVwH3Vys4OVmix6u1rAylktYKVWVDh0cYGlpgPj4bLRta4ft24eiceM6UpdFr+ilwsiyZcvwzTffICEhAa1atcKPP/6IDh06PHf/JUuWYMWKFYiNjYWVlRWGDh2KxYsXQ19f/6ULJ6Kap7BYiQvRDxEUloQT4UmITslR297Iykg1+9HOqQ70dNh8WtvY2Bhhy5Y3sW9fGL76yhtynoKrEcr9Xdy+fTv8/f2xcuVKeHp6YsmSJfDx8UF4eDhsbJ5dYnfLli2YPXs21q5di86dOyMiIgLjx4+HTCbD999/XyFfBBFpruSsApwIL1n59ExkCrILilXbdLVl8GxoiZ6PAkhDKyMJK6WqJoTAqlWXMXRoU1hZPWk87tHDCT16OElXGFU4mRBC/PtuT3h6eqJ9+/b46aefAABKpRKOjo6YMWMGZs+e/cz+7733HkJDQxEYGKga+/DDD3H+/HmcOXOmTK+ZmZkJMzMzZGRkwNTUtDzlElE1o1QK3HyQicCwRJwIS8Lf9zPUtlsZy9HTtWTtj65NrGHMv3xrpYcP8zBx4n7s3x+Ovn2b4ODBEdDSYh+Qpinr+3e5/pcXFhbi8uXLmDNnjmpMS0sL3t7eCA4OLvUxnTt3xqZNm3DhwgV06NABUVFROHLkCMaMGfPc1ykoKEBBQYHaF0NEmiu7oBhnbqeUrP0RnoTkrAK17S3rmaGna8nsRwsHM77p1HJ//XUfw4btQmxsSVA9cuQ2/vwzhrMhNVi5wkhKSgoUCgVsbW3Vxm1tbREWFlbqY0aOHImUlBR07doVQggUFxdjypQpmDt37nNfZ/HixViwYEF5SiOiaiYmNQeBoSW9H+ejHqJQ8eTGc0Z62ujaxAq9HjWf2piyf4xKZs2+++4c5s4NQnFxyc+LpaUBNmwYxCBSw1X6/OfJkyexaNEiLF++HJ6enoiMjMTMmTOxcOFCfPbZZ6U+Zs6cOfD391d9npmZCUdHx8oulYheQZFCiYt3H6oWH4tKVm8+bWBpqGo+7dCwDuQ6vPEcPZGSkovx4/fh8OHbqrGuXetj69Y3Ua8eT8/XdOUKI1ZWVtDW1kZiYqLaeGJiIurWrVvqYz777DOMGTMGb7/9NgCgRYsWyMnJwbvvvotPPvkEWlrPdsPL5XLI5bxMj6i6S80uwMnwZASFJeHPiGRkPdV8qqMlQ3unOujlXrL0eiMrI679QaU6cyYWw4fvQlxclmpszpyu+PzzntDhFVO1QrnCiJ6eHtq2bYvAwEAMGjQIQEkDa2BgIN57771SH5Obm/tM4NDWLvmLqJy9s0QkMSFKmk8f936E3EvH0/+NLY300ONR70c3FyuY6utKVyxphOvXE9Gjx3ooFCU/SNbWhvj118Hw8XGWuDKqSuU+TePv749x48ahXbt26NChA5YsWYKcnBxMmDABADB27Fg4ODhg8eLFAABfX198//33aN26teo0zWeffQZfX19VKCGi6iu3sBhnI1MRFJaIE2HJSMjMV9vezN5UdfqlVT1zNp9SuTRvboMRI1pg06Zr6NHDCZs3D4G9vYnUZVEVK3cYGTZsGJKTkzFv3jwkJCTAw8MDx44dUzW1xsbGqs2EfPrpp5DJZPj0008RFxcHa2tr+Pr64osvvqi4r4KIKtS9h7mqlU+Do1JRWPyk+dRAVxtdnK1KTr+42qCuGZtP6eXJZDIsX94XbdrUxfvve0Kbd1Gulcq9zogUuM4IUeUqVihxOSYNQY8WH7udlK22vZ6FAXq5lfR+dGxkCX1dzmpS+SkUSnzxxWm0aGGDwYPdpS6HqkClrDNCRDVHWk4hTkUkIzAsCafCk5CZ/6T5VFtLhrYNLNDr0ekXZxtjNp/SK0lIyMaoUXsQFBQNc3N9tG5tBycnc6nLomqCYYSolhBCICwhq+S+L2FJuBKbhqfuOwdzQ130dC2Z/ejexBpmhmw+pYrxxx9RGDVqD5KSSi73zswswJ9/xjCMkArDCFENll+kwLk7KSWLj4Ul4UGGevOpW10TeLnZoJe7DTwcLaDN5lOqQMXFSsyffxKLFp1WXXVlb2+CrVvfxGuvNZC2OKpWGEaIapi49DzV7MfZyBQUPNV8KtfRQldnK/R81P/hYG4gYaVUk8XFZWLEiN04fTpWNdanjzM2bhwEa2ve8JDUMYwQaTiFUuBqbJrq6pewhCy17Q7mBujpZo1ebrbo1JjNp1T5jh69jbFj9yElJRcAoK0tw6JFvfCf/3Tmpd9UKoYRIg2UkVuEkxElsx+nIpKRlluk2qYlA9rUt4CXe0nzqautCZtPqcpkZRWoBRFHR1Ns2zYUnTvzlh70fAwjRBpACIHbSdklsx+hSbgcmwbFU92npvo6qpVPu7tYw8JIT8JqqTYzMZFj3bqB8PXdCl9fF6xbNxCWloZSl0XVHMMIUTWVX6TAX1GpqtMv99Py1La72Bqjp5sNernZok19c+hwsSiSiFIp1E6/9O/vglOnxqNbt/qclaMyYRghqkYSMvJV4eNsZAryihSqbXo6Wujc2BJebiUrnzrW4V+bJK3CQgXmzPkDcXFZ2Lr1TbXgwatlqDwYRogkpFAK/H0/HSfCkhAYmoRb8Zlq2+ua6j+a/bBBZ2dLGOrxvyxVD9HRaRg+fDcuXIgDAPTo4YQpU9pJXBVpKv5mI6pimflF+DMiGUFhSTgVnozUnELVNpkM8HA0Vy293tTOlNPcVO3s2ROKiRP3IyOjAACgp8crtOjVMIwQVTIhBO4k55TMfoQl4tLdNBQ/1XxqItfBa67W8HK1QQ9Xa1gayyWsluj5CgqK8Z///I6ffrqoGmvc2ALbtw9F27b2ElZGmo5hhKgSFBQrcCH6YcnKp+FJiEnNVdve2NoIXm428HKzRTsnC+iy+ZSqucjIhxg2bBeuXIlXjfn5NcPPP/eHGe/cTK+IYYSogiRl5uNEeEnz6ZnbKcgpfKr5VFsLno3qPAogNmhgyRUoSXPs2HETb799AFlZJacU5XJtLF3aB+++25anEalCMIwQvaIDfz/A6j+jcD0uQ23c2kQOL1cbeLnboKuzFYzk/O9GmkcIgS1brquCiIuLJXbsGIpWrepKXBnVJPztSPQKbj7IwAfbrqruftuqnhm83Gzh5WaDZvamXPqaNJ5MJsPatQPRuvUqdOtWHytW9IOJCfuaqGIxjBC9JCEEAvbfhFIA3u62WDSkOWxMeO6cNF9iYjZsbY1Vn9epY4CLF9+BtbUhT8tQpWDXHNFL2hcSh0sxaTDQ1cbCQc0YREjj5eYW4e23D6Bly5WIj1e/4aKNjRGDCFUahhGil5CVX4RFR8IAADN6OcPOzEDiioheza1byejQYTXWrLmKpKQcjBq1B8qnLkEnqkw8TUP0En4MikRyVgEaWhlhUteGUpdD9ErWrw/B9OlHkPvo7s+GhroYP96DPU9UZRhGiMopMikLa89EAwDm+TaFXIerT5Jmys4uxPTpR7Bx49+qsebNbbBz51twc7OSsDKqbRhGiMpBCIH5B26hWCng7W6Lnq42UpdE9FKuX0+En98uhIWlqMbeeacNli7tAwMDXQkro9qIYYSoHH67mYAzkSnQ09HCvP5NpS6H6KVs2BCCKVMOIz+/GABgbKyHn3/ujxEjWkhcGdVWDCNEZZRXqMDCQ6EAgCmvNUJ9S0OJKyJ6OXK5jiqIeHjUxfbtQ+HiYilxVVSbMYwQldGKk5GIS8+Dg7kBpvZwlrocopc2fHhznDgRDR0dLXz3nQ/09flWQNLiTyBRGcSm5mLln1EAgM/6u8OAt0wnDSGEwMmTd9Gzp/pVXytW9OfVMlRtcJ0RojL4/NAtFBYr0dXZCj7NeE8O0gwZGfnw89sFL6+N2LLluto2BhGqThhGiP7FibAk/BGaCB0tGeYPaMpVKEkjXLr0AG3a/Ixdu24BACZPPoSUlFyJqyIqHcMI0QsUFCuw4OBNAMDErg3hbGMicUVELyaEwNKlf6Fz5zWIikoDAJib6+PXXwfDyopN11Q9sWeE6AXWnInG3dRcWJvIMcOLTatUvaWl5WHixAPYty9MNebp6YBt24bCyclcusKI/gXDCNFzxGfk4cfASADA3L5uMNHnQlBUff31130MH74LMTEZqrH//KcTFi3qBV1dNlxT9cYwQvQcXxwORV6RAu2dLDDIw0Hqcoiea/fuWxg+fDeKi5UAgDp1DLBx4yD06+cicWVEZcOeEaJSBN9JxaFr8dCSAfMHNGPTKlVrXbrUh6WlwaN/OyIkZDKDCGkUzowQ/UORQon5B0qaVkd5NkAzezOJKyJ6sbp1jbF58xAEBkbj8897QkeHf2eSZuFPLNE//Bocg/DELFgY6uLD1/nXJVUvSqXA//3feaSmql+m26tXIyxa1ItBhDQSf2qJnpKcVYAfjkcAAD7q4wZzQz2JKyJ6IikpB337bsbMmccwYcJ+CCGkLomoQjCMED3l62NhyCooRgsHM/i1c5S6HCKVU6fuwsNjJX777Q4A4NChCAQH35e4KqKKwTBC9MiV2DTsvFzyy33BwGbQ5nLZVA0oFEp8/vkpeHltRHx8NgDA1tYIx4+PQefODMxUM7CBlQiAQikQsL+kafWttvXQpr6FxBURAQkJ2Rg9eg8CA6NVY716NcSmTUNQt66xhJURVSyGESIAOy7dw/W4DJjIdfBRHzepyyFCYGAURo3ag8TEHAAlN7abP7875s7tBm1tTmpTzcIwQrVeem4hvj5Wsnz2rN4usDaRS1wR1XaXLz9A796/4nF/qr29CbZsGYLu3Z0krYuosjBeU6333e8RSMstgqutCcZ2aiB1OURo08YOw4Y1BwD06eOMkJDJDCJUo3FmhGq1mw8ysPl8DICSlVZ1OP1N1YBMJsOqVf3RrVt9TJnSDlpspqYajr95qdYSoqRpVSmA/i3t0KmxpdQlUS1UXKzEnDl/4MCBcLVxU1M5pk1rzyBCtQJnRqjW2hcSh0sxaTDQ1cYn/dylLodqoXv3MjBixG6cPXsPFhb6uHp1Mho0MJe6LKIqx5kRqpWy8ouw6EhJ0+qMXs6wMzOQuCKqbQ4dioCHxyqcPXsPAJCVVchFzKjW4swI1Uo/BkUiOasADa2MMKlrQ6nLoVqksFCBuXMD8d13waqxBg3MsG3bUHTsWE/CyoikwzBCtU5kUhbWnilZRGqeb1PIdbQlrohqi7t30zF8+C6cPx+nGhs0yA1r1w6AhQVn56j2YhihWkUIgfkHbqFYKeDtbouerjZSl0S1xL59YZgwYT/S0/MBALq6Wvj229cxY0YHyGRsUqXajWGEapXfbibgTGQK9HS0MK9/U6nLoVoiPT0fEyc+CSKNGllg+/ahaNfOXuLKiKoHNrBSrZFXqMDCQ6EAgCmvNUJ9S0OJK6LawtxcH+vWDQQAvPVWU1y58i6DCNFTODNCtcaKk5GIS8+Dg7kBpvZwlrocquEUCqXaPWQGDnTDmTMT0LmzI0/LEP0DZ0aoVohNzcXKP6MAAJ/1d4eBHptWqXLk5xdj2rTDGDt2H8Tjm8s80qVLfQYRolJwZoRqhc8P3UJhsRJdna3g06yu1OVQDRURkQo/v534++9EAEDPnk54++02EldFVP0xjFCNdyIsCX+EJkJHS4b5A5ryL1OqFFu2XMfkyYeQnV0IANDX14GODieficqCYYRqtIJiBRYcvAkAmNi1IZxtTCSuiGqa3NwizJx5FL/8clU15uZmhZ0730Lz5rx0nKgsXiq2L1u2DE5OTtDX14enpycuXLjwwv3T09Mxffp02NnZQS6Xw8XFBUeOHHmpgonKY82ZaNxNzYWNiRwzvNi0ShUrNDQZnp6/qAWRceNa4dKldxhEiMqh3DMj27dvh7+/P1auXAlPT08sWbIEPj4+CA8Ph43Ns//5CgsL0bt3b9jY2GDXrl1wcHBATEwMzM3NK6J+oueKz8jDj4GRAIA5fd1goq8rcUVUk2zYEIJp044gN7cIAGBoqIvly/ti3DgPaQsj0kDlDiPff/893nnnHUyYMAEAsHLlShw+fBhr167F7Nmzn9l/7dq1ePjwIc6dOwdd3ZI3Aycnp1ermqgMvjgcirwiBdo7WWCQh4PU5VANIoTArl2hqiDSvLkNtm8fiqZNrSWujEgzles0TWFhIS5fvgxvb+8nT6ClBW9vbwQHB5f6mAMHDqBTp06YPn06bG1t0bx5cyxatAgKheK5r1NQUIDMzEy1D6LyOHcnBYeuxUNLBswf0IxNq1ShZDIZ1q8fCEdHU7z9dmucP/82gwjRKyjXzEhKSgoUCgVsbW3Vxm1tbREWFlbqY6KiohAUFIRRo0bhyJEjiIyMxLRp01BUVISAgIBSH7N48WIsWLCgPKURqRQplFhw4BYAYJRnAzSzN5O4ItJ0QggkJGTDzu5JA7SlpSGuXp0MS67kS/TKKv26M6VSCRsbG/z8889o27Ythg0bhk8++QQrV6587mPmzJmDjIwM1ce9e/cqu0yqQX4NjkF4YhYsDHXx4esuUpdDGi4rqwCjR+9FmzY/IzExW20bgwhRxSjXzIiVlRW0tbWRmJioNp6YmIi6dUtfSMrOzg66urrQ1n6y4qW7uzsSEhJQWFgIPT29Zx4jl8shl8vLUxoRACA5qwA/HI8AAHzUxw3mhs/+fBGVVUhIAvz8duL27YcAgNGj9+L330fztB9RBSvXzIienh7atm2LwMBA1ZhSqURgYCA6depU6mO6dOmCyMhIKJVK1VhERATs7OxKDSJEr+LrY2HIKihGy3pm8GvnKHU5pKGEEFix4iI6dvxFFURMTeV45502DCJElaDcp2n8/f2xevVqbNiwAaGhoZg6dSpycnJUV9eMHTsWc+bMUe0/depUPHz4EDNnzkRERAQOHz6MRYsWYfr06RX3VRABuBKbhp2X7wMAFgxoBm0tvmlQ+WVk5GP48N2YNu0ICgpKGu3btrXDlSvvws+vmcTVEdVM5b60d9iwYUhOTsa8efOQkJAADw8PHDt2TNXUGhsbCy2tJxnH0dERv/32G2bNmoWWLVvCwcEBM2fOxMcff1xxXwXVegqlQMD+kpVW32pbD63rW0hcEWmiy5cfwM9vF6Ki0lRj77/fAV9/3RtyOResJqosMvHP20pWQ5mZmTAzM0NGRgZMTU2lLoeqoS3nYzF373WY6Osg6MMesDZhzxGVz88/X8aMGUdRWFgyG2Juro+1awdg8GB3iSsj0lxlff9m1CeNl55biG9+K7m0fJa3C4MIvRQjI11VEOnQwQHbtw+Fk5O5tEUR1RIMI6Txvvs9Amm5RXC1NcHYTg2kLoc01KhRLXHy5F2Ymelj0aJe0NPT/vcHEVGFYBghjXbzQQY2n48BULLSqo42b9lO/04IgT/+iELv3o3Vxlet8oUWG5+Jqhx/c5PGEqKkaVUpgP4t7dCpsaXUJZEGSE3NxYAB2/D665uwY8dNtW0MIkTSYBghjbUvJA6XYtJgoKuNT/qxyZD+3dmzsWjdehUOHSpZGO/ddw8iPT1f4qqIiGGENFJWfhEWHSlpWp3Ryxl2ZgYSV0TVmVIp8OWXZ9C9+3rcu1dy400rK0Ns2zYU5ub6EldHROwZIY30f4G3kZxVgIZWRpjUtaHU5VA1lpycg7Fj9+HYsUjV2GuvNcCWLUPg4MClAoiqA4YR0jiRSVlYd/YuAGCeb1PIdXjVA5Xuzz9jMGLEbjx4kAUAkMmATz99DfPmdYeODieGiaoLhhHSKEIIzD9wC8VKAW93W/R0tZG6JKqmtmy5jjFj9kKpLFnX0dbWCJs2DYG3dyOJKyOif+KfBqRRjt1IwJnIFOjpaGFe/6ZSl0PVWI8eTrC0LOkl6tWrIUJCpjCIEFVTnBkhjZFXqMD/DocCAKa81gj1LQ0lroiqM3t7E2zaNATnz9/H3LndoM01aIiqLf7vJI2x4mQk4tLz4GBugKk9nKUuh6oRhUKJb789h7S0PLXx119vjM8+684gQlTN8X8oaYSY1Bys/DMKAPBZf3cYcKlueuTBgyz06rUR//3vcUyceAAacO9PIvoHhhHSCAsP3UJhsRLdmljBp1ldqcuhauK33yLh4bESp06V3BLg4MFwXL4cL3FVRFReDCNU7Z0IS8IfoUnQ0ZIhwLcZZDIu2V3bFRcrMWfOH+jTZzOSk3MBAPXqmeLkyfFo185e4uqIqLzYwErVWkGxAgsOltw/ZGLXhnC2MZa4IpLavXsZGDFiN86evaca69evCTZsGARLNjUTaSSGEarWfjkdjbupubAxkWOGF5tWa7vDhyMwduw+PHxY0qiqo6OFL7/shVmzOvEmd0QajGGEqq34jDz8FFSyhPecvm4w0deVuCKS0rlz99C//1bV5w0amGHbtqHo2LGehFURUUVgzwhVW18cDkVekQLtnSwwyMNB6nJIYp061cPQoSUL3Q0a5IarVycziBDVEJwZoWrp3J0UHLoWDy0ZMH8Am1YJkMlk+OUXX/j4NMakSa35M0FUg3BmhKqdIoUS8w+UNK2O7tgAzezNJK6IqlpBQTE++OAYDh+OUBs3M9PH22+3YRAhqmEYRqja+TU4BhGJ2bAw1IV/bxepy6EqFhWVhi5d1mLp0vMYN24f7t/PlLokIqpkDCNUrSRnFeCH4yV/DX/Uxw3mhnoSV0RVadeuW2jdepVq4bKsrEJcvBgncVVEVNnYM0LVylfHwpBVUIyW9czg185R6nKoiuTnF+PDD3/D8uWXVGNNmtTBjh1vwcODK+4S1XQMI1RtXIlNw67L9wEACwY0gzbXjagVbt9OhZ/fLoSEJKjGRoxojlWr+sPERC5hZURUVRhGqFpQKAUC9pc0rb7Vth5a17eQuCKqClu3Xse77x5CdnYhAEBfXwc//vgGr5YhqmUYRqha2H7xHq7HZcBEXwcf9XGTuhyqAqmpuZg69bAqiLi5WWHHjqFo0cJW4sqIqKqxgZUkl55biG9+CwMA+Pd2gTWn5msFS0tDrF07EAAwdmwrXLz4DoMIUS3FmRGS3He/RyAttwiutiYY07GB1OVQJSouVkJH58nfQEOGuOOvvybB05MrqRLVZpwZIUndiMvA5vMxAEpWWtXR5o9kTZSTU4gJE/Zj4sT9EEKobWMQISLOjJBkhBCYf+AmlALwbWWPTo0tpS6JKsHNm0nw89uFW7eSAQA9ezphwoTWEldFRNUJwwhJZl9IHC7FpMFAVxtz+7JptaYRQmDt2quYMeMo8vKKAQBGRrowMODdl4lIHcMISSIrvwiLjpQ0rc7o5Qw7MwOJK6KKlJVVgKlTD2Pz5uuqsVatbLFjx1twceEMGBGpYxghSfxf4G0kZxWgoZURJnVtKHU5VIH+/jsBfn67EBGRqhqbMqUtvv/eh7MiRFQqhhGqcpFJWVh39i4AYJ5vU8h1tKUtiCqEEAKrVl3GBx8cQ0GBAgBgYqKHX34ZAD+/ZhJXR0TVGcMIVamSptVbKFYKeLvboqerjdQlUQURAjhwIFwVRNq0scP27UPh7FxH4sqIqLrjdZRUpY7dSMCZyBTo6WhhXv+mUpdDFUhLS4YNGwbBwcEEM2Z0wLlzExlEiKhMODNCVSavUIH/HQ4FAEzp3hj1LQ0lrohehRACcXFZqFfPVDVmbW2E69enwsKCDclEVHacGaEqs+JkJOLS8+BgboCp3RtLXQ69gvT0fAwduhMdOqxGUlKO2jYGESIqL4YRqhIxqTlY+WcUAOCz/u4w0GPTqqa6cCEOrVuvwp49oYiPz8bYsXufWVWViKg8GEaoSiw8dAuFxUp0a2IFn2Z1pS6HXoIQAt9/H4wuXdbi7t10AICFhT6mT28PmUwmbXFEpNHYM0KV7kRYEv4ITYKOlgwBvs34xqWBHj7Mw/jx+3DwYIRqrFOneti2bSjq1zeTsDIiqgkYRqhSFRQrsODgTQDAxK4N4WxjLHFFVF7nzt3D8OG7cO9epmrs44+7YOHCntDV5ek2Inp1DCNUqX45HY27qbmwMZFjhpez1OVQOS1d+hc+/PB3KBQlPSFWVobYuHEQ3nijicSVEVFNwjBCleZBeh5+CooEAMzt6w4TfS4FrmnMzfVVQaRbt/rYuvVNODiY/sujiIjKh2GEKs2iI6HIK1KgvZMFBnrYS10OvYRx4zxw6lQMHBxMEBDQAzo67HknoorHMEKV4tydFBy6Fg8tGTB/AJtWNYFSKfD773fQp4/66bQ1awbw+0dElYp/5lCFK1IoMf9ASdPq6I4N0MyeV1tUd4mJ2ejTZxPeeGMzdu26pbaNQYSIKhvDCFW4jcExiEjMhoWhLvx7u0hdDv2LoKBoeHiswvHjJYvSvfvuQWRmFkhcFRHVJgwjVKGSswqw5HjJWhQf9XGDuaGexBXR8ygUSgQEnIC390YkJGQDAOrWNcaePcNgaiqXuDoiqk3YM0IV6qtjYcgqKEbLembwa+codTn0HA8eZGHUqD04efKuauz11xvj118Hw8bGSLrCiKhWYhihCnM5Jg27Lt8HACwY0AzaWuw1qI5+//0ORo/eg+TkXACAlpYMCxf2xOzZXaHF7xkRSYBhhCqEQilUTatvta2H1vUtJK6ISrNu3VVMmnQAj+9r5+Bggq1b30S3bg2kLYyIajX2jFCF2H7xHq7HZcBEXwcf9XGTuhx6jtdfb4w6dQwAAH37NkFIyBQGESKSHGdG6JWl5xbim9/CAAD+vV1gbcLmx+rKwcEUv/46GDdvJsPfvxNPyxBRtcCZEXpl3/0egbTcIrjammBMR/6VXV0UFSmwaNFppKfnq42/8UYT/Oc/nRlEiKjaeKkwsmzZMjg5OUFfXx+enp64cOFCmR63bds2yGQyDBo06GVelqqhG3EZ2Hw+BkDJSqs62sy31UFMTDpee209PvkkCO+8cxDicZMIEVE1VO53ju3bt8Pf3x8BAQG4cuUKWrVqBR8fHyQlJb3wcXfv3sV//vMfdOvW7aWLpepFCIGAAzehFIBvK3t0amwpdUkEYP/+MLRuvQp//XVf9fn16y/+/0lEJKVyh5Hvv/8e77zzDiZMmICmTZti5cqVMDQ0xNq1a5/7GIVCgVGjRmHBggVo1KjRKxVM1cfeq3G4HJMGQz1tzO3LplWpFRYqMGvWMQwatB1paSWnZho2NMfZsxPRsqWtxNURET1fucJIYWEhLl++DG9v7ydPoKUFb29vBAcHP/dxn3/+OWxsbDBp0qQyvU5BQQEyMzPVPqh6ycovwuKjJU2r73k5w87MQOKKareoqDR06bIWS5acV429+aY7rlyZjPbtHSSsjIjo35UrjKSkpEChUMDWVv2vLFtbWyQkJJT6mDNnzmDNmjVYvXp1mV9n8eLFMDMzU304OnIlz+rm/wJvIzmrAA2tjDCpa0Opy6nVdu++hdatV+HSpQcAAD09bSxb1hc7d74Fc3N9iasjIvp3ldptmJWVhTFjxmD16tWwsrIq8+PmzJmDjIwM1ce9e/cqsUoqr8ikLKw7excAEODbFHIdbWkLqsVOnbqLoUN3qm5s5+xcB3/9NQnTprXn3XaJSGOUa50RKysraGtrIzExUW08MTERdevWfWb/O3fu4O7du/D19VWNKZXKkhfW0UF4eDgaN278zOPkcjnkcq5VUR0JITD/wC0UKwW83W3Rw9VG6pJqtddea4AhQ9yxZ08ohg9vjlWr+vMmd0SkccoVRvT09NC2bVsEBgaqLs9VKpUIDAzEe++998z+bm5uuH79utrYp59+iqysLCxdupSnXzTQsRsJOBOZAj0dLczr31Tqcmo9mUyGNWsGYOBAV4wZ05KzIUSkkcq9Aqu/vz/GjRuHdu3aoUOHDliyZAlycnIwYcIEAMDYsWPh4OCAxYsXQ19fH82bN1d7vLm5OQA8M07VX16hAgsP3QIATOneGPUtDSWuqHbJyyvCBx8cw5Ah7vDxcVaNm5vrY+zYVhJWRkT0asodRoYNG4bk5GTMmzcPCQkJ8PDwwLFjx1RNrbGxsdDS4sJXNdHyk5F4kJEPB3MDTO3+7Ok1qjxhYSnw89uJ69eTsHdvGEJCpsDe3kTqsoiIKoRMaMDSjJmZmTAzM0NGRgZMTU2lLqdWiknNQe8f/kRhsRIrR7dBn+Z2UpdUa/z669+YOvUwcnKKAAAGBjrYtcsPffs2kbgyIqIXK+v7N2+UR2Wy8NAtFBYr0a2JFXyaPdusTBUvJ6cQM2Ycxbp1Iaqxpk2tsXPnW2ja1Fq6woiIKhjDCP2rE2FJ+CM0CTpaMgT4NmOTZBW4eTMJfn67cOtWsmps4kQP/PhjXxga6kpYGRFRxWMYoRcqKFZgwcGbAICJXRvC2cZY4opqNiEE1q0LwXvvHUFeXjEAwMhIFytX9sfo0S0lro6IqHIwjNAL/XI6GndTc2FjIscML+d/fwC9kqSkHMya9ZsqiLRsaYvt24fCza3siwYSEWkaXvZCz/UgPQ8/BUUCAOb2dYeJPk8PVDZbW2P88kvJIoGTJ7fFX39NYhAhohqPMyP0XF8cCUVekQLtnSww0MNe6nJqJCEEiouV0NV9sqT+W281w8WLFmjXjseciGoHzoxQqc7dScHha/HQkgHzB7BptTJkZhZgxIjdmDz50DPbGESIqDbhzAg9o0ihxPwDJU2rozs2QDN7M4krqnmuXImHn99O3LmTBgDo2dMJY8ZwFVUiqp04M0LP2Bgcg4jEbNQx0oN/bxepy6lRhBD46acL6NRpjSqImJnJYWysJ3FlRETS4cwIqUnOKsCS4xEAgP/6uMLckG+SFSU9PR9vv30Au3eHqsbat7fH9u1D0bChhYSVERFJi2GE1Hx1LAxZBcVoWc8Mfu14V+WKcvFiHIYN24Xo6HTV2KxZHfHll97Q09N+/gOJiGoBhhFSuRyThl2X7wMAFgxoBm0tNq2+KiEEli49j48+Oo6iIiUAwMJCH+vXD8KAAa4SV0dEVD0wjBAAQKEUCDhwAwDwVtt6aF2fpw0qghDA0aORqiDSqVM9bNs2FPXrsymYiOgxNrASAGD7xXu4EZcJE30dfNTHTepyagwtLRk2bhwEe3sTfPRRZ5w6NZ5BhIjoHzgzQkjLKcTXv4UBAPx7u8DaRC5xRZpLqRS4fz9TLXDY2hrj1q1pMDPTl7AyIqLqizMjhO+OhyM9twiutiYY07GB1OVorOTkHPTvvwWdO69BSkqu2jYGESKi52MYqeVuxGVgy/lYAMCCgc2go80fiZdx+nQMPDxW4ejRSMTFZWHChP1Sl0REpDH4zlOLCSEQcOAmlALwbWWPjo0spS5J4yiVAl988Sd69NiABw+yAAA2NkZ4//0OEldGRKQ52DNSi+29GofLMWkw1NPG3L5sWi2vxMRsjBmzF8ePR6nGevZ0wubNQ2BnZyJhZUREmoVhpJbKyi/CoiMlTavveTnDzsxA4oo0S1BQNEaN2oOEhGwAgEwGBAR0x6efvgZtnuoiIioXhpFa6v8CbyMluwANrYwwqWtDqcvRKF9+eQZz5wZCiJLP69Y1xpYtQ9CzJ48jEdHLYBiphW4nZmHd2bsAgADfppDrcDny8rC2NlQFkd69G2HTpiGwsTGStigiIg3GMFLLCCEw/+BNFCsFeje1RQ9XG6lL0jgTJ7bG6dOxcHGxxOzZXaHFZfOJiF4Jw0gtc+xGAs5GpkJPRwuf9WsqdTnVXnGxEseORaJ/fxfVmEwmw7p1AyGTMYQQEVUEdtrVInmFCiw8dAsAMKV7Y9S3NJS4ourt/v1M9Oy5Ab6+W7F3b6jaNgYRIqKKwzBSiyw/GYkHGflwMDfA1O6NpS6nWjty5DY8PFbizJmSBeHeffcQcnIKJa6KiKhmYhipJWJSc7DqVMl6GJ/1d4eBHptWS1NUpMBHHx1Hv35bkJqaBwBwdDTFgQPDYWSkJ3F1REQ1E3tGaomFh26hUKFEtyZW8GlWV+pyqqWYmHQMH74bf/11XzU2YIAr1q0biDp1uA4LEVFlYRipBYLCEvFHaBJ0tGQI8G3GfodS7N8fhgkT9iMtLR8AoKurha+/7o2ZMz15vIiIKhnDSA1XUKzA5wdLmlYndm0IZxtjiSuqfpYvv4jp04+oPndyMseOHUPRvr2DhFUREdUe7Bmp4X45HY27qbmwMZFjhpez1OVUS76+LqrTMEOGuOPq1ckMIkREVYgzIzXYg/Q8/BQUCQCY29cdJvq6EldUPTk6mmHDhkGIiUnHtGnteVqGiKiKMYzUYF8cCUVekQLtnSww0MNe6nKqhfz8YixefBr+/p1gZqavGn96UTMiIqpaDCM11LnIFBy+Fg8tGbBgQHP+tQ/g9u1UDBu2C1evJiAsLBXbtr3J40JEVA2wZ6QGKlIoMf/gTQDA6I4N0NTeVOKKpLdt2w20bfszrl5NAFBy9UxYWIrEVREREcAwUiNtDI5BRGI26hjpwb937T79kJdXhMmTD2LEiN3IyipZQdXFxRIXLrwDd3driasjIiKAp2lqnOSsAiw5HgEA+K+PK8wNa++qoeHhKfDz24Vr1xJVY6NHt8SKFf1gbFx7jwsRUXXDMFLDfHUsDFkFxWhZzwx+7RylLkcymzZdw5Qph5CTUwQAMDDQwbJlfTF+vAf7RIiIqhmGkRrkckwadl0uWcp8wYBm0NaqnW+6v/9+B2PG7FV93rSpNXbsGIpmzWwkrIqIiJ6HPSM1hEIpEHDgBgDAr109tK5vIXFF0unduxEGDHAFAEyY4IELF95mECEiqsY4M1JDbLsYixtxmTDR18FHfdykLkdSMpkM69YNxPHjdzBsWHOpyyEion/BmZEaIC2nEN/8Fg4A8O/tAitjucQVVZ3s7EKMG7cPx4/fURuvU8eAQYSISEMwjNQA3x0PR3puEVxtTTCmYwOpy6ky164lol27n7Fx498YPXov4uOzpC6JiIheAsOIhrsRl4HN52MBAAsGNoOOds3/lgoh8PPPl9Ghw2qEh6cCAHJzi3DzZrLElRER0ctgz4gGE0Ig4MBNCAH4trJHx0aWUpdU6TIzCzB58iFs23ZDNebhURc7dgxFkyY1/+snIqqJGEY02N6rcbgckwZDPW3M7Vvzm1avXo2Hn98uREY+VI1Nn94e3377OvT1+aNMRKSp+BtcQ2XlF2HRkTAAwAyvJrAzM5C4osojhMDy5Rfh7/87CgsVAABTUznWrBmAoUObSlwdERG9KoYRDbX0j9tIyS5AQysjTOzqJHU5lerBgyzMnh2oCiLt2tlj+/ahaNSo9q6lQkRUk9T8bsca6HZiFtafuwsACPBtCrmOtrQFVTIHB1P8/HN/AMAHH3ji7NmJDCJERDUIZ0Y0jBAC8w/eRLFSoHdTW/RwrXkriwohUFSkhJ7ek5A1YkQLuLtbw8OjroSVERFRZeDMiIY5eiMBZyNToaejhc/61bx+iYcP8zBo0HZMn374mW0MIkRENRNnRjRIXqEC/zt0CwAwpXtj1Lc0lLiiihUcfA/Dh+9GbGwGAKBnz4YYObKFxFUREVFl48yIBll+MhIPMvLhYG6Aqd0bS11OhVEqBb7++iy6dVunCiKWlgawsNCXuDIiIqoKnBnREDGpOVh1KgoA8Fn/pjDQqxlNqykpuRg7di+OHo1UjXXtWh9bt76JevVMJayMiIiqCsOIhlh46BYKFUp0a2IFn2a2UpdTIU6fjsGIEbsRF/fknjJz5nTF55/3hI4OJ+2IiGoLhhENEBSWiD9Ck6CjJUOAbzPIZDKpS3olSqXA4sWnMW/eSSiVAgBgbW2IX38dDB8fZ4mrIyKiqvZSf34uW7YMTk5O0NfXh6enJy5cuPDcfVevXo1u3brBwsICFhYW8Pb2fuH+pC6/SIEFB0uaVid1bQhnG2OJK3p1QgicOHFXFUR69HBCSMgUBhEiolqq3GFk+/bt8Pf3R0BAAK5cuYJWrVrBx8cHSUlJpe5/8uRJjBgxAidOnEBwcDAcHR3x+uuvIy4u7pWLrw3WnIlGTGoubEzkmNGridTlVAhtbS1s2jQEdnbGCAjojj/+GAN7exOpyyIiIonIhBCiPA/w9PRE+/bt8dNPPwEAlEolHB0dMWPGDMyePftfH69QKGBhYYGffvoJY8eOLdNrZmZmwszMDBkZGTA1rT1NjQ/S89Dru1PIK1JgyTAPDGrtIHVJL0WhUOLevUw4OZmrjWdlFcDERC5NUUREVOnK+v5drpmRwsJCXL58Gd7e3k+eQEsL3t7eCA4OLtNz5ObmoqioCHXq1HnuPgUFBcjMzFT7qI2+OBKKvCIF2jtZYKCHvdTlvJT4+Cz07v0rXnttHVJTc9W2MYgQERFQzjCSkpIChUIBW1v1qzlsbW2RkJBQpuf4+OOPYW9vrxZo/mnx4sUwMzNTfTg6OpanzBrhXGQKDl+Lh5YMWDCguUY2rR4/fgceHqtw4sRd3LuXibffPih1SUREVA1V6fWTX375JbZt24a9e/dCX//5C1rNmTMHGRkZqo979+5VYZXSK1IoMf/gTQDA6I4N0NRes05NFRcr8emnQfDx2YSkpBwAgL29CT74wFPiyoiIqDoq16W9VlZW0NbWRmJiotp4YmIi6tZ98X1Dvv32W3z55Zf4448/0LJlyxfuK5fLIZfX3in8jcExiEjMRh0jPfj3dpG6nHK5fz8TI0fuxunTsaqxPn2csXHjIFhbG0lYGRERVVflmhnR09ND27ZtERgYqBpTKpUIDAxEp06dnvu4r7/+GgsXLsSxY8fQrl27l6+2FkjKyseS4xEAgI98XGFuqCdxRWV35MhteHisVAURbW0ZvvyyFw4fHskgQkREz1XuRc/8/f0xbtw4tGvXDh06dMCSJUuQk5ODCRMmAADGjh0LBwcHLF68GADw1VdfYd68ediyZQucnJxUvSXGxsYwNtb8NTMq2ldHw5FVUIyW9czg105zemXmzTuBhQv/VH3u6GiKbduGonNnzfkaiIhIGuUOI8OGDUNycjLmzZuHhIQEeHh44NixY6qm1tjYWGhpPZlwWbFiBQoLCzF06FC15wkICMD8+fNfrfoa5nJMGnZfuQ8AWDCgGbS0NKdp9en7yPj6umDduoGwrGF3FSYiospR7nVGpFAb1hlRKAUGLjuDG3GZ8GtXD18PbSV1SeUihMD48fvh4WGLDz7oqJFX/xARUcUq6/s3701TTWy7GIsbcZkw0dfBR33cpC7nhQoLFTh2LBIDBriqxmQyGdavH8gQQkRE5cZbo1YDaTmF+Oa3cACAf28XWBlX3yuJoqPT0K3bOgwcuA0HDoSrbWMQISKil8EwUg18dzwc6blFcLU1wZiODaQu57n27AlF69arcOFCyX2Fpkw5hPz8YomrIiIiTccwIrEbcRnYfL7kUtgFA5tBR7v6fUsKCooxY8YRvPnmDmRkFAAAGje2wMGDI6CvzzN9RET0avhOIiEhBAIO3IQQgG8re3RsZCl1Sc+IjHyIYcN24cqVeNWYn18zrF7tC1PT6ns6iYiINAfDiIT2Xo3D5Zg0GOppY27f6te0un37DbzzzkFkZRUCAORybSxd2gfvvtuW/SFERFRhGEYkkpVfhEVHwgAAM7yawM7MQOKK1H3/fTA+/PB31ecuLpbYsWMoWrV68bL/RERE5VX9GhRqiaV/3EZKdgEaWhlhYlcnqct5xptvusPCouRmhqNGtcClS+8wiBARUaXgzIgEbidmYf25uwCAAN+mkOtoS1tQKRo0MMf69YOQnJyDiRNb87QMERFVGs6MVDEhBOYfvIlipUDvprbo4WojdUnIzS3C3LmByMoqUBsfMMAVkya1YRAhIqJKxZmRKnb0RgLORqZCT0cL8/o3lboc3LyZBD+/Xbh1KxkxMRnYtGkwwwcREVUpzoxUodzCYvzv0C0AwJTujeFYR7obyQkhsG7dVbRvvxq3biUDAPbvD8OdO2mS1URERLUTw0gVWnHyDh5k5MPB3ABTuzeWrI7s7EKMG7cPEyceQF5eyQqqLVrY4NKld+HsXEeyuoiIqHbiaZoqcjclB6tORQEAPuvfFAZ60jStXruWiGHDdiEsLEU19u67bbBkSR8YGOhKUhMREdVuDCNVZOGhWyhUKNGtiRV8mtlW+esLIbB69RXMnHlMdT8ZY2M9rF7ti+HDm1d5PURERI8xjFSBoLBEBIYlQUdLhgDfZpI0iB4+fBuTJx9Sfe7hURc7dgxFkybVbwl6IiKqXdgzUsnyixRYcLCkaXVS14ZwtjGWpI5+/Zqgf38XAMC0ae0QHDyJQYSIiKoFzoxUsjVnohGTmgsbEzlm9GoiWR0ymQzr1w/En3/GYPBgd8nqICIi+ifOjFSiB+l5+CkoEgAwt687jOVVk/3S0/MxbNguBAVFq41bWhoyiBARUbXDMFKJvjgSirwiBdo7WWCgh32VvObFi3Fo02YVduy4iVGj9iAxMbtKXpeIiOhlMYxUknORKTh8LR5aMmDBgOaV3rQqhMCSJX+hS5e1iI5OBwDk5xcjIiK1Ul+XiIjoVbFnpBIUKZQIOHATADC6YwM0tTet1Nd7+DAPEyfux/794aqxjh3rYdu2N9GggXmlvjYREdGrYhipBBuDY3A7KRt1jPTg39ulUl/rr7/uY9iwXYiNzVCN/fe/nfHFF17Q1a1+dwMmIiL6J4aRCpaUlY8lxyMAAB/5uMLcUK9SXkepFPjuu3OYOzcIxcVKAIClpQE2bBiEfv0qNwARERFVJIaRCvbV0XBkFRSjZT0z+LVzrLTXuX8/EwsWnFIFka5d62Pr1jdRr17lnhIiIiKqaGxgrUCXYx5i95X7AIAFA5pBS6vymlbr1zfDypX9AQBz5nTFiRPjGESIiEgjcWakgiiUQtW06teuHlrXt6jQ51cqBYqLldB76gZ7o0e3RKtWtmjRourvdUNERFRRODNSQbZdjMWNuEyY6Ovgoz5uFfrcSUk5eOONzZg58+gz2xhEiIhI03FmpAKk5RTim99KLqv17+0CK2N5hT33yZN3MXLkbsTHlyxe1rNnQ/j5Nauw5yciIpIaZ0YqwHfHw5GeWwRXWxOM6digQp5ToVBiwYKT6NVroyqI1K1rDGtrwwp5fiIiouqCMyOv6EZcBjafjwUALBjYDDrar57v4uOzMHr0XrV7y3h7N8KmTYNhayvNXX+JiIgqC8PIK1AqBebtvwEhAN9W9ujYyPKVn/P48TsYPXovkpJyAABaWjJ8/nkPzJ7dFdoVEHSIiIiqG4aRV7D3ahyuxKbDUE8bc/u+WtNqcbES8+efxKJFpyFEyZi9vQm2bn0Tr71WMad+iIiIqiOGkZeUlV+ExUfDAAAzvJrAzszglZ5PJgPOnr2nCiJ9+jhj48ZBsLY2etVSiYiIqjXO+7+kpX/cRkp2ARpZGWFiV6dXfj5tbS1s3jwEdnbG+PLLXjh8eCSDCBER1QqcGXkJtxOzsP7cXQDAPN+mkOuU/4Z0RUUK3L+fiYYNnyyOZm9vgtu3Z8DIqHLuZ0NERFQdcWaknIQQmH/wJoqVAr2b2qKHq025nyM2NgM9emxAz54bkJaWp7aNQYSIiGobhpFyOnojAWcjU6Gno4V5/ZuW+/EHD4bDw2Mlzp27h5iYDEyefKgSqiQiItIcDCPlkFtYjP8dugUAmNK9MRzrlH0BssJCBT788DcMGLANaWn5AAAnJ3P85z+dK6VWIiIiTcGekXJYfuIOHmTkw8HcAFO7Ny7z46Kj0zB8+G5cuBCnGhs82A1r1w6Eubl+ZZRKRESkMRhGyuhuSg5+/jMKAPBZ/6Yw0Ctb0+qePaGYOHE/MjIKAAB6etr47rvXMX16e8hkskqrl4iISFMwjJTRwkO3UKhQolsTK/g0K9udcv/739/x7bfBqs8bN7bA9u1D0batfWWVSUREpHEYRsogKCwRgWFJ0NGSIcC3WZlnNJ6+bNfPrxlWr/aFqWnF3dGXiIioJmAY+Rf5RQosOFjStDqpa0M425T9RnVTp7bDX3/dR+fOjpg8uS1PyxAREZWCYeRfrDkTjZjUXNiYyDGjV5Pn7pefX4yjR29j8GB31ZhMJsPGjYOrokwiIiKNxUt7XyAuPQ8/Bt0GAMzt6w5jeenZLTw8BZ6ev2DIkB04fDiiKkskIiLSeAwjL7DocCjyi5Ro72SBgR6lN51u3nwNbdv+jGvXEgEAU6ceRmGhoirLJCIi0mg8TfMc5yJTcPh6PLRkwIIBzZ/p98jNLcL77x/FmjVXVWPu7lbYseMt6JXxsl8iIiJiGClVkUKJgAM3AQCjOzZAU3tTte23biXDz28nbt5MVo2NH++Bn356g/eWISIiKieGkVJsOHcXt5OyUcdID/69XdS2rV8fgunTjyA3twgAYGioixUr+mHs2FZSlEpERKTxGEb+ISkrH0v/KGla/cjHFeaGT2Y6Fi06jU8+CVJ93ry5DXbufAtublZVXicREVFNwQbWf/jqaDiyCorRqp4Z/No5qm0bMaI5zMxKFi175502uHDhbQYRIiKiV8SZkadcjnmI3VfuAwDmD2gGLS31ptWGDS2wfv0g5OUVYcSIFlKUSEREVONwZuQRhVJg3v6SplW/dvXgbGGIjz46juzsQrX9Bg1yYxAhIiKqQJwZeWTbxVjcfJAJE30d9LEzR5s2PyMy8iESErKxYcMgLuVORERUSTgzAiAtpxDf/BYOIQQ8spTo2+tXREY+BADs3x+O2NgMiSskIiKquV4qjCxbtgxOTk7Q19eHp6cnLly48ML9d+7cCTc3N+jr66NFixY4cuTISxVbWb79PRwP0/JQ8FssNn1/AQUFJSuotm1rhytX3kWDBubSFkhERFSDlTuMbN++Hf7+/ggICMCVK1fQqlUr+Pj4ICkpqdT9z507hxEjRmDSpEm4evUqBg0ahEGDBuHGjRuvXHxFuBGXgXX7QxG/PhSJfz9ZxGzmTE+cPTsRjRvXkbA6IiKimk8mhBDleYCnpyfat2+Pn376CQCgVCrh6OiIGTNmYPbs2c/sP2zYMOTk5ODQoUOqsY4dO8LDwwMrV64s02tmZmbCzMwMGRkZMDU1/fcHlJFCoUTr4dtxfc9tQFlyGMzN9bFu3UAMGuRWYa9DRERUG5X1/btcMyOFhYW4fPkyvL29nzyBlha8vb0RHBxc6mOCg4PV9gcAHx+f5+4PAAUFBcjMzFT7qAyzvzuL67siVEHE09MBISGTGUSIiIiqULnCSEpKChQKBWxtbdXGbW1tkZCQUOpjEhISyrU/ACxevBhmZmaqD0dHx+fu+7LyixQ4UZAP/UYlSe0//+mE06cnsD+EiIioilXLS3vnzJkDf39/1eeZmZkVHkj0dbWxbFQbLK9jhDcbWGJAf9cKfX4iIiIqm3KFESsrK2hrayMxMVFtPDExEXXr1i31MXXr1i3X/gAgl8shl8vLU9pL8WxkCc/pnSv9dYiIiOj5ynWaRk9PD23btkVgYKBqTKlUIjAwEJ06dSr1MZ06dVLbHwCOHz/+3P2JiIiodin3aRp/f3+MGzcO7dq1Q4cOHbBkyRLk5ORgwoQJAICxY8fCwcEBixcvBgDMnDkT3bt3x3fffYd+/fph27ZtuHTpEn7++eeK/UqIiIhII5U7jAwbNgzJycmYN28eEhIS4OHhgWPHjqmaVGNjY6Gl9WTCpXPnztiyZQs+/fRTzJ07F02aNMG+ffvQvHnzivsqiIiISGOVe50RKVTWOiNERERUeSplnREiIiKiisYwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCRV7uXgpfB4kdjMzEyJKyEiIqKyevy+/W+LvWtEGMnKygIAODo6SlwJERERlVdWVhbMzMyeu10j7k2jVCrx4MEDmJiYQCaTVdjzZmZmwtHREffu3eM9byoRj3PV4bGuGjzOVYPHuWpU5nEWQiArKwv29vZqN9H9J42YGdHS0kK9evUq7flNTU35g14FeJyrDo911eBxrho8zlWjso7zi2ZEHmMDKxEREUmKYYSIiIgkVavDiFwuR0BAAORyudSl1Gg8zlWHx7pq8DhXDR7nqlEdjrNGNLASERFRzVWrZ0aIiIhIegwjREREJCmGESIiIpIUwwgRERFJqsaHkWXLlsHJyQn6+vrw9PTEhQsXXrj/zp074ebmBn19fbRo0QJHjhypoko1W3mO8+rVq9GtWzdYWFjAwsIC3t7e//p9oSfK+zP92LZt2yCTyTBo0KDKLbCGKO9xTk9Px/Tp02FnZwe5XA4XFxf+/iiD8h7nJUuWwNXVFQYGBnB0dMSsWbOQn59fRdVqpj///BO+vr6wt7eHTCbDvn37/vUxJ0+eRJs2bSCXy+Hs7Iz169dXbpGiBtu2bZvQ09MTa9euFTdv3hTvvPOOMDc3F4mJiaXuf/bsWaGtrS2+/vprcevWLfHpp58KXV1dcf369SquXLOU9ziPHDlSLFu2TFy9elWEhoaK8ePHCzMzM3H//v0qrlzzlPdYPxYdHS0cHBxEt27dxMCBA6umWA1W3uNcUFAg2rVrJ/r27SvOnDkjoqOjxcmTJ0VISEgVV65ZynucN2/eLORyudi8ebOIjo4Wv/32m7CzsxOzZs2q4so1y5EjR8Qnn3wi9uzZIwCIvXv3vnD/qKgoYWhoKPz9/cWtW7fEjz/+KLS1tcWxY8cqrcYaHUY6dOggpk+frvpcoVAIe3t7sXjx4lL39/PzE/369VMb8/T0FJMnT67UOjVdeY/zPxUXFwsTExOxYcOGyiqxxniZY11cXCw6d+4sfvnlFzFu3DiGkTIo73FesWKFaNSokSgsLKyqEmuE8h7n6dOnCy8vL7Uxf39/0aVLl0qtsyYpSxj56KOPRLNmzdTGhg0bJnx8fCqtrhp7mqawsBCXL1+Gt7e3akxLSwve3t4IDg4u9THBwcFq+wOAj4/Pc/enlzvO/5Sbm4uioiLUqVOnssqsEV72WH/++eewsbHBpEmTqqJMjfcyx/nAgQPo1KkTpk+fDltbWzRv3hyLFi2CQqGoqrI1zssc586dO+Py5cuqUzlRUVE4cuQI+vbtWyU11xZSvBdqxI3yXkZKSgoUCgVsbW3Vxm1tbREWFlbqYxISEkrdPyEhodLq1HQvc5z/6eOPP4a9vf0zP/yk7mWO9ZkzZ7BmzRqEhIRUQYU1w8sc56ioKAQFBWHUqFE4cuQIIiMjMW3aNBQVFSEgIKAqytY4L3OcR44ciZSUFHTt2hVCCBQXF2PKlCmYO3duVZRcazzvvTAzMxN5eXkwMDCo8NessTMjpBm+/PJLbNu2DXv37oW+vr7U5dQoWVlZGDNmDFavXg0rKyupy6nRlEolbGxs8PPPP6Nt27YYNmwYPvnkE6xcuVLq0mqUkydPYtGiRVi+fDmuXLmCPXv24PDhw1i4cKHUpdErqrEzI1ZWVtDW1kZiYqLaeGJiIurWrVvqY+rWrVuu/enljvNj3377Lb788kv88ccfaNmyZWWWWSOU91jfuXMHd+/eha+vr2pMqVQCAHR0dBAeHo7GjRtXbtEa6GV+pu3s7KCrqwttbW3VmLu7OxISElBYWAg9Pb1KrVkTvcxx/uyzzzBmzBi8/fbbAIAWLVogJycH7777Lj755BNoafHv64rwvPdCU1PTSpkVAWrwzIienh7atm2LwMBA1ZhSqURgYCA6depU6mM6deqktj8AHD9+/Ln708sdZwD4+uuvsXDhQhw7dgzt2rWrilI1XnmPtZubG65fv46QkBDVx4ABA9CzZ0+EhITA0dGxKsvXGC/zM92lSxdERkaqwh4AREREwM7OjkHkOV7mOOfm5j4TOB4HQMHbrFUYSd4LK601thrYtm2bkMvlYv369eLWrVvi3XffFebm5iIhIUEIIcSYMWPE7NmzVfufPXtW6OjoiG+//VaEhoaKgIAAXtpbBuU9zl9++aXQ09MTu3btEvHx8aqPrKwsqb4EjVHeY/1PvJqmbMp7nGNjY4WJiYl47733RHh4uDh06JCwsbER//vf/6T6EjRCeY9zQECAMDExEVu3bhVRUVHi999/F40bNxZ+fn5SfQkaISsrS1y9elVcvXpVABDff/+9uHr1qoiJiRFCCDF79mwxZswY1f6PL+3973//K0JDQ8WyZct4ae+r+vHHH0X9+vWFnp6e6NChg/jrr79U27p37y7GjRuntv+OHTuEi4uL0NPTE82aNROHDx+u4oo1U3mOc4MGDQSAZz4CAgKqvnANVN6f6acxjJRdeY/zuXPnhKenp5DL5aJRo0biiy++EMXFxVVcteYpz3EuKioS8+fPF40bNxb6+vrC0dFRTJs2TaSlpVV94RrkxIkTpf7OfXxsx40bJ7p37/7MYzw8PISenp5o1KiRWLduXaXWKBOCc1tEREQknRrbM0JERESagWGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSf0/1dr/Ws87O4sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0).clf()\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, predicitions)\n",
    "auc = metrics.roc_auc_score(test_label, predicitions)\n",
    "plt.plot(fpr,tpr,label=\"XGBoost, auc=\"+str(auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.legend(loc=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
